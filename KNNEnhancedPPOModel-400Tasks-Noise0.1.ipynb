{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f973fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
      "MAE: 1.9645398393113325\n",
      "RMSE: 2.4344408047900314\n",
      "R-squared: 0.9599156505668087\n",
      "RAE: 0.20517700777318204\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=['Eligible'])\n",
    "    y = data['Eligible']\n",
    "    return X, y\n",
    "\n",
    "def optimize_knn_model(X_train, y_train):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    knn_model = KNeighborsRegressor()\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 10, 20, 30, 40],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "        'p': [1, 2]  # 1: Manhattan distance, 2: Euclidean distance\n",
    "    }\n",
    "    grid_search = GridSearchCV(knn_model, param_grid, cv=5, verbose=1, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    best_knn = grid_search.best_estimator_\n",
    "    return best_knn, scaler\n",
    "\n",
    "# Load and train on VehicleTrainingDataset.csv\n",
    "X_train, y_train = load_and_preprocess_data('VehicleTrainingDataset_Noisy_0.1.csv')\n",
    "knn_model, scaler = optimize_knn_model(X_train, y_train)\n",
    "\n",
    "# Predict eligibility scores on 1000VehicleDataset.csv\n",
    "vehicles_df = pd.read_csv('1000VehicleDataset_Noisy_0.1.csv')\n",
    "X_test = vehicles_df.drop(columns=['Eligible'])\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "predicted_scores = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Assuming you have access to actual scores, replace this line with the actual score loading logic if available\n",
    "y_actual = vehicles_df['Eligible']\n",
    "\n",
    "# Replace actual scores with predicted ones\n",
    "vehicles_df['Eligible'] = predicted_scores  \n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_actual, predicted_scores)\n",
    "rmse = np.sqrt(mean_squared_error(y_actual, predicted_scores))\n",
    "r_squared = r2_score(y_actual, predicted_scores)\n",
    "rae = np.sum(np.abs(y_actual - predicted_scores)) / np.sum(np.abs(y_actual - np.mean(y_actual)))\n",
    "\n",
    "# Output the results\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "print(f\"RAE: {rae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c97398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -372.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.5\n",
      "All assignments history: [8, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -378     |\n",
      "| time/              |          |\n",
      "|    fps             | 201      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -322.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.166666666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -375         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 180          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068475376 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.88        |\n",
      "|    explained_variance   | -0.214       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.66         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 17.6         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -358.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.61111111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -375         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 157          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077202194 |\n",
      "|    clip_fraction        | 0.0916       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | -0.0898      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.82         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -340.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.791666666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007133017 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.0783      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.14        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -320.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.133333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008011054 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | -0.0246     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.01        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 8.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -294.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.569444444444443\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007747723 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | -0.0211     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 7.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -230.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.76190476190476\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008658298 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | -0.0333     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 6.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -198.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.145833333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008695146 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | -0.00863    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 5.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.370370370370374\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009640477 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 4.63        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 56.108333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009969589 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.00446     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 3.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 62.265151515151516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010514291 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.00525     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 3.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 67.55555555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011862276 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.000301    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 70.01282051282051\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012010341 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00124     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 76.17857142857143\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017342456 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | -0.00107    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.359       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0565     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 82.09444444444445\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014465386 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00111     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 87.68229166666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014209313 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.000811    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 92.76960784313725\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012659851 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0052      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 97.55092592592592\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009558548 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0744      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 102.0657894736842\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007937387 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 106.09166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506895 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 110.02777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007309163 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.503       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.47348484848484\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -362       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 97         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 230        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00728218 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.7       |\n",
      "|    explained_variance   | 0.213      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.986      |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0373    |\n",
      "|    value_loss           | 2.98       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.68478260869566\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006983203 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.989       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 119.89236111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -359         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074488055 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.65        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.72         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 122.73\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -357         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 286          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075573837 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.62        |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.24358974358974\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -356       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 87         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00813533 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.57      |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.872      |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    value_loss           | 3.11       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.57098765432099\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008955641 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.74404761904762\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -353       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 83         |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 343        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00852605 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.5       |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.47       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 3.1        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.76436781609195\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007310088 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.46       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.493       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.775\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -349         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 381          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073461034 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.4         |\n",
      "|    explained_variance   | 0.294        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.7688172043011\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -347       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 79         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 399        |\n",
      "|    total_timesteps      | 31744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00810271 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.33      |\n",
      "|    explained_variance   | 0.252      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.493      |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 3.14       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.6953125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -344         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 78           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 418          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076360186 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.26        |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.52272727272728\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -341         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 77           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 437          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082763545 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.2         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.939        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.38480392156862\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007905473 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.918       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.13095238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008676674 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.73        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.9398148148148\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -332        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008284211 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.65765765765767\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008826814 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0482     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.40570175438597\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -327        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009219667 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.13247863247864\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -324        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008674614 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.75       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.751       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.89583333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -321        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 574         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009434294 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.952       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.73373983739836\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -318        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 595         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007929414 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.56944444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -315        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 614         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008417136 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.40503875968992\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -311       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 69         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 634        |\n",
      "|    total_timesteps      | 44032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00773138 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.43      |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.24       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0432    |\n",
      "|    value_loss           | 3.37       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.19886363636363\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -308         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 654          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077963807 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.32        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.043       |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.87962962962962\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -304         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 673          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076244343 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.5923913043478\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -301         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 692          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063872486 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.20567375886526\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 712         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006962402 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 3.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.77430555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -294        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005588214 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.964       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.28571428571428\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -290         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067382143 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.95        |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0431      |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.71833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 765         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006172146 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.1078431372549\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -280         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 787          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061071115 |\n",
      "|    clip_fraction        | 0.0817       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.89        |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0332      |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.4022435897436\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -275         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 806          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061471416 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.81        |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.6933962264151\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -269         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 828          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053790463 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.77        |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.92746913580248\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -264         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 849          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056604473 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.74        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.97         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.12272727272727\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 868          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056296955 |\n",
      "|    clip_fraction        | 0.0972       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.71        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.32589285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -253         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 886          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069528325 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.67        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.87         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 3.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.51461988304092\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -247         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 907          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058442163 |\n",
      "|    clip_fraction        | 0.0835       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0327      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.68965517241378\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -241        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 927         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007355328 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.82909604519773\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -235         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 947          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060260864 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0324      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.93055555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -229        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 966         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005298422 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.02322404371586\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -223         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 985          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053709606 |\n",
      "|    clip_fraction        | 0.0964       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.0752688172043\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -217         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1006         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061922367 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.08201058201058\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -212         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 1026         |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068933573 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0359      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.10677083333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -206       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 1044       |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00621905 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.39      |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.64       |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 3.2        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.12820512820514\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -199         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1061         |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061151185 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.68         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.12373737373738\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -193        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006215672 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.1082089552239\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -187        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1102        |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006378667 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.0857843137255\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -181         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1121         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067227366 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.57         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.05314009661836\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -175        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1141        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005658906 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.93928571428572\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -168         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 1162         |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052773077 |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.029       |\n",
      "|    value_loss           | 3.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.83098591549296\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -162        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1179        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005798398 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.69675925925927\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -156       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 1200       |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00613596 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.16      |\n",
      "|    explained_variance   | 0.54       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.54       |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 3.29       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.57305936073058\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -149        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1224        |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005392313 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.4358108108108\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -143        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1247        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006491244 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.24555555555557\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -137         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1270         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061178952 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0323      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.05043859649123\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -131         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1292         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073709637 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0296      |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.80844155844156\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -126       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 1313       |\n",
      "|    total_timesteps      | 78848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00682185 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.2       |\n",
      "|    explained_variance   | 0.504      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.39       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 3.48       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.53311965811966\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -120         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1332         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060148095 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 3.44         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.2331223628692\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -115         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1355         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050731343 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.22         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0273      |\n",
      "|    value_loss           | 3.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.921875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1375         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059964755 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.031       |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.60802469135803\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1398        |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006558858 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.72        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.27845528455285\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -99.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1419         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057224156 |\n",
      "|    clip_fraction        | 0.0929       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.16        |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    value_loss           | 3.56         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.95983935742973\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -95.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1441         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063638804 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.60218253968253\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -91          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1462         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051751705 |\n",
      "|    clip_fraction        | 0.0805       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.24705882352941\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -86.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1484        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006306703 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.88081395348837\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -82.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1507         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072003845 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.9          |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.50670498084293\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -77.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1527        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007411613 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.11174242424244\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -73.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1550         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060360115 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0309      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.71067415730337\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -69.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1571         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058782236 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.94        |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.2925925925926\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -65.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1592        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006391617 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.87912087912088\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -61.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1613        |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006918471 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.4356884057971\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -57.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1636         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075514372 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.94         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0308      |\n",
      "|    value_loss           | 3.36         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.99462365591398\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -54.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1656         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057759923 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.86         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 3.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.56826241134752\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -51.2     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 94        |\n",
      "|    time_elapsed         | 1678      |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0076492 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.02     |\n",
      "|    explained_variance   | 0.495     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.59      |\n",
      "|    n_updates            | 930       |\n",
      "|    policy_gradient_loss | -0.0332   |\n",
      "|    value_loss           | 3.37      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.1140350877193\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -48.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1700         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056010215 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0327      |\n",
      "|    value_loss           | 3.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.62760416666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -45.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1721         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057370476 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.81         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0308      |\n",
      "|    value_loss           | 3.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.13659793814432\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -42.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1743         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064098593 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0307      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.6734693877551\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -40.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1766         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063703605 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0371      |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.17676767676767\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -38.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 1787         |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065931715 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.6625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -37.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1808         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070223114 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.57         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 57.88\n",
      "Overall Average Successful Assignments: 151.39294183475852\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f637a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -376.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.083333333333334\n",
      "All assignments history: [17, 8, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -375     |\n",
      "| time/              |          |\n",
      "|    fps             | 52       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -340.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008592821 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | -0.157      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.99        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -378.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.055555555555557\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007637595 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | -0.152      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -266.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.666666666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008612289 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | -0.0803     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.9         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 9.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -224.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.333333333333336\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -368         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086808335 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | 0.0164       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.14         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0406      |\n",
      "|    value_loss           | 7.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.388888888888886\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008455342 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | 0.0265      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.43        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 7.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -188.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.57142857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008935481 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 6.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -194.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 58.854166666666664\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -368         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103711365 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0.00731      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0424      |\n",
      "|    value_loss           | 5.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -200.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 61.851851851851855\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010257781 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | -0.000348   |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.764       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 4.62        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 65.275\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009334944 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0135      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 4.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 68.35606060606061\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010966956 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.903       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 72.44444444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011872893 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00881     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.769       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 76.3974358974359\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -363       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 265        |\n",
      "|    total_timesteps      | 13312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01547665 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.77      |\n",
      "|    explained_variance   | 0.00345    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | -0.0984    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0493    |\n",
      "|    value_loss           | 2.78       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 80.32142857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012772763 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00614     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.744       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 83.77222222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014545677 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00717     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 86.94791666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011570144 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.603       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 89.79411764705883\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010028315 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0974      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 92.64814814814815\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011535957 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 95.39035087719299\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 384         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010328863 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.92        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 98.68333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010539939 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.457       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 102.30555555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009002307 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.62       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.493       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.23484848484848\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009106627 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.328       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.34420289855072\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008493522 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 111.46180555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009231034 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.428       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 114.38\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008433135 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.51       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.02        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 117.18589743589743\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -347       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 518        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00809734 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.48      |\n",
      "|    explained_variance   | 0.206      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.557      |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0413    |\n",
      "|    value_loss           | 2.98       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 119.9320987654321\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008122299 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.44       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.383       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 122.54166666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -343       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 557        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00865604 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.36      |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.743      |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0438    |\n",
      "|    value_loss           | 2.95       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.89942528735632\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 577         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008596454 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.394       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.20277777777778\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007075929 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.801       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.36021505376345\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007359688 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.42708333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007246917 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.973       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.35353535353536\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007643381 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.75        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.21323529411765\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -327        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008605367 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.88       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.694       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.97142857142856\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 692         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008489553 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.801       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.72453703703704\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -321      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 51        |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 711       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0080896 |\n",
      "|    clip_fraction        | 0.179     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -4.67     |\n",
      "|    explained_variance   | 0.179     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.01      |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -0.0473   |\n",
      "|    value_loss           | 3.09      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.3400900900901\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -318         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 730          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077253813 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.62        |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.98245614035088\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -315        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 747         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008029692 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 3.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.5897435897436\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -311        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008221749 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.47       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.508       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.15416666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -308        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 784         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007209544 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.6138211382114\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -304        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008242225 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.02380952380952\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -301        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 821         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008394945 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.827       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.35852713178295\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -298         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 840          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072569167 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.11        |\n",
      "|    explained_variance   | 0.198        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    value_loss           | 3.45         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.64962121212122\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -294         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 859          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073302044 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.04        |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 3.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.88888888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -291         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 878          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072660856 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.05        |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.05615942028984\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -287         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 897          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058099986 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.03        |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.12765957446808\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -284       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 915        |\n",
      "|    total_timesteps      | 48128      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00795805 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.97      |\n",
      "|    explained_variance   | 0.327      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.25       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 2.82       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.23958333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 934         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007071105 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.3095238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -278        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 952         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006918925 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.37333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -274        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 971         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006218126 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.93        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.41830065359477\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -269        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005408734 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.49198717948718\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -264        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 1006        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006521479 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.50943396226415\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -259       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 1024       |\n",
      "|    total_timesteps      | 54272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00626854 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.84      |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.34       |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 2.74       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.47685185185185\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -254        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1043        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006044778 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.46060606060607\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -249        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1062        |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006418272 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.42410714285714\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -243         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 1082         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065082447 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.7         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.832        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 2.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.3654970760234\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -238         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1101         |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062761633 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.64        |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.26724137931035\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -232         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1119         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055095926 |\n",
      "|    clip_fraction        | 0.0824       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.59        |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.16949152542372\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -227       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 1138       |\n",
      "|    total_timesteps      | 60416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00643123 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.61      |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.01       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 2.81       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.0847222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -221        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005562231 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.0054644808743\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -216         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1175         |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073017655 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.61        |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.9018817204301\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -211        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1194        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006770054 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.74603174603175\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -206       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 1213       |\n",
      "|    total_timesteps      | 64512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00687074 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.59      |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.19       |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 2.96       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.57682291666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -201        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006227777 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.38846153846154\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -195        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1250        |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007183795 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.864       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.17171717171718\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -190        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1269        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006858385 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.97885572139305\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -185         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1289         |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072983066 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.77083333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -180        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1306        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007509545 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.5096618357488\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -175        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1324        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006641016 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.27023809523808\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -170         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 1341         |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060054837 |\n",
      "|    clip_fraction        | 0.0949       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.55        |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0336      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.98474178403757\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -165        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1359        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006715635 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.69560185185185\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -161         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1377         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057131713 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.42465753424656\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -155         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1394         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058268933 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.14527027027026\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -150        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1412        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005917608 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.716       |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.82111111111112\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -146        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1429        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005482299 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.48245614035088\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -141         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1447         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073851845 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.41        |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.1417748917749\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -137        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1465        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005673437 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.79807692307693\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -133         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1482         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058228215 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.43248945147678\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -129         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1499         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059898566 |\n",
      "|    clip_fraction        | 0.0995       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.47        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0323      |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.02708333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -125         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1517         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067686187 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.49        |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.65637860082305\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -121         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1535         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067890803 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0359      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.265243902439\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -118         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1553         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064318413 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.88253012048193\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -115         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1570         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076946253 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.54        |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.992        |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.48015873015873\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1588        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005677621 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.08137254901962\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1605         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077144084 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0424      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.6453488372093\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1622        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006237721 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.81        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.21072796934865\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -104         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1640         |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066528674 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.77462121212122\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -101        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1658        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007650405 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.31554307116104\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -99.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1674         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065101115 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 2.68         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.8388888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -97.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1691        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007317531 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.34615384615384\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -95.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1708        |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006012788 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.8360507246377\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -94.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1726         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065306993 |\n",
      "|    clip_fraction        | 0.0965       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.29749103942652\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -92.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1743        |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007612965 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.963       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.77482269503545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -91.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1761        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005936704 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.25877192982455\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -90.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1777         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065209474 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0381      |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.71354166666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -89.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1795        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007759608 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.17611683848799\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -87.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1812        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005468254 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.62244897959184\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -86.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 98        |\n",
      "|    time_elapsed         | 1829      |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0064821 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.43     |\n",
      "|    explained_variance   | 0.435     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.44      |\n",
      "|    n_updates            | 970       |\n",
      "|    policy_gradient_loss | -0.04     |\n",
      "|    value_loss           | 3.24      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.08333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -85.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1846        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006335494 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.54083333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -84.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1864        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006897979 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 18.0\n",
      "Overall Average Successful Assignments: 141.94448229378392\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f889986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -380.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 11.0\n",
      "All assignments history: [17, 15, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -368     |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -258.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.208333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008145361 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | -0.0981     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 4.04        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 67.27777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007705135 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | -0.113      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.9         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 83.5625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008043985 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | -0.0381     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.9\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008374928 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | -0.0126     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 9.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.48611111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008891536 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | -0.00779    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.23        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 8.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 100.36904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008800615 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.00937     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 7.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.59375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009270734 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.00525     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 5.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 112.58333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009580351 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | -0.00281    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 4.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 119.1\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -365      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 58        |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 174       |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0100648 |\n",
      "|    clip_fraction        | 0.184     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -5.8      |\n",
      "|    explained_variance   | 0.0048    |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 0.51      |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -0.0423   |\n",
      "|    value_loss           | 4.23      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.56818181818181\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010049067 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00738     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.882       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 3.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.1875\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -361       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 209        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01225728 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.77      |\n",
      "|    explained_variance   | 0.004      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.69       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.049     |\n",
      "|    value_loss           | 3.08       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.93589743589743\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -361         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 13312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121020805 |\n",
      "|    clip_fraction        | 0.246        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.00512      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.44         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0449      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.14285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011840674 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00491     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0249     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.9611111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014567003 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00583     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.47916666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013223365 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0115      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.996       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.36274509803923\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -357       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 17408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01158911 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.72      |\n",
      "|    explained_variance   | 0.0758     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.0857     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0472    |\n",
      "|    value_loss           | 2.82       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.96296296296296\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011170417 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.3640350877193\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008672375 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.567       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.3625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008039484 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.22222222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008263191 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.62       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.4         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.97348484848484\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -351       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 381        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00784317 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.59      |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.8        |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0384    |\n",
      "|    value_loss           | 3.12       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.481884057971\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -349       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 398        |\n",
      "|    total_timesteps      | 23552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00803108 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.55      |\n",
      "|    explained_variance   | 0.182      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.37       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0427    |\n",
      "|    value_loss           | 2.96       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.03819444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009250115 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.14        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.45666666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008550446 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.38        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.96794871794873\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008964615 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.43       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.17        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0466     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.41358024691357\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008655243 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.82738095238096\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008080396 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.265       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.18103448275863\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007963407 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.27       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.579       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.46944444444443\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009245481 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.22       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.625       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.61827956989248\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -331         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 536          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077601643 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0443      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.7265625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 553         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009290963 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.71212121212122\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008095272 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.658       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.65196078431373\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -322        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 587         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008176582 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.85       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0492     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.57142857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -319        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008348577 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.75       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.489       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 2.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.46759259259258\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 621         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006943389 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.554       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.34234234234233\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -313        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 639         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007240773 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.819       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.15350877192984\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007731453 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.54       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.94444444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007092222 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.835       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.76875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 691          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063625257 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.41        |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.881        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0413      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.52845528455285\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 709         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006952616 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.9         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.28373015873015\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -296        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 726         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008119231 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.91        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.11434108527132\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -292         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 743          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071074553 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.041       |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.9090909090909\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -289       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 761        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00761362 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.09      |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.967      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0441    |\n",
      "|    value_loss           | 3.03       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.7074074074074\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -285         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 779          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064441725 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.03        |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.83         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.46014492753622\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -282         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 797          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068787383 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.96        |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.3386524822695\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -278        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 814         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007638109 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.28472222222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -274         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 832          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062368456 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.88        |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.975        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.08503401360545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -271        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006940552 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.92\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -267         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 867          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073204166 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.82        |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.796        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.76960784313727\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -262        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006776995 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.66506410256412\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -256         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 901          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067710085 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.84        |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.55345911949686\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -251      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 53        |\n",
      "|    time_elapsed         | 919       |\n",
      "|    total_timesteps      | 54272     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0061987 |\n",
      "|    clip_fraction        | 0.111     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.8      |\n",
      "|    explained_variance   | 0.601     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 0.868     |\n",
      "|    n_updates            | 520       |\n",
      "|    policy_gradient_loss | -0.0422   |\n",
      "|    value_loss           | 2.83      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.4783950617284\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -246         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 936          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056732316 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 3.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.45606060606062\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -241         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 954          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088641085 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.81        |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.48065476190476\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -235       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 972        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00600709 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.76      |\n",
      "|    explained_variance   | 0.501      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.922      |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0399    |\n",
      "|    value_loss           | 2.66       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.43421052631578\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -229        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 989         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006091937 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.38362068965517\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -224         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1007         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058598863 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.67        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.34322033898306\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -218         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 1024         |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057298103 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.28333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -212         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 1042         |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063527683 |\n",
      "|    clip_fraction        | 0.0923       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.032       |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.15573770491804\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -207        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1059        |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006930627 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.996       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.04166666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -202         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1077         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064073964 |\n",
      "|    clip_fraction        | 0.0968       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.8968253968254\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -196       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 1094       |\n",
      "|    total_timesteps      | 64512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00611679 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.57      |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.34       |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0398    |\n",
      "|    value_loss           | 3.05       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.71354166666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -191         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1113         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063900063 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.5871794871795\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -184         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1130         |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059107454 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.51        |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.41287878787878\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006336745 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.98        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.1679104477612\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -173         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1165         |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052604256 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.47        |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0326      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.90196078431373\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -167        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1183        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005553674 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.57608695652175\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -162         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 1200         |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059770793 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.52         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.2904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -157        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1217        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006114715 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.956       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.0117370892019\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -151         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 1235         |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055773035 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.72569444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -146        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1252        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005759973 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.846       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.43835616438355\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -140        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1268        |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005761346 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.1283783783784\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -135         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1285         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053719934 |\n",
      "|    clip_fraction        | 0.0745       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0306      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.75444444444443\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -130         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1303         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061810273 |\n",
      "|    clip_fraction        | 0.0999       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0311      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.37609649122808\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -125        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1321        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007236004 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.03571428571428\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -120        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1338        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005248792 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.64957264957266\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -116        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1355        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006203485 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.26371308016877\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -111         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1373         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064419224 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.88958333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1389        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006095282 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.91        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.51234567901236\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1407        |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005610957 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.871       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.08739837398375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -98         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1424        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005644599 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.679718875502\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -93.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1441         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050321305 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0327      |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.25\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1459        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005588134 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.83039215686276\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -86.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1475         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064729606 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.915        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.4156976744186\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -82.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1492        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005873613 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.9750957854406\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -79.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1512         |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053372714 |\n",
      "|    clip_fraction        | 0.0888       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0311      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.53219696969697\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -76          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1531         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057619037 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.903        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0289      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.0823970037453\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -72.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1550        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005876829 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.62037037037038\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -69.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1569         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061754202 |\n",
      "|    clip_fraction        | 0.0974       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.63         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0275      |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.15018315018315\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -66.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1588        |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006338942 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.65670289855072\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -64          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1606         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069526145 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.13620071684588\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -61.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1626        |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006611862 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.61258865248226\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -60.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1644        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005407801 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.0842105263158\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -57.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1663         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060233204 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.036       |\n",
      "|    value_loss           | 3.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.54861111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -55.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1681         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056442884 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0307      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.99484536082474\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -53.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1699        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006068525 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.44727891156464\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -52.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1717        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005971286 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.8804713804714\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -50.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 1735         |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061030732 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.27166666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -49.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1754         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065556727 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.56         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 75.56\n",
      "Overall Average Successful Assignments: 175.30661773959324\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a13b0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -392.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 5.0\n",
      "All assignments history: [12, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -380     |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -314.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.416666666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -378        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008110204 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -380.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.916666666666668\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -375       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00810842 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.87      |\n",
      "|    explained_variance   | -0.222     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.44       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -388.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.208333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -375        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009367506 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0.00402     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 9.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -382.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.0\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -376         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082616005 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | 0.011        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.99         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 8.51         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -380.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.527777777777779\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008020364 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.28        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 7.63        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -304.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.761904761904763\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008776843 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.00724    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 6.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -270.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.635416666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009101767 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 6.53e-05    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 4.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.44444444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009381037 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.00461    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 4.55        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.56666666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -369       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00998069 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.82      |\n",
      "|    explained_variance   | 0.00159    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.658      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 3.64       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 62.95454545454545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010896931 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.00281     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.27        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 72.78472222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010875132 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00658     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0631     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 81.12820512820512\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013710073 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00397     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.87        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.6547619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013500881 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00334     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 95.03333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013953209 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00616     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.601       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 100.65625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012018984 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.678       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.69607843137256\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011202542 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0414      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 110.17129629629629\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009444494 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0674      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.576       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 114.1140350877193\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010303822 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.469       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 117.7875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008668503 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.25        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 121.3452380952381\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008122066 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.81        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.63636363636364\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008409215 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.27173913043478\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008111458 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.98958333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 441         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009615804 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.85        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.55333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008244289 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.395       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.80128205128204\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -350         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 478          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078507485 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.48        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.918        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0406      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.93827160493828\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009086177 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.41       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.801       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.0625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -346         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 516          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068114577 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.35        |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.434        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 3.19         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.00862068965517\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -343         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 534          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075181713 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.3         |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.835        |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.88055555555556\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -341         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 553          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082028825 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.22        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.49         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0426      |\n",
      "|    value_loss           | 2.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.56182795698925\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006906847 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.16       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.654       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.18489583333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 590         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007076961 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.09       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.95        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.65151515151516\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -333         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 609          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074098236 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.685        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.11764705882354\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -330       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 628        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00777787 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.92      |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.19       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 3.35       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.50238095238095\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -326       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 646        |\n",
      "|    total_timesteps      | 35840      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00785325 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.81      |\n",
      "|    explained_variance   | 0.409      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.675      |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0445    |\n",
      "|    value_loss           | 3.3        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.84722222222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -323         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 665          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076341406 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.747        |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0444      |\n",
      "|    value_loss           | 3.19         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.13288288288288\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -319        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 683         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007976746 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.2828947368421\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 702         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006992306 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.57       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.3803418803419\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -313         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 720          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079009915 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.49        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0463      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.525\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -310         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 739          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082236305 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.41        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.974        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0454      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.65650406504065\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -306         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 758          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071474314 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.3         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.976        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0464      |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.7420634920635\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -303       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 777        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00671835 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.23      |\n",
      "|    explained_variance   | 0.538      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.24       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    value_loss           | 3.11       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.89922480620154\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008360025 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.903       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.0719696969697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -296        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 812         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008757038 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.995       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.28703703703704\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -293        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009153395 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0482     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.55253623188406\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -289        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 847         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008938648 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.875       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.75886524822695\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 865         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007977351 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.00173611111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -283        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 882         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813114 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.30102040816325\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -279         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 899          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069238674 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.50833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -276        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 914         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007874241 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.839       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.7107843137255\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -271         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 933          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064540035 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.89        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.92307692307693\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -266        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 951         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008163977 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.08647798742138\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -261       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 969        |\n",
      "|    total_timesteps      | 54272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00681809 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.83      |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.06       |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 3.35       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.28703703703704\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -255        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 988         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006396249 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.4530303030303\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -250         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 1007         |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069128824 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.77        |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.58333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -244        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1026        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006331347 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.7061403508772\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -238        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1044        |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006729238 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.75574712643677\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -233         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1063         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065588695 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.64        |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0406      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.79661016949152\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -227        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007451773 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.929       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.77083333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -222         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 1099         |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060564745 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.6         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.77322404371586\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -216        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1117        |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006248857 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 3.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.71774193548387\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -211         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1136         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064231725 |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.51        |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.6468253968254\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -205        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1154        |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005937334 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.58984375\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -200      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 64        |\n",
      "|    time_elapsed         | 1173      |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0050607 |\n",
      "|    clip_fraction        | 0.0843    |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.43     |\n",
      "|    explained_variance   | 0.44      |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.02      |\n",
      "|    n_updates            | 630       |\n",
      "|    policy_gradient_loss | -0.0311   |\n",
      "|    value_loss           | 3.01      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.51666666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -193        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1192        |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005753202 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.41666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -188         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 1209         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066670645 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.25\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -182         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1228         |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053829225 |\n",
      "|    clip_fraction        | 0.0861       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.06495098039215\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -176        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1247        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005517235 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.89371980676327\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -170        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1265        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005391732 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.6904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -165        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1284        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006364683 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.5082159624413\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -159         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 1303         |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049492572 |\n",
      "|    clip_fraction        | 0.0801       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.31944444444446\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -153         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1322         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061010765 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.10616438356163\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -147         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1340         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063127726 |\n",
      "|    clip_fraction        | 0.0942       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.29        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0298      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.86148648648648\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -142         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1360         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062728487 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.29        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.59555555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -137        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1379        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005165943 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.3640350877193\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -131         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1397         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061163465 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0323      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.12445887445887\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -126        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1415        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006165848 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.86324786324786\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -121        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1434        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005980946 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.61181434599155\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -116        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1453        |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007313692 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.31979166666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1471         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048548174 |\n",
      "|    clip_fraction        | 0.0836       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0298      |\n",
      "|    value_loss           | 3.48         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.99588477366254\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -107         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1490         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060179606 |\n",
      "|    clip_fraction        | 0.099        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0316      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.6910569105691\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -103         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1508         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064549977 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.999        |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0332      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.3714859437751\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -98.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1527         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054034814 |\n",
      "|    clip_fraction        | 0.0837       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.0515873015873\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -94.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1547         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062873634 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.70490196078433\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -90.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1567         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050851507 |\n",
      "|    clip_fraction        | 0.0956       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.64         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0324      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.32558139534885\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -86.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1585         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070793605 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.9434865900383\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -83.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1603         |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062138885 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.55397727272728\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -79.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1622         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056533962 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 3.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.15074906367042\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -76.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1641         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054278267 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.03        |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.73611111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -73.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1659        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005363147 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 3.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.3150183150183\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -70.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1676        |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006403055 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.08       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.89764492753622\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -67.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1694         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064988574 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0275      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.46326164874552\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -64.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1711        |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006974088 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.9964539007092\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -62.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1728        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006700885 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.57719298245615\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -59.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1745         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061348956 |\n",
      "|    clip_fraction        | 0.0948       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0315      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.14670138888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -57          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1762         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072074146 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0311      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.6890034364261\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -55         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1780        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006306171 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.22534013605443\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -52.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1797        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006426589 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.763468013468\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -50.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 1814         |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050332034 |\n",
      "|    clip_fraction        | 0.0741       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.06         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.28583333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -48.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1831         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050776075 |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    value_loss           | 3.85         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 52.34\n",
      "Overall Average Successful Assignments: 152.1810413276932\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0da3262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -388.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.333333333333333\n",
      "All assignments history: [18, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -372     |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -316.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.333333333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008061668 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.82        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -276.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.888888888888886\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007893557 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | -0.188      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.14        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -196.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.395833333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007529198 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | -0.0738     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.17        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 56.7\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -372         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073729097 |\n",
      "|    clip_fraction        | 0.0976       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.86        |\n",
      "|    explained_variance   | -0.0682      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.43         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 9.7          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 68.93055555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008667234 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | 0.000854    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.98        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 7.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 77.95238095238095\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008893466 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.00076    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 6.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.4375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008931147 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.00362     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 5.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 93.81481481481481\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009007182 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.00203    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 5.07        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.54166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010368078 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.00458     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.655       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 4.24        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 99.17424242424242\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -369       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01105769 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.8       |\n",
      "|    explained_variance   | 0.00554    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.41       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0428    |\n",
      "|    value_loss           | 3.81       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 102.29861111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010212011 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00475     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 107.41666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011628883 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00514     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 111.32142857142857\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -366         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141722625 |\n",
      "|    clip_fraction        | 0.275        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.00921      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.27         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0471      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.20555555555555\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012563375 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.227       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 120.63541666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012419097 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0723      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.736       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.56862745098039\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012791045 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0525     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.42592592592592\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011289533 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.97368421052633\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010387147 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.10833333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009471807 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0252      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.17460317460316\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008131801 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.79166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 393         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009797028 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.95289855072463\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007981483 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.593       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.85069444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008194171 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.888       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.88\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007879809 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.61       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.941       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.61858974358975\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -353       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00796575 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.58      |\n",
      "|    explained_variance   | 0.289      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.295      |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 2.95       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.3179012345679\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007428789 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.87        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.9047619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 502         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008052196 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.923       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.3793103448276\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008429028 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.44       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.8361111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 539         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008368958 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.858       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.16666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009181432 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.32       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.355       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.5234375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008238976 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.25       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.80555555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007743141 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.719       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.06127450980392\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -334         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 612          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077776397 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.609        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0445      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.27857142857144\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -332         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 630          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077715996 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.05        |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.895        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0466      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.3773148148148\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009368507 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.918       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.46396396396398\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -327         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 666          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083904965 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.88        |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.825        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0477      |\n",
      "|    value_loss           | 2.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.515350877193\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008001627 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.624       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.62820512820514\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -320         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 703          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076174526 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.72        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0426      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.63333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008377565 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.991       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.6158536585366\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -314        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 739         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008311185 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.61309523809524\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -311       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 757        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00847897 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.47      |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.994      |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0493    |\n",
      "|    value_loss           | 2.88       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.71317829457365\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -308        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008001264 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.39       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.797       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.77272727272728\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -305       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 794        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00664393 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.33      |\n",
      "|    explained_variance   | 0.22       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.43       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0423    |\n",
      "|    value_loss           | 2.87       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.8148148148148\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -301         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 812          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070727933 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.28        |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0415      |\n",
      "|    value_loss           | 3.56         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.98007246376812\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -298         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 831          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074473266 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.24        |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.972        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.1755319148936\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -295        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007752862 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.39409722222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -292         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 866          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077995793 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.12        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.043       |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.6156462585034\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -289         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 883          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074986536 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.09        |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.045       |\n",
      "|    value_loss           | 3.42         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.86\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007033619 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.0702614379085\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008076966 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.29647435897436\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -275         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 933          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063444884 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.973        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0432      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.50157232704402\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -270         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 951          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069488953 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.6820987654321\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -265         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 969          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068373596 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.84        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.766        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0402      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.86666666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -260       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 988        |\n",
      "|    total_timesteps      | 56320      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00827006 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.84      |\n",
      "|    explained_variance   | 0.247      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.14       |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    value_loss           | 2.87       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.02529761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -254        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005911805 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.14912280701753\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -249         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1018         |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064509925 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.7         |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0396      |\n",
      "|    value_loss           | 2.74         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.2255747126437\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -243         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1034         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054948423 |\n",
      "|    clip_fraction        | 0.0939       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.25282485875707\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -237         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 1051         |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071885274 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.27777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -232        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006468421 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.29918032786884\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1083        |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005854857 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.30510752688173\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -219         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1100         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077306563 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.56         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.2314814814815\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -214       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 1115       |\n",
      "|    total_timesteps      | 64512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00640865 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.39      |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.53       |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 3.11       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.16145833333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -208        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1131        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006166745 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.11282051282052\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -202         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1147         |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064711925 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.42         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.03787878787878\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -196         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 1164         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063147615 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.94776119402985\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -189        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1180        |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005261601 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.985       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.8308823529412\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -183         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1195         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056944815 |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.7173913043478\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1212        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006091984 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.58690476190475\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -171        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1228        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006358724 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.892       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.4049295774648\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -165         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 1243         |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070061823 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.22685185185185\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -159        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1260        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005302403 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.02625570776254\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -153        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1276        |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004860128 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.79054054054055\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -147         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1292         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061397823 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.54555555555555\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -141         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1308         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069610737 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.2686403508772\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -135         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1324         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051636053 |\n",
      "|    clip_fraction        | 0.0985       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.06        |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.00757575757575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -129        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1340        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005776217 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.73183760683762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -124        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1357        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005605161 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 3.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.42088607594937\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -118         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1372         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068888413 |\n",
      "|    clip_fraction        | 0.0994       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0289      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.12604166666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1388         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051827366 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.95        |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0316      |\n",
      "|    value_loss           | 3.67         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.84156378600824\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -107         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1405         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055494127 |\n",
      "|    clip_fraction        | 0.0885       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.97        |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0278      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.5518292682927\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -101         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1421         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064639854 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.031       |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.22289156626505\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -96.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1436         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050317775 |\n",
      "|    clip_fraction        | 0.0977       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.94        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0299      |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.87400793650792\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -91.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1453        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008463295 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.5235294117647\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -86.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1469        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006339686 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.1918604651163\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -81.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 1485       |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00545019 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.9       |\n",
      "|    explained_variance   | 0.516      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.24       |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 3.5        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.80938697318007\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -76.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1501        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005505669 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.42992424242425\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -72.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1515         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066826297 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.978        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.04400749063672\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -68.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1530        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006460469 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.64444444444445\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -64.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005390888 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.22893772893772\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -60.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1562         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052188216 |\n",
      "|    clip_fraction        | 0.0887       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0293      |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.78079710144928\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -56.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1576         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057051373 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.63         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0323      |\n",
      "|    value_loss           | 3.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.33333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -52.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1589         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052792085 |\n",
      "|    clip_fraction        | 0.0887       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.52         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.86170212765958\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -49.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1603         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058493256 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.38771929824563\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -45.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 1617       |\n",
      "|    total_timesteps      | 97280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00572467 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.76      |\n",
      "|    explained_variance   | 0.569      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.04       |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 3.22       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.93315972222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -41.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1631         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061223023 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0311      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.45103092783506\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -38.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1644         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065255407 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.75        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0334      |\n",
      "|    value_loss           | 3.36         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.9421768707483\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -35.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1658         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060909614 |\n",
      "|    clip_fraction        | 0.0973       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0294      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.4503367003367\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -32.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 1672         |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072360886 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0321      |\n",
      "|    value_loss           | 3.63         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.95083333333332\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -29.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 1686       |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00646118 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.81      |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.5        |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    value_loss           | 3.22       |\n",
      "----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 74.54\n",
      "Overall Average Successful Assignments: 166.54753152220866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b30266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -388.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.666666666666667\n",
      "All assignments history: [18, 14, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -368     |\n",
      "| time/              |          |\n",
      "|    fps             | 84       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -364.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.333333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008186003 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | -0.0287     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.7         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -366.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.88888888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 77           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071003446 |\n",
      "|    clip_fraction        | 0.0846       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | 0.0493       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.17         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.520833333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008509245 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 9.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 62.083333333333336\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -367       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 75         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 5120       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00854785 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.86      |\n",
      "|    explained_variance   | 0.00894    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.86       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    value_loss           | 8.29       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 75.375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -367         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085222395 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | 0.0128       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.15         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 7.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 86.3452380952381\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -367         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075077023 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | 0.00919      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 6.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 94.75\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008455416 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.00728     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 5.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 101.36111111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010350147 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.00362     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 4.73        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 106.69166666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -365         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094745755 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | 0.00329      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.675        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 3.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 111.78030303030303\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010142315 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.00527     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.09027777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011391364 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00347     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 119.91666666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -363       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 75         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 176        |\n",
      "|    total_timesteps      | 13312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01323225 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.78      |\n",
      "|    explained_variance   | 0.00324    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.39       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0473    |\n",
      "|    value_loss           | 2.74       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 122.99404761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014562845 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0047      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.86666666666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -360       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 74         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01398137 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.77      |\n",
      "|    explained_variance   | 0.0111     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.13       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 2.88       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.78645833333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012921588 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0318      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0516     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.83333333333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -358       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 74         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 232        |\n",
      "|    total_timesteps      | 17408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00944136 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.75      |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.45       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 2.76       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.4814814814815\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009671427 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.502       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.05701754385964\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008358531 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.44166666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -355         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092578605 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0.236        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0425      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.54365079365078\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008442637 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.82        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.60227272727272\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008680777 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.78623188405797\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009543233 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.79513888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008574432 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.70333333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008757136 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.35576923076923\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -346        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008848988 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.46       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.33        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.89197530864197\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -344         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073691467 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.42        |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.54761904761904\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008812464 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.16954022988506\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009202858 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.31       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.69722222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008253545 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.25       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.09408602150538\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006847566 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.18       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.546875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -332         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 442          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084654875 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.11        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0452      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.81565656565655\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008543458 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.1299019607843\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -327        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008513044 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.4404761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -324        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008542334 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.57638888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -322        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008024979 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.81306306306305\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -319        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007965315 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.0328947368421\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008446599 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.995       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.26709401709402\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008604843 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.59       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.45\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 557         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008861694 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.6117886178862\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -305        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008570638 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.46       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.73214285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 585          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074879536 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.39        |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0421      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.8875968992248\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -298       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 73         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 599        |\n",
      "|    total_timesteps      | 44032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00840449 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.3       |\n",
      "|    explained_variance   | 0.316      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.12       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    value_loss           | 2.94       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.00757575757575\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -295         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 612          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088952705 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.23        |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0453      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.13518518518518\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -292        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008271638 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.30615942028984\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -288        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009073372 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.4787234042553\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008160658 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.61631944444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007777974 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.7908163265306\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -279        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007773915 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.96166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -276        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 696         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008623855 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.13888888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -271        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 712         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008067304 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.35576923076923\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -266         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 728          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072971205 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.4748427672956\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -261        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006737998 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.63888888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -256         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 755          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082410835 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.84        |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.76818181818183\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -250        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 769         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006255418 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.88244047619048\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -245        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 784         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006563721 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.93859649122808\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -239         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 816          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074633034 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.76        |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.967        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.9712643678161\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -234         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 830          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066449977 |\n",
      "|    clip_fraction        | 0.0961       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.74        |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.9689265536723\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -228         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 843          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057224417 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.68        |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.912        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.93055555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -223         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 855          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062649995 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.89890710382514\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -217         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 869          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056885583 |\n",
      "|    clip_fraction        | 0.0895       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.85         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.81182795698925\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -212        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 882         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006337099 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.70634920634922\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -206         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 895          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065968717 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.51        |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.5859375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 907          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055812774 |\n",
      "|    clip_fraction        | 0.0889       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0346      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.42179487179487\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -195        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 921         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006552415 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.25631313131314\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -189         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 937          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062225256 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.036       |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.02985074626866\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -184        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 950         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007827856 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.7781862745098\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -178        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 966         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006222254 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.4987922705314\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -173         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 980          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059476523 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.19880952380953\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -167        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 997         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006811128 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 3.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.91901408450704\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -162       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 71         |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 1012       |\n",
      "|    total_timesteps      | 72704      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00550846 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.37      |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.36       |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.0346    |\n",
      "|    value_loss           | 3.53       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.64699074074073\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -156        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1025        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005909512 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 3.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.3584474885845\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -151         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1040         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058931294 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.08333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -146         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1056         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065692402 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.7577777777778\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -141         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1070         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065608933 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 3.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.43859649122808\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -136        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1083        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005690186 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.08225108225108\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -131         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 1097         |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060584084 |\n",
      "|    clip_fraction        | 0.0989       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0335      |\n",
      "|    value_loss           | 3.73         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.7136752136752\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -125         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1111         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051418124 |\n",
      "|    clip_fraction        | 0.0992       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 3.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.30379746835442\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -121        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1126        |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005550366 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.91145833333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -116         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1140         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071440726 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.94         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.51954732510288\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1154         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061047636 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0316      |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.0630081300813\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -107         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1168         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055261776 |\n",
      "|    clip_fraction        | 0.0941       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0283      |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.61947791164658\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1181        |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005834085 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 3.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.16765873015873\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -99.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1194         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070165675 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.978        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0381      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.70098039215685\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -95.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1207         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068843765 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.68         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 3.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.25387596899225\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -91.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1220        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005590679 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.77011494252875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -87.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1233        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006520572 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.2964015151515\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -84.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1246         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056240447 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0332      |\n",
      "|    value_loss           | 3.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.7631086142322\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -81.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1259        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006086274 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 3.82        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.2324074074074\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -78.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1271        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005624253 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.99        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.6831501831502\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -75.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1285         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069945995 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0285      |\n",
      "|    value_loss           | 3.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.1213768115942\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -72.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1297         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066489913 |\n",
      "|    clip_fraction        | 0.0933       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.5331541218638\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -70.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1310        |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007788011 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.9654255319149\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -67.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1323         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070739617 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.37719298245614\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -65.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1336         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062954985 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0327      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.81423611111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -62.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1349        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006144223 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.08       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.25257731958763\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -60.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1362        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005538175 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.91        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.67176870748298\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -58.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1376         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049558426 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.10521885521885\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -55.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1388        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006576711 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.535\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -53.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1401        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005799142 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 74.98\n",
      "Overall Average Successful Assignments: 169.62967302437065\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50166714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -384.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.25\n",
      "All assignments history: [13, 18, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -369     |\n",
      "| time/              |          |\n",
      "|    fps             | 90       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -304.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.166666666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -366         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072508883 |\n",
      "|    clip_fraction        | 0.0668       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.88        |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.31         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -232.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.583333333333336\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -368         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075164484 |\n",
      "|    clip_fraction        | 0.0965       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | 0.0936       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 12.3         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 55.729166666666664\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077296635 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | 0.0179       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 9.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -330.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.88333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007788293 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0.0213      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.27        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 9.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 60.888888888888886\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069591394 |\n",
      "|    clip_fraction        | 0.0912       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | -0.00541     |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.36         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 8.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 73.28571428571429\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087419115 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | 0.00711      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    value_loss           | 6.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 81.22916666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009019346 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.00341     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 5.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 84.04629629629629\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092625385 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.0116       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 4.7          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.64166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010260159 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0133      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.519       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 4.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.06818181818181\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010235153 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.012       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 3.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 102.16666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010573363 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00888     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.792       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 107.17948717948718\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013435823 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0117      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 112.30952380952381\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013461538 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.657       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.81666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011834485 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0455      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.301       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 120.55729166666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011327468 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.971       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.44117647058823\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009918071 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.252       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.02314814814815\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010866793 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.729       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0492     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.14473684210526\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008604648 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.09166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009460612 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.63492063492063\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008479128 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.517       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.9318181818182\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009078877 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.1159420289855\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009717692 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.841       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.27083333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009956319 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.73        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.13666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009161799 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.54       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.193       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.15064102564102\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009910397 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.904       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.96913580246914\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009520562 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.986       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.79761904761904\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -345       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 79         |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 362        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00985373 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.45      |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.922      |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0474    |\n",
      "|    value_loss           | 3.2        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.4367816091954\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009681415 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.42        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.90277777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009327427 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.349       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0491     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.4247311827957\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -340       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 79         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 399        |\n",
      "|    total_timesteps      | 31744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00977476 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.3       |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.558      |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 3.07       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.91927083333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008421185 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.24       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.922       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 3.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.32070707070707\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007825334 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.802       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.7058823529412\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008971657 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.11       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.9952380952381\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008788742 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.661       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.26157407407408\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 462         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008492637 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.4189189189189\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009508964 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.88       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.61622807017545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -322        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009628605 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.707       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.78846153846155\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009895444 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.96041666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 513         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008635301 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.0691056910569\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -314        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 525         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008598327 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.944       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.140873015873\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -311        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009405053 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.22868217054264\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -308        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009127311 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0507     |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.29545454545453\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -305        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007676797 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.31666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -301         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 574          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076560536 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.37        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0422      |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.30615942028984\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -298         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 587          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076891966 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.31        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0463      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.24290780141843\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -296        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007785029 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.18055555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -292         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 612          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071377107 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.9          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0456      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.1173469387755\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -289        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006773765 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.01333333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006257517 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.90032679738562\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -282         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 647          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056652892 |\n",
      "|    clip_fraction        | 0.0847       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.05        |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.033       |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.82852564102564\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -277         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 658          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058720033 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.04        |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.73899371069183\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -272       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 81         |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 669        |\n",
      "|    total_timesteps      | 54272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00653267 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.97      |\n",
      "|    explained_variance   | 0.535      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.33       |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 3.43       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.60956790123456\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -267        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008280109 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.4848484848485\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -262        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006257709 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.36011904761904\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -257         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 702          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062235137 |\n",
      "|    clip_fraction        | 0.0974       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.23391812865498\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -252         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 713          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064152637 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.88        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 3.54         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.1221264367816\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -246        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006987291 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.9590395480226\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -241         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 82           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 734          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065365965 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.8         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.76944444444445\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -236        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 743         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006426771 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.55464480874318\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -230         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 82           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 754          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060152244 |\n",
      "|    clip_fraction        | 0.0928       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.76        |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.036       |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.31854838709677\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 763         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006342254 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.05291005291005\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -220        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 773         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005842504 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.78125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -215        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005449762 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.52820512820512\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -210        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 791         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006978737 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.28535353535352\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -204         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 800          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060800826 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.57        |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.96641791044777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -199        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 808         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007148462 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.6764705882353\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -193         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 816          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055624275 |\n",
      "|    clip_fraction        | 0.0998       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.7          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.3599033816425\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -188         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 823          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057204333 |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.32         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.025\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -182         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 829          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066094147 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.67018779342723\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -177         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 835          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063833864 |\n",
      "|    clip_fraction        | 0.0879       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 4.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.34722222222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -172         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 841          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058644544 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.98059360730593\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -167         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 847          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062259585 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.37        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 3.36         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.58445945945945\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -162        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007193667 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.18\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -157        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 858         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006620411 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.77412280701753\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -152        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 864         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007000865 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.3560606060606\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -146       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 90         |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 870        |\n",
      "|    total_timesteps      | 78848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00607821 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.37      |\n",
      "|    explained_variance   | 0.498      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.97       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 3.48       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.9155982905983\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -141         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 876          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054224646 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.87         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 4.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.4409282700422\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -137        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 882         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005586721 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.94270833333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -132        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 888         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006281774 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 4.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.47942386831275\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -127        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 894         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007844751 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.98373983739836\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -123        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 899         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006824901 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.99        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.50100401606426\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -119         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 904          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051025203 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.9970238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -115        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 909         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007291478 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 3.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.48235294117646\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 913         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006752656 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.9748062015504\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -107        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 917         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007394687 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.91        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 3.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.41283524904213\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -103         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 922          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063332813 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.81         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 3.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.86363636363637\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -100         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 926          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075045023 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.3052434456929\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -96.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 930          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069458545 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0348      |\n",
      "|    value_loss           | 3.7          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.75833333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -93.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 935          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057997582 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 3.7          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.1831501831502\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 939         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006700835 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.60416666666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -88.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 943        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00635289 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.37      |\n",
      "|    explained_variance   | 0.497      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.47       |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 3.95       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.01254480286738\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -85.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 948          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059924596 |\n",
      "|    clip_fraction        | 0.0996       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.42375886524823\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -83.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 952          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072767786 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 3.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.80877192982456\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -81.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 956         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007676504 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 3.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.1875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -79.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 961          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060490957 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 4.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.5627147766323\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -77.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 965         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006594606 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.92006802721087\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -75.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 969         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005399489 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.2929292929293\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -73.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 973          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072197854 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 4.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.65916666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -71.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 978          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062136026 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.29        |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.74         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.85         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 54.18\n",
      "Overall Average Successful Assignments: 163.02333094389374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29e8aa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -376.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.333333333333334\n",
      "All assignments history: [12, 16, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -372     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -366.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.541666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008034301 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | -0.121      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.16        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -352.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.25\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007505992 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | -0.111      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -214.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.104166666666664\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008429896 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.061       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2           |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 9.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.6\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -367       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 244        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 5120       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00777517 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.86      |\n",
      "|    explained_variance   | 0.0966     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.86       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0389    |\n",
      "|    value_loss           | 8.51       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 66.90277777777777\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -366       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00830882 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.85      |\n",
      "|    explained_variance   | 0.00694    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.28       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0389    |\n",
      "|    value_loss           | 7.7        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 79.1547619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008275357 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | 0.0133      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 6.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.80208333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009331379 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.00975     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 5.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.54629629629629\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009205701 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.00263    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 5.01        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.65\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010805573 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | -0.000117   |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 112.99242424242425\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011103252 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.000695    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.395       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 118.52777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011621642 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00696     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.8076923076923\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013687912 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.859       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.0654761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015730299 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00781     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0648     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0497     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.12777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013270222 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.96875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012328859 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0614      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.719       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0514     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.42156862745097\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011411562 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.97        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.61574074074073\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010314517 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.43421052631578\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009666061 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.87916666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010384928 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.702       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0466     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.20634920634922\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008270959 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.324       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.40151515151516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008376544 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.78        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.45289855072463\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -346       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 98         |\n",
      "|    total_timesteps      | 23552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00784445 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.52      |\n",
      "|    explained_variance   | 0.307      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.7        |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 2.7        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.15625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -344         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072235498 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.48        |\n",
      "|    explained_variance   | 0.278        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.332        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.91\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008625655 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.43       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.75\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008929601 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.439       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.5030864197531\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -339         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074386667 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.35        |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.909        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.9672619047619\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -337       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00724833 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.29      |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.922      |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 3.17       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.52586206896552\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008355737 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.22       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.507       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.98055555555555\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -331         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072462284 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.56         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.41666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -327        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008160567 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.07       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.465       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.8203125\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -324       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00720818 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.01      |\n",
      "|    explained_variance   | 0.498      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.11       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 3.1        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.1818181818182\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -321        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008149054 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0469     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.42156862745097\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -318         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076205092 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.85        |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0437      |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.67142857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -315        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009023301 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.80555555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007703572 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.98423423423424\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007867172 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.877       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.12280701754386\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -305       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00807497 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.54      |\n",
      "|    explained_variance   | 0.477      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.08       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 3.19       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.22649572649573\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010342438 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0497     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.32916666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007724264 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.4288617886179\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -295         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073655155 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.33        |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.886        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.046       |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.42857142857142\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -292         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070308815 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.25        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0441      |\n",
      "|    value_loss           | 3.19         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.51356589147287\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -288        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006463861 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.899       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.5056818181818\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007339324 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.52037037037036\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007729689 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.854       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.55797101449275\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -278        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006632259 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.5336879432624\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -275        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007709879 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.58159722222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -271         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071059857 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.923        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0413      |\n",
      "|    value_loss           | 2.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.59183673469389\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -268        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007014678 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.58666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -265        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007151505 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.838       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.6356209150327\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -260         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076607876 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.8         |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.62820512820514\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -255         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059065004 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.61949685534591\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -249        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007011065 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.958       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.58024691358025\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -244         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075486805 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.964        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.4848484848485\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -239         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069241654 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.73        |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.37946428571428\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -233         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074176397 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.25438596491227\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -228         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059847925 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.73        |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.08477011494253\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -222         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 249          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067530433 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0396      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.8728813559322\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -217        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007387145 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.68194444444444\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -211         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063323467 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.47267759562843\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -205        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006009614 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.21505376344086\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006935201 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.95767195767195\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -195        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007037146 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.65364583333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -189         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 275          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067642704 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.37051282051283\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -183        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007069763 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.01641414141415\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -178         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 284          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066296943 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0335      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.6766169154229\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005941593 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.975       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.32843137254903\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -167        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006114785 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.9963768115942\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -161        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007588478 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.948       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.63333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -156        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006215534 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.898       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.22535211267606\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -150        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006942657 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.83912037037038\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -145        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006546442 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.4623287671233\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -140         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 314          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068497225 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.42         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.06306306306305\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -134         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067480137 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.66333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -129         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 322          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057319626 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.55         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.24013157894737\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -124         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051308214 |\n",
      "|    clip_fraction        | 0.0859       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.81926406926408\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -119       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 331        |\n",
      "|    total_timesteps      | 78848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00696024 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.25      |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.08       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0353    |\n",
      "|    value_loss           | 3.17       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.39529914529913\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -114        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005904494 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.95991561181435\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005810166 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.51145833333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -105         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 343          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058311634 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.03292181069958\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -101         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061767558 |\n",
      "|    clip_fraction        | 0.0996       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.16        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.5680894308943\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -96.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006089556 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 4.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.08032128514057\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -92.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 356          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055307923 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.5734126984127\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -88.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057863807 |\n",
      "|    clip_fraction        | 0.099        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.06176470588235\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -84.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060682925 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 3.45         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.58527131782947\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -80.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006652238 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.06992337164752\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -77.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069952556 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.56         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.57007575757575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -74.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007315939 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.07116104868913\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -71.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 382        |\n",
      "|    total_timesteps      | 91136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00686431 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.12      |\n",
      "|    explained_variance   | 0.506      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.45       |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | -0.0392    |\n",
      "|    value_loss           | 3.61       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.55462962962963\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -68.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 386          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056436043 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.02930402930403\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -65.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 391          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068834685 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.4519927536232\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -62.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 395          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072913747 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.8673835125448\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -60.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 399          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062481724 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.31737588652481\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -57.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005832229 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.75877192982455\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -54.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005491874 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.19184027777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -52.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 412          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062714787 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 3.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.60309278350516\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -49.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 417          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062068743 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.67         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.02295918367346\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -47.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 421          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067636333 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0317      |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.39646464646464\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -45.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 425          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061588725 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.78666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -43.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006586176 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 78.38\n",
      "Overall Average Successful Assignments: 173.97123602439592\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54aded7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -392.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 5.5\n",
      "All assignments history: [16, 10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -374     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -252.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008103466 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | -0.256      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.1         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -376.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.055555555555557\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -375         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072903335 |\n",
      "|    clip_fraction        | 0.0938       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -338.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.520833333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007982947 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.13        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.81666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007946499 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0.0741      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.39        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 8.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.041666666666664\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007936692 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | -0.00604    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 7.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 63.57142857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008079598 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | -0.0239     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 6.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 74.69791666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009174637 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.00254     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.877       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 5.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 83.00925925925925\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -369       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00920325 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.83      |\n",
      "|    explained_variance   | 0.00375    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.736      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 4.72       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 90.11666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009897721 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.00651     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.15151515151516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009110713 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 3.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 100.95833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010986208 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.00187     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.27564102564102\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011897589 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00579     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.707       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.89880952380952\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012756889 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00773     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 112.31666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015323266 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00864     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0509     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 115.453125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011933203 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0301      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0494     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 118.21078431372548\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012799907 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0695      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.944       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 120.75462962962963\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009406296 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.0219298245614\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010258551 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.48333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009283456 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.685       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.59126984126983\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -360         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094296895 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.49         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0418      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.48863636363637\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007976539 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.1231884057971\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008067865 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.73958333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008187737 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.32        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.34333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -355         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069675306 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.6         |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.67         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.0096153846154\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007082748 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.481       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.52469135802468\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -352         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068598925 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.54        |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.754        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.03869047619048\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008265767 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.58620689655172\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -348         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075199255 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.45        |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.92777777777778\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -347         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075353133 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.43        |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.17741935483872\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -345         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075299595 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.39        |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.673        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.35416666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007520221 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.6969696969697\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -341         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074715093 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.26        |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.644        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.0808823529412\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008132404 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.2        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.43809523809523\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007703099 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.906       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.87962962962962\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -334       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00829377 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.07      |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.12       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 3.09       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.36486486486487\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007772306 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.822       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.00438596491227\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -327         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085582975 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0479      |\n",
      "|    value_loss           | 2.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.67094017094018\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007689826 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.45\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -321       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00839602 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.68      |\n",
      "|    explained_variance   | 0.439      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.56       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0512    |\n",
      "|    value_loss           | 2.89       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.1361788617886\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -318        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008064073 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.58       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.717       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0469     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.74404761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -315        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008475111 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.51       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.2906976744186\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006910606 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.931       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.83522727272728\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -308        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008680513 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.4        |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.665       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.35555555555555\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -305         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078966115 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.33        |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.879        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0427      |\n",
      "|    value_loss           | 2.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.8514492753623\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006894285 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.29       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.25177304964538\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -298         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069239167 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0442      |\n",
      "|    value_loss           | 3.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.66145833333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -295       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00776679 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.1       |\n",
      "|    explained_variance   | 0.352      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.12       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 2.76       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.98809523809524\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007950926 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.01       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    value_loss           | 3.7         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.26833333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -288        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008549869 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.56209150326796\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007880144 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.8028846153846\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -277        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007899754 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -272        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007297313 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.18364197530863\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -266         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062709046 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0396      |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.33636363636364\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -260        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006667489 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.4717261904762\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -255       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00777942 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.66      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.15       |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0432    |\n",
      "|    value_loss           | 2.84       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.546783625731\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -249       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 244        |\n",
      "|    total_timesteps      | 58368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00645989 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.6       |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.07       |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0404    |\n",
      "|    value_loss           | 3.05       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.6278735632184\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -243         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074028918 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0418      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.6723163841808\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -237        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006935068 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.961       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.6888888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -231         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067055244 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0372      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.63387978142077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006248551 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.59274193548387\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -219        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006899368 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.52513227513228\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -213         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 270          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070971576 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.41        |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0381      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.40625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -207        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007914059 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.947       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.28846153846155\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -201         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 278          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064494777 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.15530303030303\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -195         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 282          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071262233 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.41        |\n",
      "|    explained_variance   | 0.278        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0335      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.97014925373134\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -188         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 287          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060355803 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.73406862745097\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -183        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006917362 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.53381642512076\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006769169 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.2654761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -171         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062812166 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.52         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.99530516431926\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -165         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073615815 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.72685185185185\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -160        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005597038 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.40639269406392\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -154         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 313          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068939165 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 3.48         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.0777027027027\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -149         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077324165 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 3.51         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.73555555555555\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -143         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 321          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066309627 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.875        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.39144736842104\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -138         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063095954 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.45         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.017316017316\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -133       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 78848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00661566 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.36      |\n",
      "|    explained_variance   | 0.426      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.76       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0381    |\n",
      "|    value_loss           | 3.71       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.63141025641025\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -128        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006622821 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 3.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.24789029535864\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -123        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006414128 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 3.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.83020833333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -119         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 344          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066696503 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0371      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.40946502057614\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -114         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071914927 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 3.85         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.97764227642276\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 352          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062232553 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.51706827309238\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -105         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 357          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061764065 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 3.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.06349206349208\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -100         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058768317 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.60294117647058\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -96          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 366          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073702782 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.11143410852713\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -92         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006262331 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.61877394636016\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -88.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006367501 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.10416666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -85.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006201397 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.5926966292135\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -81.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 384          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069589713 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    value_loss           | 3.96         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.08703703703705\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -78.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 388          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057815984 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.16        |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.78         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 4.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.56410256410257\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -75.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 393         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006424878 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.03079710144928\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -72.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 397        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00676124 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.18      |\n",
      "|    explained_variance   | 0.645      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.42       |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 3.56       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.50089605734766\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -69.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007344598 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.95567375886526\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -66.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005832162 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.41842105263157\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -64.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005808757 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.81        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.87152777777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -62.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 415          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075178547 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 3.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.2963917525773\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -60.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 420         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006189379 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.71173469387756\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -58.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 424          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060798796 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.25        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.1405723905724\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -56.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 428          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055756955 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.25        |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.947        |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.56166666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -55.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 433          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069552893 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 52.44\n",
      "Overall Average Successful Assignments: 157.90547355205615\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0692ebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -346.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.916666666666668\n",
      "All assignments history: [15, 14, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -371     |\n",
      "| time/              |          |\n",
      "|    fps             | 263      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -332.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.791666666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -372         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072868476 |\n",
      "|    clip_fraction        | 0.0659       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.88        |\n",
      "|    explained_variance   | -0.116       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.62         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0371      |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -310.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.916666666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076837232 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | -0.0691      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.05         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 13.2         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -344.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.25\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007574626 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -232.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.666666666666664\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007669285 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | -0.0205     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.28        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 9.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.583333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008122088 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | -0.003      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 7.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 69.32142857142857\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -371       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00875474 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.85      |\n",
      "|    explained_variance   | 0.0118     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.77       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 6.71       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 82.71875\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -370       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00862055 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.84      |\n",
      "|    explained_variance   | -0.0115    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.11       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0364    |\n",
      "|    value_loss           | 5.97       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 93.03703703703704\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101969205 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.0095       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.93         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.043       |\n",
      "|    value_loss           | 4.75         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 101.225\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009186739 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.00308     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.922       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 4.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.09848484848484\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010684157 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.00662     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.70833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010622915 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.00369     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.544       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 118.53846153846153\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013297441 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00176     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0468     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 122.7797619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013299468 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | -0.000125   |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0329     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 126.44444444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014316993 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00272     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.78645833333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015581999 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00556     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0499     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.92156862745097\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009753402 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0488      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.746       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.8564814814815\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009481924 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.3421052631579\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009847008 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.56        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.6875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009491338 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.608       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.8452380952381\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009022849 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.821       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.83712121212122\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506608 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.43        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.6485507246377\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007601372 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.634       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.50694444444446\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -355         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080412775 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.61        |\n",
      "|    explained_variance   | 0.232        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.764        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.26\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008378574 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.437       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.97756410256412\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009516819 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.5216049382716\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008989181 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.47       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.0922619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008805288 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.47701149425288\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008003559 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.609       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.76666666666668\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -345       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00788736 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.3       |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.778      |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    value_loss           | 2.63       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.99462365591398\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008360659 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.25       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.416       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.1875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007980911 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.16       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.489898989899\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007166544 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.614       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.62745098039215\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007784465 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.01        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.76904761904763\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008249549 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.489       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.92592592592592\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008102146 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.761       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.1081081081081\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -326        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008012829 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.934       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.24122807017545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008841688 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.4059829059829\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -319         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071312897 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.63        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0434      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.52291666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007964251 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.836       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.59552845528455\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -312       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 41984      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00775609 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.45      |\n",
      "|    explained_variance   | 0.485      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.15       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    value_loss           | 3.3        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.66468253968253\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008031162 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.784       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.7248062015504\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -305        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007998519 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.36       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.7594696969697\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074426783 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.31        |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.796        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0427      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.84074074074073\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -299         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071816747 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0422      |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.84057971014494\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -296        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008133348 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.918       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.7695035460993\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -292        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007899475 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.65277777777777\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -289       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00760693 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.18      |\n",
      "|    explained_variance   | 0.542      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.42       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0434    |\n",
      "|    value_loss           | 3.15       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.47278911564626\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -287        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007116394 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.255\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -284         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082113445 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.08        |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.987        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0446      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.06209150326796\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -279        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007735458 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.84455128205127\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -275        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007234592 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.956       |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.62735849056602\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -270        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007519283 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.4104938271605\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -264         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080992635 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.87        |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.961        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0438      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.1621212121212\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -259        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007849969 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.88392857142858\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -254         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 246          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073723476 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.8         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.995        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0427      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.5716374269006\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -249        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008433284 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.2772988505747\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -243        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007956551 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.9590395480226\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -237        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006702971 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.902       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.61805555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -232        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008336516 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.28415300546447\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -227         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077812816 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.65        |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.81         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.044       |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.94758064516128\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -221        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007086873 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.64153439153438\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -216         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 277          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077236476 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.59        |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.952        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 2.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.31770833333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -210         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066072755 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.9576923076923\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -204         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 286          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075220037 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.54        |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0396      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.59469696969697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -198        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007842584 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.2325870646766\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -193        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007557176 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -188         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 299          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070476294 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.948        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.4746376811594\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -183        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007440118 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.09642857142856\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006766963 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.70422535211267\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006619052 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.3148148148148\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -166         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062129805 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.925799086758\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -161         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 321          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069555487 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.27         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.53265765765767\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -156        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006802239 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.10888888888888\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -151         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 330          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073349094 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.6688596491228\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -146         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058091814 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.86         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 3.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.24242424242425\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -140        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007015721 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.76923076923077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -136        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007149307 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.292194092827\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -131        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005920287 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.79895833333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -127        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005806879 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.3343621399177\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -122        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006469271 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.8709349593496\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -117         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058738776 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.51         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.38152610441767\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005894004 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.87599206349208\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 369          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073375925 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.35098039215686\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005658758 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.84108527131784\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005617177 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.2844827586207\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -98.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 381          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061162254 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0294      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.70833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -95.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006835888 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.1619850187266\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -92.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 389          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059952633 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.75         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0349      |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -89.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 393          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054015038 |\n",
      "|    clip_fraction        | 0.0969       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.63         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0336      |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.0613553113553\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -86.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059388895 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.033       |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.47826086956522\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -83.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005687345 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.90860215053763\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -81.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006070992 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 3.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.3386524822695\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -78.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006073666 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.7640350877193\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -75.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 413          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067475373 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.73         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.51         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.17361111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -73.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 417          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059534246 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.69         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.5627147766323\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -71.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006047044 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.9387755102041\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -69.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006803367 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.31313131313132\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -66.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008044766 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.69333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -64          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 433          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062811077 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.92         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.55         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 53.3\n",
      "Overall Average Successful Assignments: 164.97236141784498\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a100bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
