{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "795d4be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6709803969580043\n",
      "RMSE: 1.1802692335254894\n",
      "R-squared: 0.9905780981775942\n",
      "RAE: 0.07007735214500166\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=['Eligible'])\n",
    "    y = data['Eligible']\n",
    "    return X, y\n",
    "\n",
    "def train_svr_model(X_train, y_train):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    svr_model = SVR()\n",
    "    svr_model.fit(X_train_scaled, y_train)\n",
    "    return svr_model, scaler\n",
    "\n",
    "# Load and train on VehicleTrainingDataset.csv\n",
    "X_train, y_train = load_and_preprocess_data('VehicleTrainingDataset_Noisy_0.01.csv')\n",
    "svr_model, scaler = train_svr_model(X_train, y_train)\n",
    "\n",
    "# Predict eligibility scores on 1000VehicleDataset.csv\n",
    "vehicles_df = pd.read_csv('1000VehicleDataset_Noisy_0.01.csv')\n",
    "X_test = vehicles_df.drop(columns=['Eligible'])\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "predicted_scores = svr_model.predict(X_test_scaled)\n",
    "\n",
    "# Assuming you have access to actual scores, replace this line with the actual score loading logic if available\n",
    "y_actual = vehicles_df['Eligible']  # This would be prior to overwriting with predictions if you run this block again\n",
    "\n",
    "# Replace actual scores with predicted ones\n",
    "vehicles_df['Eligible'] = predicted_scores  \n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_actual, predicted_scores)\n",
    "rmse = np.sqrt(mean_squared_error(y_actual, predicted_scores))\n",
    "r_squared = r2_score(y_actual, predicted_scores)\n",
    "rae = np.sum(np.abs(y_actual - predicted_scores)) / np.sum(np.abs(y_actual - np.mean(y_actual)))\n",
    "\n",
    "# Output the results\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "print(f\"RAE: {rae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2696c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -390.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 6.583333333333333\n",
      "All assignments history: [11, 18, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -371     |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -302.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.208333333333332\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -368       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00707292 |\n",
      "|    clip_fraction        | 0.0615     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.84      |\n",
      "|    explained_variance   | -0.0705    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 3.16       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    value_loss           | 17.1       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -256.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.861111111111114\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -366         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072388332 |\n",
      "|    clip_fraction        | 0.0873       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.0867      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.96         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -348.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.5\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -366         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077429004 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | -0.154       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0406      |\n",
      "|    value_loss           | 10.1         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -236.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.833333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007757666 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.045       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.02        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 8.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 59.94444444444444\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -366         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077995374 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | -0.011       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.94         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0372      |\n",
      "|    value_loss           | 7.73         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 78.63095238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008430333 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 6.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 91.4375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008536728 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00225     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 5.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 100.98148148148148\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009855749 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00945     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 4.46        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 107.675\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010770481 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00612     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.373       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 115.39393939393939\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010466652 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 122.79861111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011591146 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00913     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.30769230769232\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010356072 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.91071428571428\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012669763 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.971       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.12777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011247636 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0559      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.64583333333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -358       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01106063 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.71      |\n",
      "|    explained_variance   | 0.113      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.709      |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    value_loss           | 2.79       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.56372549019608\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009778935 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.954       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.71759259259258\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009144871 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.7280701754386\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009590287 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.74        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.5375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009250333 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.26984126984127\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 393         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008436065 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.61       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.802       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.6439393939394\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008539814 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.0036231884058\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -349         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 433          |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071707205 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.54        |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.20833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 452         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008112663 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.624       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.37666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008436367 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.45       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.929       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.47435897435898\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -343       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 488        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00801563 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.4       |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.463      |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    value_loss           | 2.69       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.4506172839506\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007866507 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.27380952380952\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 524         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007994122 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.29       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.58        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.05172413793105\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008008072 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.24       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.721       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.68333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008393146 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.17       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.247311827957\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 582         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008397166 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.1        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.70052083333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008614229 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.547       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0508     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.25252525252526\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -325         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 624          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086388495 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.9         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0483      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.8014705882353\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -321        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008447626 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.943       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.14285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -319        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 662         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007605952 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.819       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.55092592592592\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -315        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008156639 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.85585585585585\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -311         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 701          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070810094 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.54        |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.983        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0423      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.109649122807\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -308        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007335864 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.48       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.37820512820514\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -304         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 741          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073585496 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.42        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.57         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0425      |\n",
      "|    value_loss           | 3.67         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.67291666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -300        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 760         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007973803 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.3        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.83333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 779         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008702618 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.99603174603175\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -293        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 799         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007842006 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.15503875968992\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -289        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008589462 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.24242424242425\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 838         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006577012 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.2962962962963\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 855         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008627936 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.898       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.30615942028984\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -277         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 875          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074711763 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.78        |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0441      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.36347517730496\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -273         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 895          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065205395 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.43055555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -269         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 913          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076270215 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.71        |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0403      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.43197278911563\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -265         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 933          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063362075 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.955        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0415      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.45\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -261         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 954          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074232463 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.872        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.40359477124184\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -255         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 971          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075527346 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.6         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.3573717948718\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -249         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 992          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066605145 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.3191823899371\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -243         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 1015         |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066807214 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.27006172839506\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -237        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1038        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007942708 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.1878787878788\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -231        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007376178 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.04464285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -225         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 1083         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064707818 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.8684210526316\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -219         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1101         |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076675834 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.043       |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.63793103448276\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -213         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1120         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075114286 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.832        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0381      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.42514124293785\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -207         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 1142         |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062708077 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.18055555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -201        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1163        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006148841 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.96038251366122\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -194        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1184        |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006657466 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.66397849462365\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -188         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1206         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068897223 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.25        |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.44         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.35978835978835\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -181         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 1227         |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067795175 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.07552083333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -175         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1248         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070860144 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.23        |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.7679487179487\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -168        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1270        |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007251853 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.42550505050505\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -161         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 1291         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071799853 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0418      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.0870646766169\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1313        |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005989054 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.7561274509804\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -149         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1333         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060039023 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.3997584541063\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -142         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 1355         |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060097193 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.9904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -136        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1378        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005924984 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.6032863849765\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -130         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 1396         |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070367195 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.22222222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -124        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1418        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005965232 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.81506849315068\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -118         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1436         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062736273 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.1         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.38288288288288\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1458         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051760958 |\n",
      "|    clip_fraction        | 0.091        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.9777777777778\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -106         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1479         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056853266 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.04        |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.12         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 3.52         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.55372807017545\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -101         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1501         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062359716 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.04        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.12229437229436\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -95.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1522        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006685228 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.944       |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 2.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.63782051282053\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -90.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1544         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077575324 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 3.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.14345991561183\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -85.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1565         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057632253 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.66458333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -80.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1587        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005710947 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.19958847736626\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -76          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1608         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060441764 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.64         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.7357723577236\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -71          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1630         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068676844 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.24799196787149\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -66.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1650         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065699834 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.04        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.73511904761904\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -62.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1673        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006303991 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.1813725490196\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -58.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1693        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006157371 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.6656976744186\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -54.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1714         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063121854 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3           |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.11206896551724\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -50.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1735         |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061206035 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.905        |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.55492424242425\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -47.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1756        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005414349 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.98876404494382\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -43.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1776         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065156845 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.41203703703704\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -41         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1796        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006678763 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.83333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -37.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1816         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063117556 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0336      |\n",
      "|    value_loss           | 2.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.22826086956522\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -35.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1832        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007448829 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.62186379928315\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -33          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1852         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076055857 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0324      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.04609929078015\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -30.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1874        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006763665 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.44210526315788\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -28.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1894         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063954405 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.80642361111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -26.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1915        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007171721 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 229.15893470790377\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -25.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1934        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005340226 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 229.5187074829932\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -24          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1953         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069877617 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 3.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 229.88804713804714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -22.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1972        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007505785 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 230.24083333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -21         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1992        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006187062 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 100.82\n",
      "Overall Average Successful Assignments: 183.3696311977157\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8a45f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -380.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 10.666666666666666\n",
      "All assignments history: [15, 13, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -372     |\n",
      "| time/              |          |\n",
      "|    fps             | 58       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -364.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007574724 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.118      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.1         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -280.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.86111111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -371         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072802776 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | 0.0591       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 12           |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -284.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.979166666666664\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008120018 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.0367     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.19        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 9.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -194.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.05\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076447814 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | -0.0432      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.08         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 8.51         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 59.72222222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007347201 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.023      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.5         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 7.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 72.39285714285714\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -368       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00840186 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.81      |\n",
      "|    explained_variance   | 0.00224    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.64       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0402    |\n",
      "|    value_loss           | 6.32       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 83.02083333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008470273 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | -0.00103    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.39        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 5.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 91.94444444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009548473 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | -0.00242    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.777       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 4.49        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 99.08333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010300366 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00348     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.65        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 3.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.00757575757575\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -364       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01049893 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.76      |\n",
      "|    explained_variance   | 0.00733    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.47       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0442    |\n",
      "|    value_loss           | 3.41       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 109.375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012059424 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0032      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.77564102564102\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015614568 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.000589    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0509     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 117.48809523809524\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012610259 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0118      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.965       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 118.61666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013269283 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0482     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 120.21354166666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010177686 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.896       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 121.36764705882354\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010493953 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0637      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.22222222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009213578 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.8859649122807\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010034043 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.0\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -354         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 370          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100265145 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.62        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0459      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.3095238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248728 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.8         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.8181818181818\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009164812 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.394       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.0036231884058\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010803755 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.9         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0494     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.13888888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009982708 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.12333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 463         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008353983 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.44       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.41666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008368617 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.84876543209876\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -340         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 499          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077468194 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.35        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.442        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.10416666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010192426 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.28       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.979       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.33045977011494\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008674849 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.45\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -332        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008511856 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.5215053763441\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -329         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 572          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083378665 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.08        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0452      |\n",
      "|    value_loss           | 2.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.6328125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -326        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 590         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009474659 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0513     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.62626262626262\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007848021 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.593       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.52696078431373\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009282824 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.88       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.907       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0482     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.2904761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -317         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 644          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081311595 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.79        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.844        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0494      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.1435185185185\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -314       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 664        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00891196 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.74      |\n",
      "|    explained_variance   | 0.5        |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.827      |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    value_loss           | 2.99       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.8716216216216\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -311        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008127829 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.85        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0469     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.6315789473684\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -307        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 700         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009182891 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.28205128205127\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -304       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 719        |\n",
      "|    total_timesteps      | 39936      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00755559 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.54      |\n",
      "|    explained_variance   | 0.535      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.49       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.044     |\n",
      "|    value_loss           | 3.17       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.87708333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -301        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 738         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007575907 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.52439024390245\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 756         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007940646 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.4        |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.962       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.15079365079364\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -294         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 774          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071404646 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.34        |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0414      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.73062015503876\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 793         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007974001 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.3        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.726       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.34469696969697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -287        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 812         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007682097 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.915       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0466     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.92222222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -284        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 830         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007562531 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.46376811594203\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -280         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 848          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072132167 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.09        |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0453      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.98936170212767\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -276        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 867         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006906253 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.48611111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -273        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 886         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006787681 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.03231292517006\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -269         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 903          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072384938 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.96        |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.939        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.42833333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -266         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 921          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073637934 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.87        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0448      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.84313725490196\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -260        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 939         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007816089 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.759       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.18108974358975\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -255        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 957         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006404291 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.5314465408805\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -249        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 974         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007546993 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.65       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.8641975308642\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -242         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 991          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075479955 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.6         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0415      |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.13333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -236        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1009        |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006676618 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.35267857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -230        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1026        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006799015 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.839       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.56286549707602\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -224         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1044         |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075028236 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0431      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.78304597701148\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -217        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006428725 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.95762711864407\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -210         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 1077         |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080570895 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0438      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.13194444444446\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -204         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 1095         |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069944756 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.2827868852459\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -197         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1112         |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066290637 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.29        |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.3978494623656\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -191         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1130         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062250243 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.946        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 2.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.51455026455025\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -184        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1147        |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006779898 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.60807291666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -178         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1165         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065914597 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.67179487179487\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -171        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1182        |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007926512 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.67929292929293\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -165         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 1199         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068129674 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 2.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.68905472636817\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -158         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1216         |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062106038 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.6813725490196\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -151         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1233         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066149877 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 178.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.67753623188406\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -145        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1250        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005952724 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.65\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1268        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006236987 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.60915492957747\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -132         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 1284         |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064936914 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.04        |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 178.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.53819444444446\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -126         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1301         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073921727 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.975        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 2.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 178.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.45091324200914\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -119         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1319         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066998163 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.758        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.45         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 174.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.3096846846847\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1336        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006110826 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.15777777777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -107         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1353         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055547054 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.99890350877192\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -101         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1370         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052138157 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 178.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.83658008658008\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -94.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 1387         |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061895773 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 3.45         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.6688034188034\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -88.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1404         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074214065 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.4915611814346\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -82.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1422         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064344695 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.29375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -77.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1438        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006348787 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.09156378600824\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -71.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1455        |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007849289 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.85365853658536\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -66.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1472         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061337715 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.6004016064257\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -61.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1489         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060780635 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.99         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.33928571428572\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -56.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1506        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006334094 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.967       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.06470588235294\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -51.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1523        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006261206 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.969       |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.77713178294573\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -46.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1540         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060511325 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.46647509578543\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -42         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1557        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006265456 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.14962121212122\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -37.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1575         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071504517 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.82303370786516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -33.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1593        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007294099 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.46666666666667\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -28.7     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 90        |\n",
      "|    time_elapsed         | 1612      |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0057247 |\n",
      "|    clip_fraction        | 0.112     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -2.66     |\n",
      "|    explained_variance   | 0.419     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.16      |\n",
      "|    n_updates            | 890       |\n",
      "|    policy_gradient_loss | -0.0345   |\n",
      "|    value_loss           | 2.79      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.1043956043956\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -24.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1630         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066242022 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0308      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.71376811594203\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -21         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1648        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005813859 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.30824372759858\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -17.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1665         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054832343 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.9086879432624\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -13.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1683         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060513783 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.4780701754386\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -10.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1700        |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008586187 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.897       |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.05034722222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -7.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1718         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068390863 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.6168384879725\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -4.36        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1735         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060758423 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.17261904761904\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -1.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1752         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061361436 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.71885521885523\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 1.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1769        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007280064 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 188.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.2475\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 4.4          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1787         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069418065 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 93.98\n",
      "Overall Average Successful Assignments: 169.70068950309917\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40faf539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -306.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.083333333333336\n",
      "All assignments history: [18, 5, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -377     |\n",
      "| time/              |          |\n",
      "|    fps             | 71       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -362.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008143319 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.191      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.78        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -380.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.444444444444443\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -372         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072498955 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | -0.0537      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.01         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -314.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.3125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072006164 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.036        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.45         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 10.1         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -276.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.6\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008117855 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.0163     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.98        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 8.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -292.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075244512 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | -0.0331      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.05         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 8            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -244.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.80952380952381\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -369       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00826218 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.81      |\n",
      "|    explained_variance   | 0.0125     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.02       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0377    |\n",
      "|    value_loss           | 6.62       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.78125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008959234 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 5.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 56.24074074074074\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009010066 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 4.56        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 61.125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008898931 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00865     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.601       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 4.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 65.75757575757575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011389484 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00172     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.723       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 3.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 71.36111111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010905984 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 75.26282051282051\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011533013 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00857     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 80.02380952380952\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016900156 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0512     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 84.25555555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011867385 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.791       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.546875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011051197 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0538      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.411       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 92.93627450980392\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010908527 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0716      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 98.18055555555556\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -362         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 301          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107940715 |\n",
      "|    clip_fraction        | 0.216        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0868       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.06         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0455      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 102.70614035087719\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009197395 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.965       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 106.87083333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008745269 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 110.67063492063492\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009394323 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 114.36742424242425\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -358         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 370          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090851635 |\n",
      "|    clip_fraction        | 0.178        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.61        |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0415      |\n",
      "|    value_loss           | 2.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 117.76811594202898\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008455474 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 120.88541666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009066862 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.92333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008250622 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.51       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 126.96474358974359\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -352       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 439        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00840632 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.49      |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.97       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0421    |\n",
      "|    value_loss           | 2.7        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.679012345679\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 456         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008072019 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.45       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.15178571428572\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008062814 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.816       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.58333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -346        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009143518 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.8111111111111\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -344       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 507        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00838181 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.32      |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.2        |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0428    |\n",
      "|    value_loss           | 3.24       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.88978494623655\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -342       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 524        |\n",
      "|    total_timesteps      | 31744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00950025 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.28      |\n",
      "|    explained_variance   | 0.291      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.769      |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    value_loss           | 2.92       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.98177083333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -340         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091312565 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.23        |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.999        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.046       |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.88888888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008050419 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.18       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.58333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008819554 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.775       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.37142857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -332        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008609011 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.25\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 609         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008021585 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.9189189189189\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -326        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 627         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009088321 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.69736842105263\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009091163 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.581       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0525     |\n",
      "|    value_loss           | 2.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.6965811965812\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 662         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008182743 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.74       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.884       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.64166666666668\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -317       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 678        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00900625 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.68      |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.799      |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    value_loss           | 2.89       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.5060975609756\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -313        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 696         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008774311 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.57       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.607       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0494     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.43849206349208\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -310        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 713         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007378944 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.33333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008834028 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.16287878787878\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073462306 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.37        |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0425      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.94074074074075\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -299         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 765          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077984016 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0474      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.7753623188406\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -295        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 783         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007722834 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.829       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.5177304964539\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -292        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 801         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008396028 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.24479166666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -288        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008999543 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.92006802721087\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -285         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 835          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073780096 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.07        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0425      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.61166666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007877469 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.20751633986927\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -276        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 870         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007507467 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.83333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -270        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 887         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007026634 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.35377358490567\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -264        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 904         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007233911 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.838       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.79166666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -259         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 922          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069254357 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.79        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0429      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.1712121212121\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -253        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 939         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008596493 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.5595238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -247        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 955         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009145669 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.794       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.94590643274853\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -241       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 973        |\n",
      "|    total_timesteps      | 58368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00780518 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.69      |\n",
      "|    explained_variance   | 0.595      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.897      |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0433    |\n",
      "|    value_loss           | 2.98       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.35201149425288\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -235         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 990          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073135076 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.64        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0411      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.68785310734464\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -229        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1008        |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007699112 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.997       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.04861111111111\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -223       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 1024       |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00723066 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.57      |\n",
      "|    explained_variance   | 0.551      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.44       |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.0438    |\n",
      "|    value_loss           | 3.4        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.3360655737705\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -217         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1041         |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068920627 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.55        |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.6008064516129\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -210        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1059        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008027764 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.82010582010582\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -204        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1075        |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007661779 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.9765625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -199        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1092        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007552582 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.1320512820513\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -192        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1109        |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007344783 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.2171717171717\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -186        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1126        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007629253 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.31965174129354\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -180        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1143        |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006669123 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 174.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.38848039215685\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -174         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1159         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063915458 |\n",
      "|    clip_fraction        | 0.0934       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0336      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.43357487922705\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -167         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 1176         |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069511835 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.4547619047619\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -162         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 1196         |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073579364 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.983        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 180.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.4894366197183\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1214        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006575832 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.51388888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -149         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1233         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060478947 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 180.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.4703196347032\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -143        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1251        |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006632441 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 180.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.4144144144144\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -137        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1270        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006680745 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 180.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.34555555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -131        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1288        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006729597 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 180.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.24561403508773\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -126       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 1306       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00651283 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.21      |\n",
      "|    explained_variance   | 0.524      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.22       |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    value_loss           | 3.04       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.1525974025974\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -120        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1325        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006957271 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.01816239316238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -115        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1343        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007287338 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.8512658227848\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -110      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 79        |\n",
      "|    time_elapsed         | 1362      |\n",
      "|    total_timesteps      | 80896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0073135 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.16     |\n",
      "|    explained_variance   | 0.424     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.44      |\n",
      "|    n_updates            | 780       |\n",
      "|    policy_gradient_loss | -0.0381   |\n",
      "|    value_loss           | 3.29      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.68333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -105         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1379         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073147994 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.5051440329218\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -99.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1396         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058311364 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.07        |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.3109756097561\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -94          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1414         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055541797 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.04        |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.804        |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.0953815261044\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -88.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1433         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067073777 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.07        |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.86904761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -83.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1451         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061835754 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.6186274509804\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -78.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1469         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055485815 |\n",
      "|    clip_fraction        | 0.0926       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.34593023255815\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -74.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1489         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066612596 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.73         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.07183908045977\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -70.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1508         |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057893908 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.78219696969697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -65.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1527        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006070219 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.962       |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.4756554307116\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -61.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1545         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055562276 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.95        |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.16203703703704\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -57.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1564         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058142683 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.84615384615384\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -53.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1582         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062640714 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.033       |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.4909420289855\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -50.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1601         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064349934 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0335      |\n",
      "|    value_loss           | 2.73         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.14605734767025\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -47.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1621         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052577876 |\n",
      "|    clip_fraction        | 0.0959       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0315      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.78014184397162\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -44.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1639         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067128916 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.38947368421051\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -41.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1658        |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006110519 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.00086805555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -38.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1677        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005796888 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.58762886597938\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -36         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1696        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006325312 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 188.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.19387755102042\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -33.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1714         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054976894 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.7828282828283\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -30.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1732        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005091589 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 188.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.37083333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -27.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1751        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008246593 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 84.58\n",
      "Overall Average Successful Assignments: 157.7586502636877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc8ebb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -338.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.333333333333332\n",
      "All assignments history: [10, 8, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -382     |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -280.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.833333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -377        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008177381 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.00323    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.69        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 74.36111111111111\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -374       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00840244 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.83      |\n",
      "|    explained_variance   | 0.0374     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.07       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 13.9       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 99.1875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008435456 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.0486     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 114.23333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008135756 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0425      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.17        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 8.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 119.44444444444444\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -370       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 109        |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00875093 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.81      |\n",
      "|    explained_variance   | 0.028      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.89       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0382    |\n",
      "|    value_loss           | 7.96       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.98809523809524\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009165227 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0209      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 6.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 130.45833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009205973 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.034       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 6.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.35185185185185\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009852574 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00897     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 4.5         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.48333333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123108 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0167      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 4.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.40151515151516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010564024 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00483     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.653       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.15277777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011697097 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0128      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.943       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.43589743589743\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -363         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 13312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143036265 |\n",
      "|    clip_fraction        | 0.324        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0121       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.633        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0482      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.04166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013148779 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.23        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.78333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012347654 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.0528      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.678       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.21354166666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012047273 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.9950980392157\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009931494 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.313       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.96296296296296\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010783102 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2           |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.8201754385965\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011061787 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.6625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -352         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 371          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096938405 |\n",
      "|    clip_fraction        | 0.209        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.5         |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.489        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.041       |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.62698412698413\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009429604 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.46       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008619532 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.44       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.14492753623188\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -346        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008299625 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.88541666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008092134 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.682       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.49666666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -342       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 465        |\n",
      "|    total_timesteps      | 25600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00805032 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.26      |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.01       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 3.29       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.17307692307693\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -339      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 483       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0081628 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -5.21     |\n",
      "|    explained_variance   | 0.334     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 0.514     |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -0.0373   |\n",
      "|    value_loss           | 2.85      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.92592592592592\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009094971 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.66964285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007784758 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.07       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.56034482758622\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008677244 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.52777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 553         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008135412 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.58870967741936\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -326        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008239461 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.85       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.5625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 587         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008140797 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.84        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.42171717171718\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007633484 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.71       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.35049019607843\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009013325 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.9         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.35476190476192\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -313         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 641          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073281126 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.55        |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.892        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.3148148148148\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -310         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 659          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068970746 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.48        |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.3153153153153\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -307         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 678          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076086028 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.44        |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.57         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 3.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.37061403508773\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -303        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 696         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008004643 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.41       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 3.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.4017094017094\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -300        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007860886 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.33       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.789       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.3875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 734         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007951705 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.5121951219512\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -293       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 753        |\n",
      "|    total_timesteps      | 41984      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00896162 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.17      |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.909      |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0435    |\n",
      "|    value_loss           | 3.09       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.5952380952381\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -289        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 771         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008877454 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.69        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.59108527131784\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 789         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008408447 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.57954545454547\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -283         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 807          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065710316 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.99        |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 3.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.53333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -279         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 825          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077138552 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0411      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.5090579710145\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -276        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 844         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009167279 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.4840425531915\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -272        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 862         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007912369 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.38541666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -269        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 881         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007844807 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.26700680272108\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -266        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 898         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008075644 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.19333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -263         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 917          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076437965 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.82        |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.045       |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.08333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -257         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 936          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073344046 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0442      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.98557692307693\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -252        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 954         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007004821 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 4           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.87264150943398\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -246        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 973         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008468247 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.81944444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -241        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 992         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008302398 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.73181818181817\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -236         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 1010         |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068681855 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.76        |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0431      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.69642857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -230        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1028        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006757671 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.6169590643275\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -225       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 1048       |\n",
      "|    total_timesteps      | 58368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00695384 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.72      |\n",
      "|    explained_variance   | 0.382      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.05       |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    value_loss           | 3.12       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.53879310344828\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -220         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1067         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077028014 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.7         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.4223163841808\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -215         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 1085         |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066952202 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.68        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0416      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.32083333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -209         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 1103         |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065825456 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.2295081967213\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -203         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1122         |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067353607 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.67         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 3.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.08064516129033\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -198         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1140         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073661497 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.61        |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.9457671957672\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -192        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1158        |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005315254 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.59       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.79557291666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -187         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1178         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067935106 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.61410256410255\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -182         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1196         |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065051033 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.55        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.44065656565655\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -176        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1215        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006065801 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.28855721393035\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -171        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1234        |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006146078 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.929       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.12745098039215\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -166         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1254         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064276387 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.90700483091788\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -160         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 1272         |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062475093 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.64880952380952\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1290        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006579263 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.877       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.43309859154928\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -150         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 1309         |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077115768 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.14930555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -145         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1327         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064332867 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 3.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.8744292237443\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -140         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1345         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059386813 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.56306306306305\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -135         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1362         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068308013 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.993        |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 2.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.27555555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -130        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1380        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007658363 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.96600877192984\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -126        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1396        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006886312 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.65800865800867\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -122         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 1414         |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072007026 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    value_loss           | 3.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.3311965811966\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1431        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006827725 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.98839662447259\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1449         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058402214 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -108        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1465        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006396221 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.2633744855967\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -103         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1483         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070436103 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0413      |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.864837398374\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -99.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1501         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055898456 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.032       |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.4738955823293\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -95.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1518         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059187803 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.04365079365078\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -92.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1535         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073203584 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.57647058823528\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -89          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1553         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070304833 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.140503875969\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -85.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1570         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067868163 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.985        |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.71264367816093\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -82.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1587         |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051184935 |\n",
      "|    clip_fraction        | 0.0943       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.94         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.48         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.23958333333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -80        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 1605       |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837964 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.23      |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.16       |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 3.28       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.80898876404495\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -76.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1625         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064718267 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.33703703703705\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -73.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1643         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076954104 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.8562271062271\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -71          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1662         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071038613 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.25        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0318      |\n",
      "|    value_loss           | 3.45         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.38858695652175\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -68.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1680         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064901975 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.913082437276\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -66         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1696        |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006294795 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.43971631205673\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -63.5     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 94        |\n",
      "|    time_elapsed         | 1713      |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0067493 |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.17     |\n",
      "|    explained_variance   | 0.373     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.05      |\n",
      "|    n_updates            | 930       |\n",
      "|    policy_gradient_loss | -0.0381   |\n",
      "|    value_loss           | 2.98      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.93333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -61.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1732         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070325453 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.16        |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.39670138888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -60          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1751         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059778932 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.89776632302406\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -58.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1769        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006170041 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.821       |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.42091836734693\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -56.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 1785       |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00714347 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.12      |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.32       |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.0381    |\n",
      "|    value_loss           | 3.23       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.9503367003367\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -53.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1804        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006450709 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.42\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -52          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1822         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061609116 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 2.9          |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 73.28\n",
      "Overall Average Successful Assignments: 176.55356225297987\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6103bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -356.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.333333333333332\n",
      "All assignments history: [19, 17, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -364     |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -318.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.833333333333332\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076047173 |\n",
      "|    clip_fraction        | 0.0716       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.115       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.11         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0421      |\n",
      "|    value_loss           | 16.1         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -290.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.583333333333336\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -366         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074545434 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.162       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.39         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 12.8         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.083333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007419574 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.0596     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.06        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 9.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 59.583333333333336\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -367         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070406543 |\n",
      "|    clip_fraction        | 0.0907       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.00562      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.05         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    value_loss           | 8.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 70.18055555555556\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -368         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066403556 |\n",
      "|    clip_fraction        | 0.0849       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | -0.0198      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.37         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 8.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 81.80952380952381\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006843693 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.00876    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.01        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 6.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 90.89583333333333\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -367       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00890974 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.81      |\n",
      "|    explained_variance   | -0.00112   |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.46       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0422    |\n",
      "|    value_loss           | 5.45       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 97.42592592592592\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008637588 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.000581    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.777       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 4.86        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 102.71666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009740794 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | -0.00405    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.95        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 4.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.32575757575758\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -366       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 198        |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00865794 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.78      |\n",
      "|    explained_variance   | 0.00464    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.2        |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0386    |\n",
      "|    value_loss           | 3.67       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.34027777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011163143 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.000816    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.714       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 117.69871794871794\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012592126 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00186     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 121.43452380952381\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014093051 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00699     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.000129   |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.10555555555555\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015464827 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0083      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.526       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0531     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.3125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -362         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110494215 |\n",
      "|    clip_fraction        | 0.207        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.0523       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.681        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0459      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.02941176470588\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011856342 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0938      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.584       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.055      |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.44444444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010630023 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.68421052631578\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008712769 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0752      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.58333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -358         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 362          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092060575 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.87         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.46428571428572\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -356         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 379          |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077659334 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.65        |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.041       |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.36742424242425\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -354         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 398          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071736267 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.63        |\n",
      "|    explained_variance   | 0.195        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.272        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0398      |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.18840579710144\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -353         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 416          |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079807425 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.6         |\n",
      "|    explained_variance   | 0.236        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.38         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.044       |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.12847222222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -352         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 434          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077828914 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.58        |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 2.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.96333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -351         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 453          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080602225 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.56        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.984        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0412      |\n",
      "|    value_loss           | 2.66         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.08333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006374332 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.21913580246914\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007185528 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.861       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.18154761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -346         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 508          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072178617 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.43        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.38         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0416      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.10632183908046\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -344         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 527          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069794585 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.38        |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0416      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.99166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008285943 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.32       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.80376344086022\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007727306 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.24       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.47916666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008198262 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.63        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.01262626262627\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008257413 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.08       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0466     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.5857843137255\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 613         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008560861 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0498     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.19285714285715\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -327        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007974083 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.88       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.76157407407408\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -324        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008739065 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.931       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0515     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.38288288288288\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 666         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007669218 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.73        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.90570175438597\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006724622 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.57       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.47435897435898\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -314         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 700          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068191104 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.49        |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.0125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -310         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 715          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075173783 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.39        |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.53252032520325\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -306         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 731          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072715604 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.31        |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0402      |\n",
      "|    value_loss           | 3.73         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.0793650793651\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071756495 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.23        |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0436      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.6124031007752\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -298        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008208627 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.872       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.04545454545453\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -294       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 780        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00763229 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.09      |\n",
      "|    explained_variance   | 0.379      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.75       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0432    |\n",
      "|    value_loss           | 3.28       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.50925925925927\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -290         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 797          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068962746 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.01        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0426      |\n",
      "|    value_loss           | 3.36         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.8731884057971\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -286         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 811          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067375926 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.96        |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.22163120567376\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006955174 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 4.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.55034722222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -279         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 843          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071468456 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.86        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.56         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.8078231292517\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -275         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 860          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068766335 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.82        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.967        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.04166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -271        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 876         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006929202 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.2761437908497\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -266         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 892          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069584427 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.77        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.4823717948718\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -260        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 908         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007403648 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.67295597484278\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -255         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 924          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069262367 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.76        |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.87654320987653\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -249        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 940         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007027838 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.00757575757575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -243        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 956         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006421554 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.10565476190476\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -237        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 973         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006295131 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.16666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -231        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006966107 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.19540229885058\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -225         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1004         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072218273 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.55        |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 3.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.21751412429379\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -219        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1020        |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007440578 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.20833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -213        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1037        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006712675 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.20081967213116\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -206         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1053         |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069690477 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.944        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0372      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.13575268817203\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1069        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006879421 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.07671957671957\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -194         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 1085         |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068203514 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -188        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1101        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008027021 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.89871794871794\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -181         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1117         |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067744413 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    value_loss           | 3.68         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.78535353535352\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -176         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 1133         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059719686 |\n",
      "|    clip_fraction        | 0.0991       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.41        |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 3.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.65796019900498\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -169       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 1150       |\n",
      "|    total_timesteps      | 68608      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00614255 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.37      |\n",
      "|    explained_variance   | 0.444      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.17       |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    value_loss           | 3.43       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.49264705882354\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -163        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1166        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008086946 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.32004830917873\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -157         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 1183         |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068878597 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.23         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0424      |\n",
      "|    value_loss           | 3.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.1392857142857\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -151         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 1198         |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070441235 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.19         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.8744131455399\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -146        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1213        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006364162 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.9         |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 4.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.63657407407408\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -140         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1228         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075114043 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 4.44         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.37899543378995\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -135         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1243         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061017075 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.73         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.1204954954955\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -129         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1260         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060371766 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.99         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    value_loss           | 3.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.8111111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -123        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1273        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007004994 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.06        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 4.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.49780701754386\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1287        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007038088 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 4.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.19372294372295\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -113         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 1301         |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050030546 |\n",
      "|    clip_fraction        | 0.0912       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 4.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -107        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1315        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006454046 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.85        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 4.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.5337552742616\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1329        |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005920029 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.17291666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -97.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1342         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077657006 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.79732510288065\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -92.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1356         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061698016 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.25        |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.97         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 4.19         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.390243902439\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -87.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 1370       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00669647 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.28      |\n",
      "|    explained_variance   | 0.497      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.2        |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | -0.0348    |\n",
      "|    value_loss           | 3.76       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.99899598393574\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -83.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1384        |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006623621 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.57738095238096\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -79.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1397        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006979227 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.15098039215687\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -75.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1411         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074130595 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.7044573643411\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -71.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1425         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069941203 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.272030651341\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -67.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1439        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006372533 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.8181818181818\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -64.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1453        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006237643 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 4.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.35299625468164\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -60.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1467         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065310113 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    value_loss           | 3.8          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.88518518518518\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -57.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1481         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060589663 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.98         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 4.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.41575091575092\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -54.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1495        |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006382186 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.96557971014494\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -51.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1508         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064692693 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.47132616487454\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -49.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1523        |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006479085 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.85        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 4.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.94769503546098\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -47          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1536         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064727683 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 3.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.42719298245615\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -45         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1550        |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006754783 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.81        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 4.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.8984375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -43.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1563        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006607467 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.36082474226805\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -41.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1577        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006638151 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.15        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 4.35        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.84013605442178\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -39.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1592        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006922554 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 4.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.2861952861953\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -37.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1606        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008071061 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.70916666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -35.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1620        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006025972 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 4.07        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 90.0\n",
      "Overall Average Successful Assignments: 173.2026404595929\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a6d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -364.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 16.916666666666668\n",
      "All assignments history: [13, 10, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -377     |\n",
      "| time/              |          |\n",
      "|    fps             | 79       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -342.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.083333333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006894336 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.0914     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.8         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.333333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008114528 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 63.75\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006234623 |\n",
      "|    clip_fraction        | 0.0719      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.0172     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.47        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 77.96666666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070413616 |\n",
      "|    clip_fraction        | 0.0883       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.0472       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.34         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 9.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.66666666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -369       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 74         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 82         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00858899 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.82      |\n",
      "|    explained_variance   | 0.08       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.43       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 7.61       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 100.4047619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008945024 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 6.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.98958333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008047381 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 5.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.02777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010358851 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 4.46        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 122.86666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010207795 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00487     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.894       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 3.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.79545454545455\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010066606 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00831     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.364       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.26388888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011387256 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.6         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.65384615384616\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012595804 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.805       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.57142857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014018388 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0173      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0502     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.10555555555555\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011272067 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011878613 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.0763      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.12745098039215\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -357       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 75         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 232        |\n",
      "|    total_timesteps      | 17408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01144388 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.7       |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.3        |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    value_loss           | 2.8        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.88888888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009462609 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.6798245614035\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010055195 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.524       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.36666666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -353         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082002375 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.63        |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.041       |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.6547619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007962101 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.45        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.5189393939394\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007956462 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.346       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.3913043478261\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008125336 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.54       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.20833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008819969 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.915       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -346        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008079449 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.45       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.804       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.62        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.64423076923077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008374213 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.41       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.724       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.15740740740742\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 371         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008584265 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.333       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.65178571428572\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -340         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 385          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077273482 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.3         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.328        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0433      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.1235632183908\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008318247 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.24       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.55277777777778\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008193046 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.99193548387098\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007168849 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.09       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.4921875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -328         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 438          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067193992 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0403      |\n",
      "|    value_loss           | 3.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.9090909090909\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -325         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 453          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077222334 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.91        |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.598        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0416      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.34803921568627\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -322       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 74         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 467        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00825927 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.83      |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.84       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 2.8        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.71904761904761\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -319        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007475611 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.27083333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -315         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 498          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073922165 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.66        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.516        |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.67342342342343\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007822607 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.59       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.01973684210526\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -308         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 525          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077064494 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.5         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0457      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.39529914529913\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -304        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006122802 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.42       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.67708333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -301        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007353694 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.89430894308944\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 585         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008584322 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.984       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.10714285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -294        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009292789 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.38565891472868\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -290        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007167872 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.6685606060606\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007985987 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 3.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.93148148148148\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 636         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008374879 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.913       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.17934782608697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -278        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008084613 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.865       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.39361702127658\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -274        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 662         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007289598 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.58680555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -269        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007424006 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.77551020408163\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -265         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 688          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068291095 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.57        |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.925\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -261        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 703         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007279791 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.04901960784315\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -255         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 717          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070729726 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 3.63         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.10897435897436\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -249        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006990489 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.16194968553458\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -242         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 747          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063938564 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0402      |\n",
      "|    value_loss           | 3.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.17283950617283\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -235        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 763         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006171681 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.1439393939394\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -229        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006066685 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.0297619047619\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -222         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 790          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063639404 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.9298245614035\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -216         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 805          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054528704 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0359      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.85632183908046\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -209        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 820         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005613707 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.74576271186442\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -202        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 833         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004996371 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.61805555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -196         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 846          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069349986 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0306      |\n",
      "|    value_loss           | 3.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.45901639344262\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -189        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 860         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006022967 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.06       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.79        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.252688172043\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -183        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 874         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005611317 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.06       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.0304232804233\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -176        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 888         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005625343 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.77734375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -169         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 901          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050722393 |\n",
      "|    clip_fraction        | 0.0922       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.031       |\n",
      "|    value_loss           | 3.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.48461538461538\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -163        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 915         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005824082 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.22979797979798\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -156         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 929          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060822126 |\n",
      "|    clip_fraction        | 0.0979       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0326      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.92164179104478\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -150         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 941          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065617133 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 2.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.6017156862745\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -143        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 954         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005537196 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.27777777777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -136         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 966          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063095447 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.9309523809524\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -130         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 979          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059774667 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.63         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 3.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.55985915492957\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -123        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 992         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006127465 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.14930555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1004        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005828996 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.7659817351598\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1017        |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005409851 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.356981981982\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -104       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 73         |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 1030       |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00456605 |\n",
      "|    clip_fraction        | 0.0813     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.85      |\n",
      "|    explained_variance   | 0.504      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.44       |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.028     |\n",
      "|    value_loss           | 3.41       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.94333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -98          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1042         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053528626 |\n",
      "|    clip_fraction        | 0.0889       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0308      |\n",
      "|    value_loss           | 3.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.51644736842104\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -91.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1055        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004862185 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.07251082251082\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -85.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 1067         |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054901647 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -80          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1080         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059361155 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0317      |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.1698312236287\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -74.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1093         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046603335 |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0281      |\n",
      "|    value_loss           | 3.7          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.70208333333332\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -68.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1106         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047841454 |\n",
      "|    clip_fraction        | 0.0984       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.92         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.032       |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.19753086419752\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -63.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1118         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048629204 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0303      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.6941056910569\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -58.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1131        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005002732 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.16265060240963\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -54.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1144        |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006028489 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.63888888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -49.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005268762 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 3.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 229.08039215686276\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -45.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1169        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005325568 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 229.54941860465115\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -40.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1182        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005400163 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 3.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 230.00191570881225\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -36.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1195        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005127471 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 230.4375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -32.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1208         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050366707 |\n",
      "|    clip_fraction        | 0.0954       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0295      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 230.87078651685394\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -29.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1220         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049251528 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.92         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0297      |\n",
      "|    value_loss           | 3.41         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 231.31296296296296\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -24.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1233         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054050917 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 231.7216117216117\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -21.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1245         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067996187 |\n",
      "|    clip_fraction        | 0.0995       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 232.1286231884058\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -19         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1258        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006683818 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 232.5421146953405\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -16         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1271        |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006467621 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 232.94326241134752\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -13.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1284        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006218046 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 233.3201754385965\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -10.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1297        |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006635109 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 233.69010416666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -8.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1309        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006302099 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 234.0704467353952\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -6.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1324         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049740365 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 3.81         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 234.44557823129253\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -4.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1338        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005588569 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 234.80723905723906\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -2.42      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 74         |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 1352       |\n",
      "|    total_timesteps      | 101376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00578781 |\n",
      "|    clip_fraction        | 0.0976     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.82      |\n",
      "|    explained_variance   | 0.633      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.41       |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 3.28       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 235.17\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -0.62       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1365        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007561939 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 110.58\n",
      "Overall Average Successful Assignments: 189.11759739116317\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f79e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -388.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.166666666666667\n",
      "All assignments history: [17, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -374     |\n",
      "| time/              |          |\n",
      "|    fps             | 81       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 65.375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007828108 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.323      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.37        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 92.22222222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008547481 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.0481      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.95833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007837781 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.16666666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -372         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072962986 |\n",
      "|    clip_fraction        | 0.096        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0.074        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.18         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 8.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 121.75\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -372         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 79           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072023794 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0.032        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.07         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 8.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.36904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008207258 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | -0.032      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 7.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.02083333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009383835 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | -0.00355    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.17        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 5.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.58333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008918278 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00109     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 4.79        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.35\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010399552 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00524     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.452       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 3.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.6969696969697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010822957 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.000947    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.65        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.8125\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -365       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 80         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01098644 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.76      |\n",
      "|    explained_variance   | -0.000107  |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.207      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0433    |\n",
      "|    value_loss           | 3.02       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.69230769230768\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013840458 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00312     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0603     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.23214285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015460931 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00298     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.82222222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013379283 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00648     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.84375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012166537 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0569      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.1764705882353\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010881777 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.0932      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.86        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.62962962962962\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011009565 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.8815789473684\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009086139 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0693      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.00833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008800493 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.287       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.34920634920636\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -355         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060585532 |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.63        |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.86         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.74621212121212\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007357782 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.268       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.8659420289855\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -352         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 291          |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072067184 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.56        |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.559        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    value_loss           | 2.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.82986111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -350         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077650947 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.52        |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.403        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 2.7          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.80666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007130972 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.47       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.75320512820514\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007160797 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.61111111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008295951 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.583       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008444566 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.44252873563218\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009005491 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.38611111111112\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007786395 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.14       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.332       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.36021505376345\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009160969 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.38802083333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -332        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008418726 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.52777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008643923 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.97        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.76960784313727\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -326        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008382887 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.802       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.92619047619047\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -323         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 439          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085950885 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.79        |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.72         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0413      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.9976851851852\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008005794 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.824       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.22072072072072\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -316         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 462          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073636947 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.65        |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.47149122807016\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008170534 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.927       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.60256410256412\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -309         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 82           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 484          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076781707 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.48        |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0436      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.7875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 495         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007590714 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.955       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.989837398374\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007375998 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.140873015873\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -298        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008085389 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.35852713178295\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -294         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 527          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075014583 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.1         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.806        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.6344696969697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -290        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007520159 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.95555555555555\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006729775 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.19021739130434\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 557         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006172507 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 3.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.36879432624113\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -279         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 566          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070197484 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.5625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -275        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007768335 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.873       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.78231292517006\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -271        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006780652 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.86166666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -268        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006460952 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.892       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.91993464052288\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -262        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006331097 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.97596153846155\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -257         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 610          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062825624 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0416      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.05817610062894\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -251         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 618          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063016387 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.61        |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0318      |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.04166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -245        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 625         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006138088 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.02424242424243\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -238         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 631          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058118524 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.96279761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -232         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 637          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062294696 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.44         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.91228070175438\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -226       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 90         |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 642        |\n",
      "|    total_timesteps      | 58368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00649296 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.4       |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.31       |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    value_loss           | 3.34       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.81896551724137\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -220       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 91         |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 648        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00705129 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.38      |\n",
      "|    explained_variance   | 0.65       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.31       |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.038     |\n",
      "|    value_loss           | 3.36       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.79237288135593\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -213        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006536745 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.7263888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -207         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 660          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057817595 |\n",
      "|    clip_fraction        | 0.0925       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.62021857923497\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -201         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 666          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062081777 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.25        |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.5268817204301\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -194         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 94           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 672          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062839845 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.4021164021164\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -187         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 678          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064991917 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.25911458333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -181        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 684         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007864509 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.07564102564103\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -175         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 690          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062571857 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.1         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.87247474747474\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -168         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 695          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069625303 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.66044776119404\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -162        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 701         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007081693 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.39705882352942\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -156        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 706         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005805296 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.12077294685992\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -150        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007046464 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.80833333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -143         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 714          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070030326 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.07        |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.5\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -137         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 719          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051035862 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.99         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0346      |\n",
      "|    value_loss           | 3.48         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.15162037037038\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -131       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 723        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00547936 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.02      |\n",
      "|    explained_variance   | 0.491      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.998      |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 3.18       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.7945205479452\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -124         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 727          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063017155 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0346      |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.43355855855856\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005970304 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.06333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -113         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 736          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062667485 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0334      |\n",
      "|    value_loss           | 3.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.68201754385964\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -107         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 740          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064793206 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.976        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.2694805194805\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -101        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 744         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006001205 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.8397435897436\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -95.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 749         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005711426 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.43037974683546\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 753         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006269959 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.00208333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -85.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 757          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073420247 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.53703703703704\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -80.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 762         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005776058 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.0721544715447\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -75.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006337933 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.5953815261044\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -71        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 770        |\n",
      "|    total_timesteps      | 84992      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00582478 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.93      |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.43       |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.0367    |\n",
      "|    value_loss           | 3.33       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.12301587301587\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -66.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006335891 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.6362745098039\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -63         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 779         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006800267 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.947       |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.1608527131783\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -58.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 783          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075800847 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.6772030651341\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -54.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 788         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005689873 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.91       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.1685606060606\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -51.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005677044 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 4.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.66385767790263\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -47.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 796         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006375399 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.13703703703703\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -43.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 801         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006464553 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.59615384615384\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -40.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 805         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005217519 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.04891304347825\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -37.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 809         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005725795 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.49462365591398\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -34.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 116          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 814          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053909672 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0308      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.94060283687944\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -31.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005650318 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.35701754385966\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -29.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 118          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 822          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063035283 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0372      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.7890625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -27.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 827         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006149886 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.19329896907217\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -24.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005462818 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.91       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.72        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.60799319727892\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -22.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 835         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005478408 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.01767676767676\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -20.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 839         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007557348 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.41666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -17.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 121          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 844          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076443376 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0335      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 96.78\n",
      "Overall Average Successful Assignments: 186.9519634782295\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "892349cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -376.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.25\n",
      "All assignments history: [12, 15, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -373     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -358.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 16.5\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -367         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062238574 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.124       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.95         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -270.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.72222222222222\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075654006 |\n",
      "|    clip_fraction        | 0.0895       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | 0.0557       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 12           |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -370.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.145833333333332\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069901748 |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | -0.00734     |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 9.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.1\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007926575 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.0678      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.19        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 8.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 65.59722222222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -368         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076482086 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | -0.0261      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.99         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 7.44         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 81.73809523809524\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008473813 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.0023      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.03        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 6.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 92.90625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -368         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090096705 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | -0.0097      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    value_loss           | 5.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 101.58333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009136934 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00885     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.876       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 4.63        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.85\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009469774 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | -8.94e-05   |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.954       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 4.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 115.07575757575758\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010340543 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | -0.00154    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 120.32638888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010101029 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.000202    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.343       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.91025641025641\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013817236 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00422     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 130.60119047619048\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013045904 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00317     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.9\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014761269 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00218     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.995       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.65625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013157286 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00734     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.748       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0561     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.88235294117646\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008835855 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0949      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.32        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.97685185185185\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009681193 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.0958      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.14        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.609649122807\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -358         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 19456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087403655 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.145        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | -0.0263      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.14166666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008731005 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.289       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.61904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008041783 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.8181818181818\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007470728 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.67753623188406\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008621732 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.60069444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008154818 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.773       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.48\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008494059 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.862       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.1602564102564\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -346        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008579057 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.45       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.74074074074073\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007671575 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.41       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.829       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.1904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008210181 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.63505747126436\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -339         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086133275 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.28        |\n",
      "|    explained_variance   | 0.252        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.318        |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0443      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.01388888888889\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -336       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00857106 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.18      |\n",
      "|    explained_variance   | 0.344      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.826      |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0477    |\n",
      "|    value_loss           | 2.99       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.36290322580646\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008226132 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.558       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.5390625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008302879 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.6818181818182\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -329         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077700885 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.98        |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.929        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0439      |\n",
      "|    value_loss           | 3.51         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.7941176470588\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -326        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008298276 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.91       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.879       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.7952380952381\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -323         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086907195 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.484        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.80555555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -321        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008642979 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.01126126126127\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008047849 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.1030701754386\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -314         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074129207 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.10256410256412\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -311        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008444654 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.54       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.09791666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -308        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008030124 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.20528455284554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -305        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009264329 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.37       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.30753968253967\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -301        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009174753 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.46124031007753\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -297       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 184        |\n",
      "|    total_timesteps      | 44032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00771019 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.22      |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.699      |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0463    |\n",
      "|    value_loss           | 2.9        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.62689393939394\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -294         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070317825 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.13        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0425      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.78333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -290         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080361385 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.04        |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.932        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0479      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.9003623188406\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007123878 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.07269503546098\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -282         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078873485 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.775        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0458      |\n",
      "|    value_loss           | 3.19         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.26215277777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -279         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072643533 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.88        |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.41326530612244\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -275         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064481376 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.78        |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.52333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -272         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074256468 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.78        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.036       |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.62908496732027\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -266         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063234754 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.77        |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.70673076923077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -260        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006760719 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.75786163522014\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -254        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006679574 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.8070987654321\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -248         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059486222 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.6         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.96         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.86818181818182\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -242        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007836509 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.89583333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -236        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006089974 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.87426900584796\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -230        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006385378 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.923       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.85488505747125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -224         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 249          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053247195 |\n",
      "|    clip_fraction        | 0.099        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.832        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.82627118644066\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -217         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073300777 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.7277777777778\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -211        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006768698 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.808       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.6051912568306\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -205         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 262          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065132366 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.29        |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.49193548387098\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -198         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062576067 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.041       |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.33597883597884\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -192       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 270        |\n",
      "|    total_timesteps      | 64512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00728317 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.16      |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.975      |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    value_loss           | 2.58       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.1796875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -186         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055257934 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.1         |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.01153846153846\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -180         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 279          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063870475 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.06        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.85858585858585\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -173        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005710993 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.65671641791045\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -167        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006881781 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.4607843137255\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -160        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005900938 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.27898550724638\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -154         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 296          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059887916 |\n",
      "|    clip_fraction        | 0.0999       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.07        |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.0690476190476\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -148         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068789218 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.07        |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.81455399061034\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -142        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006067834 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.05       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.58217592592592\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -135        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006193841 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.3173515981735\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -129       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 313        |\n",
      "|    total_timesteps      | 74752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00535914 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3         |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.38       |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 3.04       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.02702702702703\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -123         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060529113 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0332      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.6977777777778\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007395001 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.34978070175438\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -111         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068047973 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.99675324675326\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006586713 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.6303418803419\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -100         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066305306 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.24367088607596\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -95.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006991772 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.8375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007634241 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.41666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -85.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008186065 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.02337398373984\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -80.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006105784 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.60341365461846\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -75.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 356          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064816885 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.19444444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -70.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006264425 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.74313725490197\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -65.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008123758 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.265503875969\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -61.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 369          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069808736 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.8036398467433\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -57.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 373          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064487522 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0406      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.31723484848484\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -53.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060656955 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.95        |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.8426966292135\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -49.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006649769 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.35462962962964\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -45.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 386        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00746561 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.89      |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.3        |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.0352    |\n",
      "|    value_loss           | 3.41       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.84798534798534\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -42.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007475848 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.3360507246377\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -39.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006406473 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.828853046595\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -36.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 400          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076925997 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0348      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.32712765957447\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -33          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 404          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068887407 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.80263157894737\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -30.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005642605 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.26649305555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -28.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 413          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063666585 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.7233676975945\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -26          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 417          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055855094 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.16496598639455\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -23.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006600689 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.59259259259258\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -21.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 426         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006417719 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.03916666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -19.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 430          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062524285 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 91.6\n",
      "Overall Average Successful Assignments: 177.11146161895508\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "800d0217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -382.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 10.166666666666666\n",
      "All assignments history: [13, 19, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -368     |\n",
      "| time/              |          |\n",
      "|    fps             | 258      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -352.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 16.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007978009 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.135      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.63        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -290.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.694444444444443\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -373         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070852274 |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.106       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.84         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    value_loss           | 12.8         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -222.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.104166666666664\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -373         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077726934 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.0576       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.55         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 10.5         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.5\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -372         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075211376 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | -0.0231      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.33         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    value_loss           | 8.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 64.16666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008259045 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.00604    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.13        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 7.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 73.91666666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -370       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00830121 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.81      |\n",
      "|    explained_variance   | -0.00379   |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.69       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0365    |\n",
      "|    value_loss           | 6.68       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.98958333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008738565 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00779     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.908       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 5.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 98.54629629629629\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009543038 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0055      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 4.39        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.40833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010147281 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 4.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.84848484848484\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -365         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105973715 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.77        |\n",
      "|    explained_variance   | 0.00748      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0424      |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.39583333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011160829 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00398     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 130.85897435897436\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012418532 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00342     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.502       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.17261904761904\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -362         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155315995 |\n",
      "|    clip_fraction        | 0.3          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.00981      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.149        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0496      |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.9\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013065486 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0197      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.64        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.71875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012796046 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.0402      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0532     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.7549019607843\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -358         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103575615 |\n",
      "|    clip_fraction        | 0.206        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0.0978       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0414      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.56944444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009250157 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.18421052631578\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010098681 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.718       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.35833333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008117688 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.62       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.737       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.57142857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008388376 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.776       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.54924242424244\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008592971 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.54       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.4855072463768\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008654352 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.36458333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -346         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081232125 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.45        |\n",
      "|    explained_variance   | 0.232        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.754        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.08\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007886261 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.726       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.76923076923077\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -342         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074556386 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.33        |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.3672839506173\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813502 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.27       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.02380952380952\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007843399 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.7155172413793\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008220941 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.1        |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.20833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008715449 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.638       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.58064516129033\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -328       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 132        |\n",
      "|    total_timesteps      | 31744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00868755 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.95      |\n",
      "|    explained_variance   | 0.398      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.03       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0484    |\n",
      "|    value_loss           | 3.37       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.97395833333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -325         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075320755 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 2.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.44949494949495\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -321        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008197431 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.98529411764707\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -317         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076635513 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.69        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.986        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.045       |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.3357142857143\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -314        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008379487 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.971       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.8148148148148\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -310       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00860548 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.48      |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.934      |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0514    |\n",
      "|    value_loss           | 3.29       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.1283783783784\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006863376 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.4        |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.26973684210526\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008291788 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.933       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.51709401709402\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008642447 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.6625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -295        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008303525 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 3.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.8089430894309\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008841675 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.04166666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -287         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070580663 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.97        |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0439      |\n",
      "|    value_loss           | 3.48         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.16666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -283        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007699497 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.28977272727272\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -279        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006641535 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.48518518518517\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -275        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007139123 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.58333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -270         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072138477 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.828        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.75\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -267        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007506268 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.99826388888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -263        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008320869 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.59       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.973       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 2.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.16326530612244\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070725256 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.36833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -254        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007279274 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.54575163398692\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -248       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 219        |\n",
      "|    total_timesteps      | 52224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00813459 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.49      |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.37       |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.042     |\n",
      "|    value_loss           | 2.99       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.71314102564102\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -242         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075167944 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.787        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0418      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.86006289308176\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -235        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007204849 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.01543209876544\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -228         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073571927 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.06969696969696\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -222        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007472652 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.17708333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -215         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075011137 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0441      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.2748538011696\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -209        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007598138 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.32758620689654\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -203        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006396707 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.37429378531073\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -196         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071645314 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0327      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.38611111111112\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -189         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054152897 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.85         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 4.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.37978142076503\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -182         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 262          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076189907 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.04        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.32930107526883\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -175         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 267          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056138933 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.27380952380952\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -168       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 271        |\n",
      "|    total_timesteps      | 64512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00575005 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.01      |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.29       |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0366    |\n",
      "|    value_loss           | 3.4        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.15364583333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -162        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005859011 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.03589743589743\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005652359 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.9179292929293\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -148         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 285          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064802347 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0326      |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.72761194029852\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -142         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059532993 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 174.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.53676470588235\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -135        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006086855 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 3.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.3756038647343\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -128        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007292084 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 168.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.1261904761905\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -122         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 303          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057402495 |\n",
      "|    clip_fraction        | 0.0988       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.8450704225352\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -116         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 307          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065105124 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.94        |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.57         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.58333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065789474 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.95        |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.28881278538813\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006347603 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.98536036036037\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -97.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006421431 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.68\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006794161 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 172.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.34978070175438\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -84.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005400243 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.017316017316\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -79.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006554537 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 178.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 223.6741452991453\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -73.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066698166 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 178.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.33333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -68.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005562843 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 224.95625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -63.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 347          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064294552 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.74         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 225.6121399176955\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -58.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 352          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057565616 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 178.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.22560975609755\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -53.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006473557 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 176.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 226.83032128514057\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -48.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054488867 |\n",
      "|    clip_fraction        | 0.0938       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0315      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 178.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 227.42361111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -44.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059790276 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 180.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -39.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006876841 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 228.58527131782947\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -35.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005860567 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 229.1417624521073\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -32.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072346623 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 229.68939393939394\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -28.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006092393 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 230.23876404494382\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -24.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006135457 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 230.7490740740741\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -22         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006777312 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 231.29212454212455\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -18.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006417867 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 231.7871376811594\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -16.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 401          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066320496 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.68         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 232.29390681003585\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -13.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 405          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066750734 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 182.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 232.78546099290782\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -10.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006969494 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 233.27894736842106\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -8.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 414          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064588683 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0318      |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 233.76041666666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -5.92      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 418        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00572083 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.87      |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.15       |\n",
      "|    n_updates            | 950        |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    value_loss           | 3.12       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 234.2242268041237\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -3.84        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 423          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053755846 |\n",
      "|    clip_fraction        | 0.0972       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0317      |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 186.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 234.68112244897958\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -2           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 427          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068788384 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 188.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 235.1523569023569\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -0.22        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 432          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066535575 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 235.59333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 1.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 436          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059151435 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.878        |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 110.7\n",
      "Overall Average Successful Assignments: 184.03421305547658\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e90949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -382.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.75\n",
      "All assignments history: [10, 17, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -373     |\n",
      "| time/              |          |\n",
      "|    fps             | 256      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -278.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.458333333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007454997 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.202      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.92        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -220.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.833333333333336\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -371         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076008006 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.137       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.19         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 64.95833333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077877603 |\n",
      "|    clip_fraction        | 0.0949       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.0163       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.74         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 10.6         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 76.6\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -371       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 5120       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00751503 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.82      |\n",
      "|    explained_variance   | 0.0229     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.47       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    value_loss           | 9.29       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 90.70833333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077694408 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | -0.0334      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.87         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 8.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 101.16666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009280734 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | -0.0102     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 6.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 104.69791666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008573425 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0099      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 5.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 104.76851851851852\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009203139 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | -0.00287    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 5.33        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011317259 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00743     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.746       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 3.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 111.26515151515152\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -368      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 233       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 11264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0105679 |\n",
      "|    clip_fraction        | 0.214     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -5.77     |\n",
      "|    explained_variance   | -0.00149  |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.13      |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -0.0428   |\n",
      "|    value_loss           | 3.65      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.34722222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011152409 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00464     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.218       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 119.49358974358974\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014260918 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.76        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.16666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011668329 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00197     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 126.18888888888888\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016238526 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.00852     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.374       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.99479166666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -363       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01158743 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.72      |\n",
      "|    explained_variance   | 0.0375     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.48       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.044     |\n",
      "|    value_loss           | 2.93       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.61274509803923\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010644149 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.0768      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.638       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.00462962962962\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009719079 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.10087719298247\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009451307 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.94166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009864498 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.307       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.72619047619048\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009102806 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.302       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.52651515151516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009778636 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.30797101449275\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009621822 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.51       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.501       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.89930555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008027347 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.47       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.56333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008939169 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.838       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.96794871794873\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007949028 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.628       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.27777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008408618 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.31       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.6547619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009261504 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.02586206896552\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -336         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082886685 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.16        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0427      |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.50833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009094352 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.1        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.954       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.0779569892473\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008338235 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.68229166666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -327        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008338258 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.32575757575756\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -324        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007986993 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.572       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.76225490196077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008296595 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.719       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.29285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007023801 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.80324074074073\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -313       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 158        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00880749 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.62      |\n",
      "|    explained_variance   | 0.58       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.96       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0456    |\n",
      "|    value_loss           | 3.4        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.3063063063063\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -309         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078151785 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.52        |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.7280701754386\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -305        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007621331 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.17307692307693\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073549603 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.35        |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0427      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.59375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -298         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069070673 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.3         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.888        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.0630081300813\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -295        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008293185 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.958       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.5079365079365\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -291         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 184          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068046832 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.87403100775194\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -288      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 232       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 189       |\n",
      "|    total_timesteps      | 44032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0068207 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -4.13     |\n",
      "|    explained_variance   | 0.7       |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.16      |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -0.0385   |\n",
      "|    value_loss           | 2.9       |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.2310606060606\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008470554 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.5222222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008063098 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.01       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.752       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 2.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.76992753623188\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -278       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 232        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00709957 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.95      |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.22       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.041     |\n",
      "|    value_loss           | 3          |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.07624113475177\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -274         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064115073 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.41840277777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -270        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008356737 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.66496598639455\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -267        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007070238 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.921       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.90166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -264        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008614544 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.961       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.20915032679738\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075638946 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.629        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0412      |\n",
      "|    value_loss           | 2.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.4551282051282\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -252        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007183158 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.63993710691824\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -246        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007670355 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.80246913580248\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -240         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069977837 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.57        |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.953        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.9212121212121\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -234        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007831989 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.0282738095238\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -228         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 246          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069247847 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.52        |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0381      |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.14619883040936\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -222         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068054115 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.47        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 2.67         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.26005747126436\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -215         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071016653 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0411      |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.3276836158192\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -209        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008228606 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.36111111111111\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -203       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 232        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 264        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00786209 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.4       |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.31       |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    value_loss           | 3.09       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.37841530054644\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -197        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008276945 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.765       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    value_loss           | 2.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.3790322580645\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -191        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007143542 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.3558201058201\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -185         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 277          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064717424 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0422      |\n",
      "|    value_loss           | 3.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.37109375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -178         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067553967 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.3371794871795\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009100204 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.25757575757575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -166        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007295126 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.707       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.1492537313433\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -160         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074339034 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.979        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0424      |\n",
      "|    value_loss           | 2.67         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.05024509803923\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -154        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006321638 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.89371980676327\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -147       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 70656      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00702957 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.17      |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.65       |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0418    |\n",
      "|    value_loss           | 3.4        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.7654761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -141        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007613176 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.6455399061033\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -135         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 310          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075085163 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.46990740740742\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -129         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 314          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061302893 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 154.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.25114155251143\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -124         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063141095 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.32         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.06193693693695\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008009113 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.977       |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.84222222222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065989336 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.65021929824562\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -107        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006447112 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.992       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 2.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.43073593073592\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -101         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063301297 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.358        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.19337606837607\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -96.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062851105 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.9493670886076\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006966563 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.7\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -86          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 346          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076166326 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.41460905349794\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -80.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 350          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067215217 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.1138211382114\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -76.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 354          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064136665 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.95        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.79618473895582\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -72.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005844053 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.47420634920636\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -68          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 363          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067644236 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.94        |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.1627450980392\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -62.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 366          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060461313 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 214.8032945736434\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -59.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005839125 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 215.44731800766283\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -55.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063799303 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.87         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 2.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.0681818181818\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -51.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 377          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061622923 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 216.68445692883896\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -48.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006927017 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.28703703703704\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -44.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 384          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078089545 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 217.88553113553112\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -40.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 388          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070113963 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 218.46648550724638\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -36.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006062748 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.02777777777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -33.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 395          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054213833 |\n",
      "|    clip_fraction        | 0.0883       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.031       |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 166.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 219.5709219858156\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -30.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 399          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063181664 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.09122807017545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -27.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005428142 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 220.61458333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -24.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 406          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062699616 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.1151202749141\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -22.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 410          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066573303 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.985        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 164.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 221.61904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -20         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006241399 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 162.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.09343434343435\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -17.7     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 242       |\n",
      "|    iterations           | 99        |\n",
      "|    time_elapsed         | 417       |\n",
      "|    total_timesteps      | 101376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0062456 |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -2.85     |\n",
      "|    explained_variance   | 0.399     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 0.87      |\n",
      "|    n_updates            | 980       |\n",
      "|    policy_gradient_loss | -0.0346   |\n",
      "|    value_loss           | 3.08      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 222.5525\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -15.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 420          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065724915 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 2.82         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 82.0\n",
      "Overall Average Successful Assignments: 171.42237653228983\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b9fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
