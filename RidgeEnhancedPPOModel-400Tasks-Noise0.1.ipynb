{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c8bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8967544998516832\n",
      "RMSE: 1.1358026956536529\n",
      "R-squared: 0.991274663358528\n",
      "RAE: 0.09365725311592739\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=['Eligible'])\n",
    "    y = data['Eligible']\n",
    "    return X, y\n",
    "\n",
    "def train_ridge_model(X_train, y_train):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    ridge_model = Ridge()\n",
    "    ridge_model.fit(X_train_scaled, y_train)\n",
    "    return ridge_model, scaler\n",
    "\n",
    "# Load and train on VehicleTrainingDataset.csv\n",
    "X_train, y_train = load_and_preprocess_data('VehicleTrainingDataset_Noisy_0.1.csv')\n",
    "ridge_model, scaler = train_ridge_model(X_train, y_train)\n",
    "\n",
    "# Predict eligibility scores on 1000VehicleDataset.csv\n",
    "vehicles_df = pd.read_csv('1000VehicleDataset_Noisy_0.1.csv')\n",
    "X_test = vehicles_df.drop(columns=['Eligible'])\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "predicted_scores = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# Assuming you have access to actual scores, replace this line with the actual score loading logic if available\n",
    "y_actual = vehicles_df['Eligible']  # This would be prior to overwriting with predictions if you run this block again\n",
    "\n",
    "# Replace actual scores with predicted ones\n",
    "vehicles_df['Eligible'] = predicted_scores  \n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_actual, predicted_scores)\n",
    "rmse = np.sqrt(mean_squared_error(y_actual, predicted_scores))\n",
    "r_squared = r2_score(y_actual, predicted_scores)\n",
    "rae = np.sum(np.abs(y_actual - predicted_scores)) / np.sum(np.abs(y_actual - np.mean(y_actual)))\n",
    "\n",
    "# Output the results\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "print(f\"RAE: {rae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6781b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -386.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.833333333333333\n",
      "All assignments history: [13, 11, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -376     |\n",
      "| time/              |          |\n",
      "|    fps             | 70       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -288.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.291666666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -376         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071727214 |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.287       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.3          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -336.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.583333333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007000285 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.0188     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -300.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.458333333333336\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -373         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064591076 |\n",
      "|    clip_fraction        | 0.0841       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.0106       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.84         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0372      |\n",
      "|    value_loss           | 9.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.8\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007082169 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.06        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 8.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 59.31944444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008613059 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0552      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 7.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 66.94047619047619\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069620954 |\n",
      "|    clip_fraction        | 0.0961       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | 0.0115       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 6.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 72.61458333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009513055 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0216      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 4.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 77.79629629629629\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -368         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089554805 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 4.81         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 82.175\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009944873 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.668       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 85.79545454545455\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010468524 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 90.66666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011228526 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0149      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.392       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 97.4551282051282\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -364       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 13312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01313927 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.75      |\n",
      "|    explained_variance   | 0.0155     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.439      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0467    |\n",
      "|    value_loss           | 2.92       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 103.4702380952381\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -363         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132181775 |\n",
      "|    clip_fraction        | 0.264        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.397        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.047       |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 109.89444444444445\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012455983 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0884      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.817       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0505     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 115.70833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011717616 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 120.62745098039215\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011499462 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.945       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.04166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010806534 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.243       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.9561403508772\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010383686 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 4.31        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.3125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009592975 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.23809523809524\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009401944 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.8560606060606\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007886035 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.985       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.17028985507247\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007955129 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.46180555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 441         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009274814 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.181       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.51\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -350         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 461          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070731454 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.53        |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.819        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.31410256410257\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009655811 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.37        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.05555555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -346        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008731947 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.43       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.7529761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007993036 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.23        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.52011494252875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007885716 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.353       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.25555555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 556         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008872798 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.51        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.88172043010752\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 573         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008667214 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.25       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.917       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.46875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008704385 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.18       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.9671717171717\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 608         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009316025 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.722       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.3406862745098\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009014888 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.644       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.57380952380953\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009727117 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.865       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.76388888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 669         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009453535 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.409       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0525     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 690         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010084881 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0508     |\n",
      "|    value_loss           | 2.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.33552631578948\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -320         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 709          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074381093 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.83        |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.78         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0456      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.6260683760684\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -317         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 729          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077069607 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.78        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.876        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0454      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.85208333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -315         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081171505 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.865        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0469      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.1117886178862\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 768         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008611907 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.718       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0517     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.3531746031746\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -309         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 788          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079235695 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.52        |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0492      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.61046511627907\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 807         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008043044 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.48       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.85227272727272\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -303        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008632272 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.41       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.0888888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -300         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 846          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079657445 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.32        |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.898        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0472      |\n",
      "|    value_loss           | 2.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.2554347826087\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 865         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007996943 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.27       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.34574468085106\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -294        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 885         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008156443 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.97        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.48784722222223\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -290      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 902       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0091583 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -4.12     |\n",
      "|    explained_variance   | 0.386     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.23      |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -0.05     |\n",
      "|    value_loss           | 3.28      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.5578231292517\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -287        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 923         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008175001 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.63333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -284         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 942          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086539835 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.03        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.927        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0426      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.69771241830065\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -279        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 962         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008234576 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.72756410256412\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -273        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 981         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007188052 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.68867924528303\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -268        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1001        |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007889449 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.69907407407408\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -262        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1019        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008075792 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.876       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0491     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.6681818181818\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -258        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1040        |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007578149 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.61458333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -252         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 1062         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069682263 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.81        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.5921052631579\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -246        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1085        |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008291985 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.853       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.55172413793105\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -240        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1108        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008016695 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.989       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.50423728813558\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -235       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 1130       |\n",
      "|    total_timesteps      | 60416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00787087 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.76      |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.15       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    value_loss           | 3.61       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.41944444444445\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -230        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007194268 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 3.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.34016393442624\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -224         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1169         |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072776373 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0422      |\n",
      "|    value_loss           | 3.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.18010752688173\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -219        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1190        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006370419 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.00925925925927\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -213        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1212        |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008212006 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.84765625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -208         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1233         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076484075 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.52        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0447      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.68333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -202         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1256         |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067057586 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.47348484848484\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -196        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1277        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006353104 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.26243781094527\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -190        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006883125 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 3.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.0392156862745\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -185       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 1319       |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00736882 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.46      |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.41       |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    value_loss           | 3.58       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.79830917874395\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1341        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009126838 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.55238095238096\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -173        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1362        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006875309 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.28403755868544\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -168        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1383        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007568208 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.9537037037037\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -163       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 1405       |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00709393 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.48      |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.54       |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 3.25       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.6415525114155\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -158         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1428         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073528886 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.28153153153153\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -153         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1447         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065254383 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0421      |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.96777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -148        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1468        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006596986 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.983       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.59320175438597\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -143         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1487         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075554065 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.43        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.228354978355\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1508        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007875459 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.84294871794873\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -133         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1531         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071639856 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0428      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.47784810126583\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -128         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1552         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069102934 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.09583333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -123         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1574         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072509227 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.6923868312757\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -119       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 1596       |\n",
      "|    total_timesteps      | 82944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00655734 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.34      |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.56       |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    value_loss           | 3.37       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.28760162601625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -115        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1618        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006610384 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.89156626506025\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -110      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 51        |\n",
      "|    iterations           | 83        |\n",
      "|    time_elapsed         | 1639      |\n",
      "|    total_timesteps      | 84992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0068571 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.27     |\n",
      "|    explained_variance   | 0.535     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.22      |\n",
      "|    n_updates            | 820       |\n",
      "|    policy_gradient_loss | -0.0388   |\n",
      "|    value_loss           | 3.62      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.47222222222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -106         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1661         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073898025 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.23        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.05196078431374\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1682        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005553048 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.62306201550388\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -97.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1703         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062673697 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.23        |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.17049808429118\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -93.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1725         |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068750936 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.69886363636363\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1747        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005851143 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 3.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.22284644194755\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -86.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1768        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006077676 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.74537037037038\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -82.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1789         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059884763 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0349      |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.24358974358975\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -78.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1810        |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005864485 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.75634057971016\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -75.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1830        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006211168 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.2948028673835\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -71.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1849        |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006570913 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.77570921985816\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -68.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1869        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006615966 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.28157894736842\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -65.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1887         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067908727 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.77604166666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -62.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1906         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059212055 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 3.44         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.24742268041237\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -59.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1928         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064153858 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.04        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.902        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0381      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.70238095238096\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -57.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1950         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064087743 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.06        |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0335      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.13215488215488\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -55.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 1970         |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062552933 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.06        |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.56916666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -52.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1990        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005922482 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 66.24\n",
      "Overall Average Successful Assignments: 163.61333535601958\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcbc1f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -384.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 8.833333333333334\n",
      "All assignments history: [9, 17, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -374     |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -372.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 11.833333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007867735 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.0525     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -396.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.166666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008281234 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.101      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -344.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.4375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074533774 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0.00442      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.94         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 9.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -296.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.95\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008815123 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0646      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 8.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.208333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008018622 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 7.24        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 64.85714285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009100309 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 5.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 79.07291666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -365         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084622875 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.0128       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 5.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 90.02777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009654338 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00432     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 4.01        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 98.78333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010394647 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00621     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.56        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.96969696969697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010342073 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00726     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 111.91666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011535952 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00782     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0721      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.9551282051282\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -363       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 13312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01076385 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.73      |\n",
      "|    explained_variance   | 0.00857    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.0746     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0374    |\n",
      "|    value_loss           | 2.82       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 121.30357142857143\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013898744 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0868     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.07777777777778\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012242204 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0428      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.01        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.38541666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011226589 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0556     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.38725490196077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010688565 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0334     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.99537037037038\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -359       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 339        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00910845 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.69      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.367      |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0451    |\n",
      "|    value_loss           | 2.9        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.37719298245614\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009403742 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.321       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.60416666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009435777 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.593       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.5873015873016\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009387183 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.62       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.328       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.43560606060606\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009490839 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.571       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.1159420289855\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 430         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008632643 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.18        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -350         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 449          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083970465 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.54        |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.33         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0463      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.07666666666665\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009157866 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.01        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 2.49        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.38141025641025\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007987559 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.47       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.366       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.71604938271605\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008508982 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.59        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.02083333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008515413 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.861       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.33620689655172\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -341         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085161235 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.31        |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.39         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0448      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.60555555555555\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 560         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007088451 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.25       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.956       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.76075268817203\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -336         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 579          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077064373 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.18        |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.996        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.80729166666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007675424 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.1        |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.688       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.86363636363637\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -331         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 616          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073268497 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.851        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0421      |\n",
      "|    value_loss           | 3.14         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.99754901960785\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006762107 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.1642857142857\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -325         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 651          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084480485 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.85        |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.803        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0447      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.3287037037037\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -322        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 669         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008016951 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.75       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.47747747747746\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -318        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 688         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007403217 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.64       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.62061403508773\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -315         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 706          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071829082 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.56        |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0423      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.67948717948718\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 726         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006995054 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.65416666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -308        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 746         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008590942 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.42       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.6321138211382\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -305        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 765         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008196216 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.33       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.62698412698413\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 783          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064862063 |\n",
      "|    clip_fraction        | 0.0999       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.25        |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0381      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.6531007751938\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -298        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 801         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007755763 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.66477272727272\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -294         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 820          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077154357 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.11        |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0427      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.65555555555557\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 839         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007298451 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.6014492753623\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -288        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 856         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007052423 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.52836879432624\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -285         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 875          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076189414 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.97        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0422      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.43055555555554\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -282       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 894        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00562088 |\n",
      "|    clip_fraction        | 0.0926     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.91      |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.51       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0367    |\n",
      "|    value_loss           | 3.4        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.38095238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -279        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 912         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006218684 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.305\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -276        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 931         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007819944 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.218954248366\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -271        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009221077 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.87        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 2.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.10576923076923\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -266        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 967         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005904242 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.9433962264151\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -260        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 984         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007142556 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.77314814814815\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -255         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 1001         |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072584217 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.57575757575756\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -250        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1019        |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007318499 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.864       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.40029761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -244         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 1036         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072713126 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.67        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0418      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.26608187134502\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -238         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1054         |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072292965 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.64        |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.13074712643677\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -233        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1071        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007696846 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.00423728813558\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -228        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1088        |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006778451 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.86805555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -223        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1105        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006984614 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.71584699453553\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -217         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1123         |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082508875 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.65        |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.914        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.51344086021504\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -211        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1140        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007193829 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.84        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.32275132275132\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -206        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007825817 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.109375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1174         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071786363 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.59        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.87820512820514\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -195        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1192        |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007676784 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.65277777777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -190         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 1209         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070435237 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.57        |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0398      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.40174129353233\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -185         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1226         |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062101446 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.55        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.929        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0359      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.15441176470588\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -180         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1243         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072981715 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.55        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.90821256038646\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -174        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1260        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007273341 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.62857142857143\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -170         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 1277         |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073133744 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.57        |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.33802816901408\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -165        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1294        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006705099 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.857       |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.1064814814815\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -159        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1311        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006364842 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.7945205479452\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -154        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1329        |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007896455 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.48085585585585\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -149         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1344         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064381836 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.16333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -145        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1362        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007542353 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.799       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.8607456140351\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -139        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1379        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006788492 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.879       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.53246753246754\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -135      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 77        |\n",
      "|    time_elapsed         | 1396      |\n",
      "|    total_timesteps      | 78848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0084205 |\n",
      "|    clip_fraction        | 0.146     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.47     |\n",
      "|    explained_variance   | 0.444     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.17      |\n",
      "|    n_updates            | 760       |\n",
      "|    policy_gradient_loss | -0.0405   |\n",
      "|    value_loss           | 2.88      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.19337606837607\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -131         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1413         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070748245 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 2.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.8438818565401\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -126         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1430         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075216303 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.851        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 2.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.484375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -122        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1448        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008022197 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.1059670781893\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1465        |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006741192 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.7428861788618\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -114         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1481         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071850903 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.879        |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 2.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.38052208835342\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1499        |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007328976 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.764       |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.00992063492063\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -107         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1515         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063403966 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 2.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.65686274509804\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1533        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006069445 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.26162790697674\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -100       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 1550       |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00662428 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.31      |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.31       |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.0364    |\n",
      "|    value_loss           | 2.83       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.838122605364\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -97.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1566        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007525611 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.972       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.42708333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -93.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1584        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006488439 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.99719101123594\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -90.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1601         |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065570557 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.5675925925926\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -87.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1618         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077079246 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.12545787545787\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -85.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1637         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066681756 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.988        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.64039855072463\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -82.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1654         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075203334 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.17831541218638\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -80          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1673         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069400603 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.12        |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.69         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 3.51         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.70035460992906\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -77.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1690         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072357766 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.22368421052633\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -75        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 1708       |\n",
      "|    total_timesteps      | 97280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00548214 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.06      |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.43       |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 3.15       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.72395833333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -72.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1726         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064042984 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.07        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0335      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.2242268041237\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -70.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1743        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006267326 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.06       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.71428571428572\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -67.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1761         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066422047 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.2020202020202\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -65.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 1778         |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065798033 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.68666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -63.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1796        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005912396 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 54.72\n",
      "Overall Average Successful Assignments: 161.45652958266697\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d39aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -390.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 6.5\n",
      "All assignments history: [13, 15, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -372     |\n",
      "| time/              |          |\n",
      "|    fps             | 69       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -324.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.416666666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007000914 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.249      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.11        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -308.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.055555555555557\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -372      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 62        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 3072      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0087169 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -5.83     |\n",
      "|    explained_variance   | -0.215    |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.63      |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -0.0411   |\n",
      "|    value_loss           | 12.1      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.0625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007993646 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.0317     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.42        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -206.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 55.86666666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -372         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085937325 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | -0.108       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.29         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 8.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -160.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 63.708333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008433975 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.0353      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 7.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 75.77380952380952\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -371       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 115        |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00912098 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.8       |\n",
      "|    explained_variance   | -0.0193    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.52       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    value_loss           | 6.39       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 84.08333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008089716 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | -0.00272    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 5.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 89.74074074074075\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009125814 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00142     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 4.7         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.55\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010392476 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | -0.000429   |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.926       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 3.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 103.93939393939394\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010506597 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00109     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 110.04861111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012219183 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00267     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 115.18589743589743\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011233663 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00412     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 119.23214285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016622407 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.000765    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0165      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0512     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.10555555555555\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013900032 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.00419     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 126.59375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011050688 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.69117647058823\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010577867 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.6064814814815\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009560424 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0457     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.15350877192984\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010139363 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.197       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.57916666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -357         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073107984 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.64        |\n",
      "|    explained_variance   | 0.232        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.983        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.61507936507937\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007994234 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.56060606060606\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -354         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 368          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087508615 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.56        |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.896        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    value_loss           | 2.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.3659420289855\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -353       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 385        |\n",
      "|    total_timesteps      | 23552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00729446 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.53      |\n",
      "|    explained_variance   | 0.348      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.834      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0357    |\n",
      "|    value_loss           | 2.91       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.10416666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007418897 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.72\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -349         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 420          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076733627 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.44        |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.787        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.2051282051282\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006833949 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.613       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.57716049382717\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008508876 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.85416666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806586 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.29       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.06896551724137\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008702247 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.638       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.3\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386076 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.18       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.519       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.4247311827957\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248804 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.11       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.484375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -332        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009085245 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.694       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.56060606060606\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -329         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 558          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087487865 |\n",
      "|    clip_fraction        | 0.186        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.93        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.26         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.047       |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.6299019607843\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -327        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008109254 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.88       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.786       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.81190476190477\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -324        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009069174 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.9         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.97685185185185\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -321         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 610          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077256374 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.73        |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.646        |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.1644144144144\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008074338 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.38815789473685\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -314        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 645         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007957816 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.51923076923077\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -311       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 663        |\n",
      "|    total_timesteps      | 39936      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00843036 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.48      |\n",
      "|    explained_variance   | 0.641      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.958      |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0467    |\n",
      "|    value_loss           | 2.86       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.58958333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -307        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007853627 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.4        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.7012195121951\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -304        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007649399 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 3.58        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.81150793650792\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -301        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007829843 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.78100775193798\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007891254 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.7689393939394\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -294       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 749        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00715214 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.1       |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.838      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0431    |\n",
      "|    value_loss           | 3.35       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.7574074074074\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -291         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 767          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070376634 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.03        |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0424      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.83514492753622\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -287         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 784          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073357057 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.97        |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0429      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.80851063829786\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -284         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 801          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085612815 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.80034722222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -280        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 819         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007271705 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.77891156462584\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -277         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 836          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066781477 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.89        |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.77166666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -274         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 854          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067533194 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.83        |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.73529411764707\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -268        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 871         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007923577 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.70833333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -263         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 889          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074906703 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.88        |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.71069182389937\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 906          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070633446 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.78        |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0431      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.6358024691358\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -252       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 924        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00772895 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.78      |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.16       |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 3.29       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.58939393939394\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -246         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 941          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072145555 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.74        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 2.73         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.5297619047619\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -241       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 958        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00709224 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.72      |\n",
      "|    explained_variance   | 0.531      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.2        |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0411    |\n",
      "|    value_loss           | 3.23       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.46491228070175\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -236        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 975         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007558522 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.40086206896552\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -230        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 991         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007815592 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.808       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.29237288135593\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -225         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 1009         |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067341328 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.67        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.15972222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -219        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1026        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006273648 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.95491803278688\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -214        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1044        |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007108215 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.76344086021504\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -209        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006523623 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.5515873015873\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -203         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 1077         |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060107014 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.36328125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -198        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1094        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006379466 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.964       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.17435897435897\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -192       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 1112       |\n",
      "|    total_timesteps      | 66560      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00666508 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.53      |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.4        |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    value_loss           | 3.16       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.97222222222223\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -187         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 1129         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064097214 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.79726368159203\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -181         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1145         |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071433606 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.59313725490196\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -176         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1163         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061830003 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.52        |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.78         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.3671497584541\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -171        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1179        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006627603 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.1297619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -166        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1196        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005932438 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.92840375586854\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -160        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1213        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006048156 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.99        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.76157407407408\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006781324 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.587899543379\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -149         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1250         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055687213 |\n",
      "|    clip_fraction        | 0.0979       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.41        |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.39977477477478\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -144        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1269        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006554257 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.18555555555557\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -140        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1288        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005759893 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.94078947368422\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -135        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1307        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006135423 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 3.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.6904761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -130        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1325        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006599283 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.41239316239316\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -125        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1344        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006274225 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.06751054852322\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -121        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1363        |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005867553 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.967       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.77395833333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -117         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1381         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065729422 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.41975308641975\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1400        |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006753387 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.08130081300814\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -108        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1418        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006383815 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.7058232931727\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -104         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1435         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067981244 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.32440476190476\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -100         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1453         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055491487 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.95294117647057\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -96.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1471         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069369115 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.54651162790697\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -93.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1490         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056587327 |\n",
      "|    clip_fraction        | 0.0932       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0327      |\n",
      "|    value_loss           | 3.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.15134099616859\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1509        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006151995 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.7528409090909\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -86.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1527        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005584386 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.3323970037453\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -83.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1547        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006349783 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.87314814814815\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -80.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1565         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053526387 |\n",
      "|    clip_fraction        | 0.0959       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.23        |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0326      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.42307692307693\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -77.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1585         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061487313 |\n",
      "|    clip_fraction        | 0.0962       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.92         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0315      |\n",
      "|    value_loss           | 3.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.98641304347825\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -75.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1604        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005316688 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 3.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.52329749103941\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -72.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1623         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058872206 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.0700354609929\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -69.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1641        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006246429 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.60087719298247\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -67.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1660         |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056415154 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.12152777777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -65.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1679         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060603977 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.6443298969072\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -63.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1697        |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006174771 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 3.7         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.1377551020408\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -61.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1717        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005628464 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 3.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.6077441077441\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -60.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1735        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005795082 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.09416666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -58.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1754         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057749264 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.09        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.93         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 4.29         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 59.8\n",
      "Overall Average Successful Assignments: 163.4062121453817\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4377bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -384.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.0\n",
      "All assignments history: [16, 12, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -372     |\n",
      "| time/              |          |\n",
      "|    fps             | 57       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -318.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.541666666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007904239 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.0857     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.43        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -366.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.61111111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -373         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075352285 |\n",
      "|    clip_fraction        | 0.0972       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.0686       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.81         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 12.1         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -302.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.104166666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008004585 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0331      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.04        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 9.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -386.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.5\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -374         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074957744 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0.0621       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 8.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.93055555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008797478 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.00236     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 7.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.88095238095238\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -373         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088846125 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | 0.0316       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    value_loss           | 6.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 69.11458333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009128958 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0227      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 5.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 81.07407407407408\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009986168 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.683       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 4.22        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 88.04166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010320766 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.16666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010666999 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.552       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 102.91666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010777788 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.03        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 108.6923076923077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013836179 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.44        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0492     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.08928571428571\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011305872 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0563      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.97        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 117.13888888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011931671 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0844      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.4         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 121.0625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011477025 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.6078431372549\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -362         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099745495 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.897        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.77777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009921525 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.429       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 130.49561403508773\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009630946 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.1\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009835519 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.62       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.689       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.40873015873015\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009543986 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.54166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008390926 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.52173913043478\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -354       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 423        |\n",
      "|    total_timesteps      | 23552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00871533 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.51      |\n",
      "|    explained_variance   | 0.239      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.878      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0423    |\n",
      "|    value_loss           | 3.18       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009522324 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.16666666666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -352       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 460        |\n",
      "|    total_timesteps      | 25600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00789336 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.45      |\n",
      "|    explained_variance   | 0.331      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.369      |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0417    |\n",
      "|    value_loss           | 2.98       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.8846153846154\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009118572 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.41358024691357\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -347         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 498          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074928026 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.34        |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.629        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.041       |\n",
      "|    value_loss           | 3.67         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.8720238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009772635 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.29       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.594       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.3477011494253\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008419645 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.547       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.83333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008494889 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.744       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.16129032258064\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008658994 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.629       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.38802083333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -334       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 588        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00806284 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.05      |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.3        |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 2.99       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.58333333333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -332       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 605        |\n",
      "|    total_timesteps      | 33792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00928531 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.98      |\n",
      "|    explained_variance   | 0.413      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.57       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0467    |\n",
      "|    value_loss           | 2.99       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.78676470588235\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 622         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008189232 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.9\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -326        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008567161 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.16203703703704\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 657         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008948563 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.627       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.3108108108108\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 676         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008401618 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.99        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0469     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.390350877193\n",
      "All assignments history: []\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 400      |\n",
      "|    ep_rew_mean          | -317     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 56       |\n",
      "|    iterations           | 38       |\n",
      "|    time_elapsed         | 694      |\n",
      "|    total_timesteps      | 38912    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.008961 |\n",
      "|    clip_fraction        | 0.179    |\n",
      "|    clip_range           | 0.15     |\n",
      "|    entropy_loss         | -4.59    |\n",
      "|    explained_variance   | 0.542    |\n",
      "|    learning_rate        | 0.00018  |\n",
      "|    loss                 | 0.879    |\n",
      "|    n_updates            | 370      |\n",
      "|    policy_gradient_loss | -0.0468  |\n",
      "|    value_loss           | 3.1      |\n",
      "--------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.44017094017093\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -313        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 713         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007756206 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.772       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.45\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -310        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008281313 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.5121951219512\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -307        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007864544 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.34       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.69642857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -303        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 769         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008213516 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.33       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.795       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.9031007751938\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -300        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 788         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008320791 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.09848484848484\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -297         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 807          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076507293 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.28        |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.35925925925926\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -294        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 825         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008051684 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.68478260869566\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 843         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008488855 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0499     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.9450354609929\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -288        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 861         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006518537 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.15451388888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -284         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 880          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070643155 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.07        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0472      |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.44897959183675\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 899         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007829981 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.685\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -278         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 917          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077950153 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.96        |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.937        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 2.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.95098039215685\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -273        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 937         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007763819 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.853       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.17948717948718\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -267        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 954         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007954108 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.37735849056602\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -262        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 974         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007647609 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.570987654321\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -257        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 993         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008522576 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.976       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.74848484848485\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -251         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 1012         |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075181187 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.90178571428572\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -246         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 1031         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069896886 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.7         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.94005847953215\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -240         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1049         |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067127934 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.05603448275863\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -234         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1069         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070822486 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0381      |\n",
      "|    value_loss           | 3.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.1271186440678\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -229         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 1088         |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055442434 |\n",
      "|    clip_fraction        | 0.0841       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.55        |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.1625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -223         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 1106         |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066197263 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0321      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.2308743169399\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -217         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1126         |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062563433 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.51        |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.033       |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.2486559139785\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -212         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1144         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053178025 |\n",
      "|    clip_fraction        | 0.0839       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 3.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.24603174603175\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -206        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1162        |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006645593 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.1953125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1181         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065568076 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0371      |\n",
      "|    value_loss           | 3.45         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.11282051282052\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -195        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1200        |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006447432 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.01388888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -189        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1218        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006037183 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.91542288557213\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -183         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1237         |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060746125 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.81985294117646\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1256        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006335238 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.67874396135267\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1276        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006928255 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.55119047619047\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -166        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1297        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005618219 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.3532863849765\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -160        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1315        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005256373 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 3.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.15509259259258\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1334        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006440042 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.88584474885846\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -149         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1353         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064208736 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.69         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.5990990990991\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -143         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1371         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056055877 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.23        |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.32444444444445\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -138         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1390         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059695393 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.68         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0297      |\n",
      "|    value_loss           | 3.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.03837719298247\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -133         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1407         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061444854 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.7207792207792\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -128        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1424        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004856024 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 3.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.42521367521368\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -123        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1442        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005442217 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 3.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.07489451476792\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1460        |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006712704 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.71145833333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1476        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006051427 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.29732510288065\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1494        |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006639562 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.99        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 4.14        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.8739837398374\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1511        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006060361 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.5070281124498\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -100         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1529         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067070415 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 3.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.13392857142858\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -95.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1547         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061432184 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0332      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.71372549019608\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -91.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1563        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006472774 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.27906976744185\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -88.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 1582       |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00575227 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.05      |\n",
      "|    explained_variance   | 0.594      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.7        |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 3.59       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.82375478927204\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -84.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1598        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008217819 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.39299242424244\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -81          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1616         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067497427 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.94007490636704\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -78.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1633        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007307154 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.48611111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -75         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1652        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005748542 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 3.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.01098901098902\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -72.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1671         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056274678 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0336      |\n",
      "|    value_loss           | 4.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.52445652173913\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -70          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1690         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071222177 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.8          |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0311      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.04121863799284\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -67.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1708         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069083543 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 3.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.52570921985816\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -64.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1727         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064591165 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.036       |\n",
      "|    value_loss           | 3.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.02105263157895\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -62.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1744        |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005657659 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 3.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.51649305555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -59.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1763         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065857116 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0298      |\n",
      "|    value_loss           | 3.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.99570446735396\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -57          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1783         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061517945 |\n",
      "|    clip_fraction        | 0.0967       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    value_loss           | 3.8          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.4778911564626\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -54.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1801         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061273603 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.75         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0317      |\n",
      "|    value_loss           | 3.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 212.9318181818182\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -53.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1818        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008002734 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.06       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 3.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 213.395\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -50.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1836        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006490818 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 65.02\n",
      "Overall Average Successful Assignments: 162.01476349701576\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77eedc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -392.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 6.0\n",
      "All assignments history: [10, 22, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -368     |\n",
      "| time/              |          |\n",
      "|    fps             | 56       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -200.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.541666666666664\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -374         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065878863 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.246       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.45         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -212.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 57.361111111111114\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -372      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 3072      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0066537 |\n",
      "|    clip_fraction        | 0.0779    |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -5.83     |\n",
      "|    explained_variance   | -0.17     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 2.23      |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -0.037    |\n",
      "|    value_loss           | 14.6      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 77.0625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006825153 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.0394     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 93.53333333333333\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -372       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 5120       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00662449 |\n",
      "|    clip_fraction        | 0.0793     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.82      |\n",
      "|    explained_variance   | 0.029      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.34       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0361    |\n",
      "|    value_loss           | 9.64       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 107.52777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008235109 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | -0.00631    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.78        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 117.60714285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084655285 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.83         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0398      |\n",
      "|    value_loss           | 6.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.65625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008514531 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | -0.00547    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 5.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.21296296296296\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009581136 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | -0.0134     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 4.73        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.00833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009183964 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.668       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 4.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.0681818181818\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010219375 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0023      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.69444444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010273926 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00556     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.96794871794873\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -365       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 13312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01176204 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.73      |\n",
      "|    explained_variance   | 0.00599    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.28       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0459    |\n",
      "|    value_loss           | 2.89       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.01190476190476\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015307158 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.00699     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.12222222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015680335 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.00914     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0526     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.11458333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009398829 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.0718      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.0343137254902\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010277379 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.284       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.8101851851852\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010731483 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.703       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.4517543859649\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009500148 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.8375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009372223 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.441       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.30555555555554\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -357       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 386        |\n",
      "|    total_timesteps      | 21504      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00969556 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.58      |\n",
      "|    explained_variance   | 0.213      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.759      |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    value_loss           | 2.73       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.7348484848485\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009565787 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.1086956521739\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009569291 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.416       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.35069444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008776697 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.5\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008113587 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.45       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.64102564102564\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006801374 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.778       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.7283950617284\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -345       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 497        |\n",
      "|    total_timesteps      | 27648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00848822 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.34      |\n",
      "|    explained_variance   | 0.248      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.623      |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    value_loss           | 2.82       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.71428571428572\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008276724 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.27       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.982       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.66666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008280698 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.65\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -338         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 553          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073423367 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.12        |\n",
      "|    explained_variance   | 0.153        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.771        |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.5752688172043\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008717198 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0482     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.47395833333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -332        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007725701 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.34848484848484\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008661107 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.2156862745098\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -326         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 623          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072476217 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.81        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0416      |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.02857142857144\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -324        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007555698 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.956       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.83333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -321         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 657          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074718865 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.62        |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.044       |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.6891891891892\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008164076 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.4671052631579\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -313         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 694          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064337905 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.39        |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 4            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.26709401709402\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -310         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 712          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065490906 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.29        |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.718        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.03125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -306         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 729          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062846085 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.24        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.8          |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.7987804878049\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 744          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055864016 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.51785714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 760         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005522413 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.17248062015503\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -295         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 777          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068848915 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.07        |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.792        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.91098484848484\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -292         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 792          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069747204 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.05        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.65\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -289         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 809          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069657434 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.04        |\n",
      "|    explained_variance   | 0.195        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.999        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0345      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.3713768115942\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005911784 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.97       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.07801418439718\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -282         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 841          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057512065 |\n",
      "|    clip_fraction        | 0.0908       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.863        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.74305555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -278         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 858          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061312197 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.87        |\n",
      "|    explained_variance   | 0.171        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.40816326530611\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -275         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 873          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054834248 |\n",
      "|    clip_fraction        | 0.0905       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.81        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.971        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.095\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -272         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 890          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062248055 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.82        |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.883        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 2.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.74346405228758\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -267        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 906         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006166812 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.43589743589743\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -262         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 922          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059989374 |\n",
      "|    clip_fraction        | 0.0976       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.81        |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.786        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0349      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.17295597484278\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -257         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 938          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065342835 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.77        |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.88734567901236\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -252         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 954          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064054877 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.76        |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.66666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -247         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 970          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061494024 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.73        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.4404761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -242         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 987          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061408808 |\n",
      "|    clip_fraction        | 0.0949       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.7         |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0359      |\n",
      "|    value_loss           | 3.55         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.1827485380117\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -236        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006028331 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.90086206896552\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -231         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1018         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064009773 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0402      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.63135593220338\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1035        |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007287654 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.976       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.3111111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -220        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1051        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006310356 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.96311475409837\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -215        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006734403 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.63306451612902\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -209         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1084         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071462533 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.47        |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.963        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.23015873015873\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -204         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 1100         |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061201043 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.49        |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.899        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 2.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.828125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -198         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1116         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074827536 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 2.52         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.4269230769231\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -193         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1132         |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071648564 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.764        |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 2.65         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.989898989899\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -188        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005550173 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.544776119403\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -183         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1164         |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062916707 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.51        |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.13235294117646\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1181        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006936519 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.95        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.72101449275362\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1198        |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006383123 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.29285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -167        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1214        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007746989 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.8732394366197\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -162         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 1230         |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059376564 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.51        |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.4560185185185\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -157        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1244        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006115916 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.06050228310502\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -152         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1259         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064309435 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.39         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.6509009009009\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -147         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1275         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074138884 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.25333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -143         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1291         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068473686 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.84         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0396      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.8530701754386\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -138         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1306         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076556676 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.37        |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0372      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.42424242424244\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -134        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1319        |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006588599 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.99786324786325\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -129        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1334        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007165547 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.5717299578059\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -125         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1348         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075752256 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.1375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -121        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1362        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007518767 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.69341563786008\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1375        |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006694788 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.22459349593495\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1390        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007175516 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.76004016064257\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1404         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066767978 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.29        |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.2956349206349\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -105         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1418         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056659635 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0326      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.82450980392156\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -101         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1432         |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064721815 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.34786821705427\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -97.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1446         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075995116 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.8706896551724\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -95.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1460         |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071246102 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.40151515151516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -92.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1474        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008317683 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.968       |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.96067415730337\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -90.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1488        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006941392 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.50185185185185\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -88.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1502         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053277137 |\n",
      "|    clip_fraction        | 0.0983       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.04761904761904\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -86.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1515        |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006848532 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.59329710144928\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -84.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 1529       |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00607548 |\n",
      "|    clip_fraction        | 0.0959     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.34      |\n",
      "|    explained_variance   | 0.636      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.5        |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    value_loss           | 3.78       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.12992831541217\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -82.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1544         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066839484 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.87         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.64007092198582\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -80.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1558        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006057279 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 4.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.1342105263158\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -78.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1571        |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006558061 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.61458333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -77.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1584        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007835061 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.07388316151201\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -75.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1598         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073468126 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.52891156462584\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -74.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1612        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009181127 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.98737373737373\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -72.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 1627         |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068884874 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.45\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -71.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1641        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006345312 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 57.06\n",
      "Overall Average Successful Assignments: 172.04194178730984\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5745c462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -382.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 10.75\n",
      "All assignments history: [19, 20, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -361     |\n",
      "| time/              |          |\n",
      "|    fps             | 79       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -308.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.75\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -366         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 76           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076146424 |\n",
      "|    clip_fraction        | 0.0733       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.163       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.85         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    value_loss           | 16.5         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -276.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.111111111111114\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077580977 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | -0.115       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.08         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 12.5         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -268.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.708333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006623726 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.224      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.47        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.65\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069020283 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0.0757       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.66         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 9.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -228.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 57.90277777777778\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007689968 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | -0.00829    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.1         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 8.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 65.70238095238095\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008712359 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | -0.0245     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.17        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 6.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 73.45833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009388893 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.000727    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 5.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 79.54629629629629\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -367       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 73         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00988812 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.78      |\n",
      "|    explained_variance   | 0.00374    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.02       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0421    |\n",
      "|    value_loss           | 4.71       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 84.2\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010421181 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.00993     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 4.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 87.93181818181819\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009189162 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00377     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.325       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 91.125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010662788 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 1.35e-05    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.567       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 94.09615384615384\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012837676 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00541     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0917      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.79166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016184501 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.00411     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0342      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 99.52777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013530485 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.605       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 101.953125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010838714 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.0445      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 104.4656862745098\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010182641 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.346       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 107.24074074074075\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011276968 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 110.09210526315789\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008221504 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.198       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.03333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008193502 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.03174603174604\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008028453 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.61       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.97        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 118.60227272727273\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006718016 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.86        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 121.29347826086956\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006983755 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.85069444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007864209 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 126.14\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007803052 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.443       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.35897435897436\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008237323 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.44       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 130.5462962962963\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007336775 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.56        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.57738095238096\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008383131 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 134.49137931034483\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007869725 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.28       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.773       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009125221 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.24       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.935       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.25806451612902\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008817531 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.63        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.16927083333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008895557 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.11       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.691       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.97979797979798\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007946779 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.73039215686273\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009362513 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0469     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.31190476190477\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008648388 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.85       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.932       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.84722222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -326        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007890971 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.75       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.895       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.31756756756758\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -323         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 516          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077606617 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0448      |\n",
      "|    value_loss           | 2.51         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.78728070175438\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007983529 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.54       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.2905982905983\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 544         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007098288 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.65833333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -313        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007652007 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.4        |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.904       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.989837398374\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -310         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 590          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064460384 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.36        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.762        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.24007936507937\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -307        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007315307 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.45348837209303\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -304      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 71        |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 616       |\n",
      "|    total_timesteps      | 44032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0082645 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -4.22     |\n",
      "|    explained_variance   | 0.463     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 0.973     |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -0.0436   |\n",
      "|    value_loss           | 2.95      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.67992424242425\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -300         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 629          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064618494 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.14        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0411      |\n",
      "|    value_loss           | 3.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.89444444444445\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008415168 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.01992753623188\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -293        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813308 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.11347517730496\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -290        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 668         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008232288 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.891       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.24305555555554\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -287       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 72         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 680        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00845525 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.91      |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.796      |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0425    |\n",
      "|    value_loss           | 2.5        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.27721088435374\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -284        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 693         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007566396 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.32333333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 709         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006871123 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.4281045751634\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -276        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 723         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008356478 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.732       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.51121794871796\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -270         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 738          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061124954 |\n",
      "|    clip_fraction        | 0.0989       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.56132075471697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -265        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 752         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006055109 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.54783950617283\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -260         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 769          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077184266 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    value_loss           | 2.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.53484848484848\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -255         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 783          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057887165 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.73        |\n",
      "|    explained_variance   | 0.321        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 72.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.44345238095238\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -250        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005762037 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.33187134502924\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -245        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 811         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006138876 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.65       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 2.62        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.2183908045977\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -240        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006553691 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.63       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.12005649717514\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -235         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 840          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058693243 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.6         |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.917        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.00416666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -229        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007043192 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.86475409836066\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -223        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 867         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006599848 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.994       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.71102150537635\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -217         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 881          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054880846 |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 3.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.55820105820106\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -212        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 895         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005343831 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.976       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.44140625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -206        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 909         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005922585 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.32564102564103\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -201         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 923          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057348395 |\n",
      "|    clip_fraction        | 0.0996       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.18813131313132\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -195         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 937          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064671496 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.01990049751242\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -190        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005651478 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.81372549019608\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -185         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 962          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060832696 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.6231884057971\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -180      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 72        |\n",
      "|    iterations           | 69        |\n",
      "|    time_elapsed         | 975       |\n",
      "|    total_timesteps      | 70656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0066556 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.41     |\n",
      "|    explained_variance   | 0.352     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.1       |\n",
      "|    n_updates            | 680       |\n",
      "|    policy_gradient_loss | -0.0357   |\n",
      "|    value_loss           | 3.05      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.43214285714285\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -174        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 988         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006984841 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.965       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.2288732394366\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -169         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 1000         |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069947466 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.99305555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -164         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1013         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066874726 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.76255707762556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -158        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1026        |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006472104 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.45495495495496\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -154        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1039        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005468292 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.1511111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -149         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1051         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065419916 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0398      |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.8421052631579\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -144         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1064         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066811536 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.5\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -139         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 1077         |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072930222 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.16773504273505\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -135        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1090        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006330876 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.80801687763713\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -130        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1102        |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006080247 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.44479166666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -126         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1115         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062729074 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 3.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.09053497942386\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -122       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 73         |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 1128       |\n",
      "|    total_timesteps      | 82944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00703107 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.27      |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.37       |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 3.47       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.72459349593495\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1141        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006885047 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.3393574297189\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1153        |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006460648 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.95535714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1166        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006395571 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.86        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.5735294117647\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1179        |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006786042 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.16763565891472\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -102         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1192         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071474826 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0396      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.7528735632184\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -98.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1204        |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006426308 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.32007575757575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -95.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1218        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006327022 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.90449438202248\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -92.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1231        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006490958 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.46481481481482\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -89.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1243        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006233669 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.00915750915752\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -87.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1256         |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055894703 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0344      |\n",
      "|    value_loss           | 3.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.53351449275362\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -84.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 74         |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 1269       |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00571346 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.21      |\n",
      "|    explained_variance   | 0.547      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.51       |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 3.71       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.05824372759858\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -82.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1282         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060409405 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.59308510638297\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -79.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1295         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068194787 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.22        |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.63         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.10087719298247\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -78.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1307        |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006606917 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.59982638888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -75.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 1321         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063678306 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.08247422680412\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -73.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1335         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065749544 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.16        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 3.47         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.56037414965985\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -72         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1350        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005782791 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 3.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.0328282828283\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -70         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1364        |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007076174 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.49416666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -68         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1377        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006581899 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 36.06\n",
      "Overall Average Successful Assignments: 151.15279467577668\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55aa75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -382.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 10.0\n",
      "All assignments history: [15, 15, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -370     |\n",
      "| time/              |          |\n",
      "|    fps             | 80       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -346.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.25\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007617446 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.376      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -324.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.944444444444443\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -371       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 79         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00848362 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.83      |\n",
      "|    explained_variance   | -0.177     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.49       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 11.9       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -318.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.541666666666668\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -369       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 80         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00795943 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.82      |\n",
      "|    explained_variance   | -0.0686    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.81       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0381    |\n",
      "|    value_loss           | 9.49       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.75\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007825162 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.028       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.39        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 8.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 67.76388888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -367         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076277126 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | -0.00054     |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.97         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0348      |\n",
      "|    value_loss           | 7.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 81.14285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009512564 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.00308     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 5.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 91.46875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008771075 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.00603     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 5.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 98.80555555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009463245 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.00657     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.94        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 4.6         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 104.49166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010157961 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.3         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 3.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 109.07575757575758\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010097125 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.000563    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.811       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.42361111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011378534 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00618     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.071      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 116.8525641025641\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012211591 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00403     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.784       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 119.77380952380952\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012300197 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00473     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0444      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 122.42222222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013221638 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0142      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.403       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.77083333333333\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -361      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 80        |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 204       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0119565 |\n",
      "|    clip_fraction        | 0.253     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -5.71     |\n",
      "|    explained_variance   | 0.0464    |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -0.0466   |\n",
      "|    value_loss           | 2.88      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 126.93627450980392\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009188592 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.0804      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.86574074074073\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010085449 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.558       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 130.68421052631578\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009480635 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.957       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 132.3\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008487353 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.81746031746033\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008475883 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.61       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.24621212121212\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -353         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076659676 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.58        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.04         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.57608695652175\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007715363 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.54       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.907       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.83333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -351         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 306          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070021786 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.5         |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.05333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008860953 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.45       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.357       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.2403846153846\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008208133 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.46        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.43827160493828\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -345       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 80         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 344        |\n",
      "|    total_timesteps      | 27648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00835987 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.35      |\n",
      "|    explained_variance   | 0.215      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.49       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0411    |\n",
      "|    value_loss           | 3.46       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.8422619047619\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -342       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 80         |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00784652 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.29      |\n",
      "|    explained_variance   | 0.253      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.313      |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0412    |\n",
      "|    value_loss           | 2.72       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.19540229885058\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008164655 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.24       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.60833333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009122036 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.16       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.347       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.13440860215053\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -335         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 395          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076164245 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.1         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.533        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0438      |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 148.59375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008030334 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.524       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.96212121212122\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008245461 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.601       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.23039215686273\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007678018 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 152.55\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009171528 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.492       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 2.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.8125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -322        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821933 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.8         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.03603603603602\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -319        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009368164 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.2719298245614\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009407408 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.966       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.4017094017094\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008872825 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.55208333333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -309       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 82         |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 499        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00774895 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.39      |\n",
      "|    explained_variance   | 0.253      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.07       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0425    |\n",
      "|    value_loss           | 2.99       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.65853658536585\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 510         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007923978 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.676       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.71428571428572\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -303        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007342649 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.29       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.68798449612405\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -299         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 82           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 531          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067885774 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.22        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.66098484848484\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -296         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067160325 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.14        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.6259259259259\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -292         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 551          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066135647 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.06        |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.774        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.59601449275362\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -289        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007937529 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.57978723404256\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007070943 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.889       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.54861111111111\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -282       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 84         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 579        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00639993 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.95      |\n",
      "|    explained_variance   | 0.312      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.3        |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0375    |\n",
      "|    value_loss           | 3.1        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.51530612244898\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -279        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007092976 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 2.64        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.48\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -275        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006779015 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.796       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.38235294117646\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -270        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 605         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006294543 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.34935897435898\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -265        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 614         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006914082 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.22955974842768\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -260         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 621          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064876648 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.79        |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0412      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 76.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.1820987654321\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -255         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 627          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070117656 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.77        |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.22727272727272\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -250         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 633          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070814574 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.74        |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.987        |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.3467261904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -244        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006924063 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 3.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 106.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.44152046783626\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -239         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 644          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066814553 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.67        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 3.52         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.46264367816093\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -233        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 650         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006219098 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.46610169491527\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -228         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 656          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064415867 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.72         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.44861111111112\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -222         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 662          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064054485 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.919        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 2.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.45901639344262\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -217         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 668          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071980376 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.67        |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.957        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    value_loss           | 2.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.44220430107526\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -212         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 94           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 674          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065862196 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.69        |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.4021164021164\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -206        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005726356 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.32942708333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -201         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 686          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052181855 |\n",
      "|    clip_fraction        | 0.0853       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.64        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 3.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.28205128205127\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -196       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 692        |\n",
      "|    total_timesteps      | 66560      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00591649 |\n",
      "|    clip_fraction        | 0.0926     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.6       |\n",
      "|    explained_variance   | 0.391      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.15       |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.0362    |\n",
      "|    value_loss           | 3.3        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.22727272727272\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -190         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 697          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059617497 |\n",
      "|    clip_fraction        | 0.0915       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.59        |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0332      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.17537313432837\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -185         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 702          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067754043 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.57        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.1360294117647\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 706         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006152778 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.0012077294686\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -174         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 711          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051450445 |\n",
      "|    clip_fraction        | 0.0918       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.49        |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.9\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -168        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006338281 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.77582159624413\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -163         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 719          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061559314 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.94         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.68055555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -157        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 723         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006082705 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.52511415525115\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -152         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 728          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058146995 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.3536036036036\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -146        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005427847 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.16666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -141         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 736          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066978633 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.94736842105263\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -136         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 741          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062017823 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.918        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    value_loss           | 2.45         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.71536796536796\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -130        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006488573 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.4732905982906\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -125         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 749          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061748866 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.15189873417722\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -121       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 753        |\n",
      "|    total_timesteps      | 80896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00471624 |\n",
      "|    clip_fraction        | 0.0772     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.19      |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.04       |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 3.15       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.89166666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -116         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 758          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057850014 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0348      |\n",
      "|    value_loss           | 2.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.6255144032922\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 762         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005585162 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.33434959349594\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -106         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 766          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056613125 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.814        |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.03313253012047\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -102         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 771          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055736112 |\n",
      "|    clip_fraction        | 0.0899       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.71825396825398\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -97.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006000015 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.38235294117646\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -93.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 779          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059734406 |\n",
      "|    clip_fraction        | 0.0888       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0298      |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.0174418604651\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -89.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 784          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046614823 |\n",
      "|    clip_fraction        | 0.0821       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.66954022988506\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -86.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 788          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054185884 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.32670454545453\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -83         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006977605 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.9943820224719\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -79.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005533453 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.64074074074074\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -76.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 801          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054749874 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.858        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.253663003663\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -73.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 805          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068791583 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.87047101449275\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -70.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 116          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 810          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059282007 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 3.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.4731182795699\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -68.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 814         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005775836 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.06737588652481\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -65.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006542057 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.968       |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.64473684210526\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -63.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 823         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006130087 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.22135416666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -61         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 827         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008060748 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.79725085910653\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -58.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007454643 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.32908163265307\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -56.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 120          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 836          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063837413 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0343      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.86111111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -55          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 120          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 840          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065153614 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.39\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -53          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 121          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 844          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063207205 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.13        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 52.98\n",
      "Overall Average Successful Assignments: 159.18950174285325\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3074909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -378.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 10.916666666666666\n",
      "All assignments history: [14, 7, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -379     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -374.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.208333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007118349 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.0445      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.58        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -354.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.25\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007291991 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.0482      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -330.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.3125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386151 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.04        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 9.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -184.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008580171 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.42        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 8.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -170.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.736111111111114\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008960149 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.00871     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.94        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 7.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -156.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.273809523809526\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009501522 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0248      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.86        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 6.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 60.65625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008635782 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | -7.33e-05   |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.936       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 5.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -158.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 65.51851851851852\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008897753 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.79        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 4.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 70.475\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010112205 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 3.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 74.5909090909091\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -368       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01050344 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.75      |\n",
      "|    explained_variance   | 0.00848    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.295      |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 3.53       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 83.15277777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011601778 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00966     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 90.1474358974359\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012583548 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0132      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.54761904761905\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011647848 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 101.97777777777777\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011311681 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.0597      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0591      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 106.796875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010121747 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 111.1470588235294\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009937352 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 115.00462962962963\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008849563 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 118.57456140350877\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008738295 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.704       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 121.87083333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009278474 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.62       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 124.86111111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008072324 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.43181818181819\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006966614 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.513       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.77173913043478\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007760372 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.6         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.94444444444446\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -351         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073858285 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.52        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.8          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.94\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007700833 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.47       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.86        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.82371794871796\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007542768 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.703       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.57407407407408\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -346        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833682 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.733       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.23214285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -344         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075148847 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.34        |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.7816091954023\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009202668 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.28       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.731       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 142.29444444444445\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008747151 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.2        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.677       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.7768817204301\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008708132 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.854       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 145.16927083333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -333         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071839755 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0427      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.510101010101\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -330        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008044943 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.85539215686273\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008810377 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.88       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.918       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 2.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.21428571428572\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -325         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071334387 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.78        |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0434      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.52546296296296\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -322        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007790101 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.8355855855856\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -318        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008402737 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.815       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.07894736842104\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -315         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072264657 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.57        |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.25641025641025\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -313        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008267205 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.48       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.45833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008074391 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.59349593495935\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -306         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074173203 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.36        |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.99         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.60714285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008171134 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.3        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.69379844961242\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006862869 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.939       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.75378787878788\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -295        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006432132 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.76481481481483\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -293        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006518978 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.79891304347825\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -290         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075252815 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.09        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.977        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 2.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.7836879432624\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008361017 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 50.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 163.73090277777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -283         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077864137 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.02        |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.935        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.72619047619048\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -280        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007173978 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.68333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -278         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071962764 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.01        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.6781045751634\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -273        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007470588 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.76442307692307\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -268        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008341612 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.95        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.80503144654088\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -263        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008098698 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.82253086419752\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -257        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008329706 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.8212121212121\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -252         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064443722 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.81        |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.97         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 78.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.76041666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -247        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007864958 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.74707602339183\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -242         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077530467 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.73        |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0421      |\n",
      "|    value_loss           | 3.36         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.69827586206895\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -236         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074902065 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.75        |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.68         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0349      |\n",
      "|    value_loss           | 3.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.65395480225988\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -231        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007097676 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.61388888888888\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -226        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007452217 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.51092896174865\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -220        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007302462 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.992       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.3938172043011\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -215        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007246454 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.30026455026456\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -210         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077565657 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.69        |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.23828125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -205        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007523247 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.15\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008743623 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.07449494949495\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -195       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00782267 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.68      |\n",
      "|    explained_variance   | 0.265      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.09       |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.0399    |\n",
      "|    value_loss           | 3.03       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.90547263681592\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -190         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 287          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079315435 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.64        |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.944        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0434      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.74632352941177\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -185         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 291          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074987607 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.6         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.759        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0437      |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.58816425120773\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -180        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008600149 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.43809523809523\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -175         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073388647 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 3.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.2781690140845\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -170         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066543734 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0418      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.09490740740742\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -165        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008555484 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.9052511415525\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -160         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 312          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064408197 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.6         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.70045045045046\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007689454 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 2.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.45666666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -151        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007782055 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.65       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.22149122807016\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -146         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 325          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073654084 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.61        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0418      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.95670995670994\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -142        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006978954 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.63       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.6741452991453\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007223565 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.37869198312237\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -134         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068948744 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0443      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.08333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -130        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007340475 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.7582304526749\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -127        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006692992 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.41869918699186\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -123         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 351          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067444546 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0421      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.08232931726909\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -119        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008059324 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.7202380952381\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -115        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006004238 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.3578431372549\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006327379 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.99612403100775\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007674785 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.6522988505747\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006858807 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 3.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.2717803030303\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -102         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 377          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066054957 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0346      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.87921348314606\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -99.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 381          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077264733 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.46203703703705\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -96.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 385          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063813133 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.976        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.0448717948718\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -93.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 390          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062415926 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0414      |\n",
      "|    value_loss           | 3.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.61231884057972\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -91.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007573096 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.17562724014337\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -89.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006583868 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 3.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.71897163120568\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -87         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008090646 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.2842105263158\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -84.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007021173 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.84895833333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -82.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006132913 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.37199312714776\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -80.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 416          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071532005 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.88095238095238\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -78.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 420          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071963863 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.37457912457913\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -77         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006709946 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.86333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -75.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 429          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063190092 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 44.54\n",
      "Overall Average Successful Assignments: 152.36864690379517\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22754b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -374.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.416666666666666\n",
      "All assignments history: [13, 18, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -369     |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -376.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.458333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -376        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007829893 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.249      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.35        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -258.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.02777777777778\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007680861 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.0913     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -276.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.5\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008555442 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.94        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 9.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -228.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.18333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248556 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.00191    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 8.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 57.888888888888886\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008749885 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | -0.0112     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 7.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 71.57142857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008045914 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.1         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 6.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 81.83333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008710028 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0153      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 5.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 89.58333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009258821 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.0138      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.737       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 4.77        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.075\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010605672 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00894     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.316       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 3.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 101.43181818181819\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010593128 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 105.86805555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011468732 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00512     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.371       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 109.68589743589743\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011301326 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0092      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 113.75\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014068542 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0127      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.58        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 117.35555555555555\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010467681 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 120.328125\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -363       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01146519 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.72      |\n",
      "|    explained_variance   | 0.0626     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.54       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0445    |\n",
      "|    value_loss           | 2.74       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 123.11274509803921\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -361         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098480135 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.113        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.865        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0418      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.70370370370371\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008102678 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.19        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 127.7719298245614\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008947859 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 129.79583333333332\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008845718 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.62        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.7420634920635\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008475242 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.47348484848484\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833675 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.552       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 135.03623188405797\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007969246 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.6        |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.938       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.55208333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008025955 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 137.99\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007417268 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.561       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 139.69551282051282\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -351         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074930093 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.49        |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.42592592592592\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -350         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069795675 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.43        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.637        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.20238095238096\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006961116 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.81        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.80459770114942\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -346         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068342136 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.33        |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.49444444444444\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -344         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073738694 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.26        |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.255        |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.71774193548387\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -342         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060282466 |\n",
      "|    clip_fraction        | 0.093        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.19        |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.04166666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -339         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067743543 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.11        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0415      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.44949494949495\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008600002 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.9191176470588\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007714104 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.4547619047619\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008420171 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.822       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.88657407407408\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -329         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074852956 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.83        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0412      |\n",
      "|    value_loss           | 2.73         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.28153153153153\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008077968 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 157.67763157894737\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -322         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082355235 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.66        |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0433      |\n",
      "|    value_loss           | 3.63         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.05769230769232\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -319        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008047959 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.37291666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -315        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008837361 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.801       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.66869918699186\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007872036 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.42       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.92261904761904\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -308        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009041791 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.35       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.04651162790697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008961679 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.29       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.984       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0466     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.2159090909091\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007895795 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.99        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.3962962962963\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007999491 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.997       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.54347826086956\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -295        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008104095 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.72517730496455\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -292         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073910197 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.08        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0406      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.83333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -289        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008546222 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.74        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0497     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.91836734693877\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007634156 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.925       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.11666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008363098 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.18627450980392\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -278         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073922393 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.89        |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.869        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 2.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.2852564102564\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -273        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008407856 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 175.29245283018867\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -268        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008972577 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.320987654321\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -263         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069071017 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.81        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.3060606060606\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071217446 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.74        |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0436      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.22767857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -253        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007127096 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.15204678362574\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -247       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 244        |\n",
      "|    total_timesteps      | 58368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00623791 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.67      |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.8        |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0382    |\n",
      "|    value_loss           | 3.79       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.10632183908046\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -242         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 249          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068200044 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.65        |\n",
      "|    explained_variance   | 0.328        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.02542372881356\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -237        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007464667 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.95\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -232         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075269826 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    value_loss           | 3.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.86475409836066\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -226         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 262          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075550997 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.67        |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.997        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.77956989247312\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -221        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006692788 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.65       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.65873015873015\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -215         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 271          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069016307 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.61        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 3.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.51302083333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -210         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 276          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078182435 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.52        |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0453      |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 112.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.37692307692308\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -204         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057445355 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.73         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 3.68         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.2020202020202\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -198        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006369645 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.01119402985074\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -193        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006839704 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.885       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.80024509803923\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -188         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 293          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074883066 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.52        |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.55917874396135\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -183        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006884422 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.32142857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007147352 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.07042253521126\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -172         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 307          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065498305 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.80324074074073\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -167         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067351405 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.65        |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.036       |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.50913242009133\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -162        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006492181 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.29        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.18243243243242\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -157         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 320          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070928643 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.043       |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.85222222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -152        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006518772 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.50877192982455\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -148         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060907267 |\n",
      "|    clip_fraction        | 0.0938       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.57        |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 3.19         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.16450216450215\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -143        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007183195 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.7991452991453\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -139        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006731108 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.41350210970464\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -134         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 342          |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056043603 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.02291666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -130         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 347          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064734863 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.63683127572017\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -126        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005229459 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.84        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.2378048780488\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -122        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005282973 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.83132530120483\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005879076 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.42361111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -113         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058323415 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.37        |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.9656862745098\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006026044 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.51065891472868\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -107         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061123306 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.03927203065135\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005894041 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.58522727272728\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -101        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005745531 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.12921348314606\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -97.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 387          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054640747 |\n",
      "|    clip_fraction        | 0.0966       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.64166666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -94.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006175696 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.11996336996336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -92.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006109843 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.60326086956522\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -89.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 400        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00544476 |\n",
      "|    clip_fraction        | 0.0986     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.3       |\n",
      "|    explained_variance   | 0.535      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.41       |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 3.56       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.07616487455198\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | -86.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 235       |\n",
      "|    iterations           | 93        |\n",
      "|    time_elapsed         | 405       |\n",
      "|    total_timesteps      | 95232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0071752 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -3.26     |\n",
      "|    explained_variance   | 0.545     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 0.914     |\n",
      "|    n_updates            | 920       |\n",
      "|    policy_gradient_loss | -0.0396   |\n",
      "|    value_loss           | 3.53      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 124.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.54432624113474\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -84.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007504424 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.99473684210525\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -82.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 414        |\n",
      "|    total_timesteps      | 97280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00651923 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.27      |\n",
      "|    explained_variance   | 0.536      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.44       |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.0355    |\n",
      "|    value_loss           | 3.64       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 120.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.43229166666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -80.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 418          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068713278 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 3.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.8745704467354\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -78.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 422          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058918963 |\n",
      "|    clip_fraction        | 0.0973       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.31        |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.69         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0316      |\n",
      "|    value_loss           | 3.64         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 132.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.33843537414967\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -76.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005220937 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.79882154882154\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -75.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 431        |\n",
      "|    total_timesteps      | 101376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00649509 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.31      |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.918      |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.037     |\n",
      "|    value_loss           | 3.41       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.24416666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -74.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007388956 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 53.02\n",
      "Overall Average Successful Assignments: 159.45298563021902\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb9fd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -392.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 5.75\n",
      "All assignments history: [16, 13, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -371     |\n",
      "| time/              |          |\n",
      "|    fps             | 255      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -344.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.666666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007167103 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | -0.206      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -324.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.944444444444443\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -370        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007914629 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | -0.126      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -268.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.854166666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083976835 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | -0.11        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.64         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0416      |\n",
      "|    value_loss           | 9.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -264.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.6\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072557875 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0.0311       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.02         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 8.36         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -244.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.68055555555556\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -370         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076585514 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.5          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 7.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 58.892857142857146\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -369         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074006296 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | 0.0166       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.75         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 6.48         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 71.85416666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009211965 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 5.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 81.72222222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -369        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009053281 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | -0.00103    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.637       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 4.62        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 89.84166666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -368         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096925255 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.013        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.303        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0398      |\n",
      "|    value_loss           | 3.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 96.72727272727273\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011721203 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.00112     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.384       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 103.64583333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011913743 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0071      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.323       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 109.37820512820512\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012006977 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00981     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 114.11309523809524\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015204096 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0099      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 118.49444444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012203652 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0565      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.677       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 122.22916666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -363         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124380905 |\n",
      "|    clip_fraction        | 0.238        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.398        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0464      |\n",
      "|    value_loss           | 2.63         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 125.86274509803921\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -362        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009447347 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.75        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 128.87962962962962\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -361        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009952436 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.371       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 131.55263157894737\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -360        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009054811 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 133.9625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010941939 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.672       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 136.14285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -357        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008978119 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.61       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 138.125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009860599 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.72        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 140.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009404958 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.447       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 141.76041666666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -353       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00925668 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.5       |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.166      |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    value_loss           | 2.93       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 143.39\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008661913 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.46       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.375       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 144.92948717948718\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -349       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 113        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00976792 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.42      |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.77       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0479    |\n",
      "|    value_loss           | 3.1        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 146.44444444444446\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -347        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008998783 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 147.8779761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008792797 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.444       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 149.24425287356323\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008164085 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.22       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.78        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 150.59722222222223\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663775 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.14       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 151.91397849462365\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008541904 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.681       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 3.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 153.1484375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008078026 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.694       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 154.40151515151516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -332        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009020616 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.925       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 155.63480392156862\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -329         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075411284 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.78        |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 3.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 156.84761904761905\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008838258 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 3.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 158.04166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008305488 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 159.24774774774775\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010922635 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.563       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 52.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 160.484649122807\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -316        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007504369 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.699       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 161.72649572649573\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -313         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068644937 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.39        |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.57         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 162.94166666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007967915 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.802       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 164.1178861788618\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -305         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075957994 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.22        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.69         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0438      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 165.23015873015873\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -302         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 184          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062987288 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.14        |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.749        |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 166.37596899224806\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -298        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007121778 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 167.42992424242425\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -295         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062722964 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.02        |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 168.54074074074074\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -291         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069117756 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.01        |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 169.55434782608697\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -288         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069531184 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0412      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 170.59929078014184\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006373984 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 70.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 171.63541666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -281         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071540056 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.84        |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 80.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 172.71598639455783\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -277         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054980423 |\n",
      "|    clip_fraction        | 0.0706       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.81        |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0332      |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 84.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 173.77166666666668\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -274         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072292164 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.8         |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 94.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 174.87908496732027\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -269        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006338886 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 104.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 176.00480769230768\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -264         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072968667 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.77        |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 3.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 102.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 177.0927672955975\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -259        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006298096 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 3.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 108.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 178.17746913580248\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -253         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061746384 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.68        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 3.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 179.31363636363636\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -248        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007425323 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 180.41815476190476\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -242        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006302976 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 181.5014619883041\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -236         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064845057 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 182.57902298850576\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -230         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064606955 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.47        |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0437      |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 183.57627118644066\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -224         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 259          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071542095 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.998        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 184.56527777777777\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -218         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 263          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077582444 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 110.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 185.48497267759564\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -212         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071211895 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 186.4220430107527\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -206         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056579895 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.933        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 187.33068783068782\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 276          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063073644 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.37        |\n",
      "|    explained_variance   | 0.27         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 3.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 114.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 188.20052083333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -194        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006655922 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 3.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 116.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.08846153846153\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -187        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006610724 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 3.49        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 118.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 189.91919191919192\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -181         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048839515 |\n",
      "|    clip_fraction        | 0.0666       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 190.77487562189054\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -175         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 293          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065790378 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0359      |\n",
      "|    value_loss           | 3.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 122.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 191.58455882352942\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -170        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005670377 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 192.40579710144928\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -164        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006331949 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 3.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 193.23095238095237\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -158         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 305          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061430973 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.33        |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.01291079812208\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -153         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 309          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061834343 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 126.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 194.76967592592592\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -147         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 313          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065508103 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 195.52283105022832\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -142         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065455865 |\n",
      "|    clip_fraction        | 0.0913       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.32        |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    value_loss           | 3.77         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 136.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 196.30292792792793\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -136         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 321          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064771227 |\n",
      "|    clip_fraction        | 0.0984       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.34        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 134.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.0288888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -131        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006612804 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 130.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 197.72258771929825\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -126         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065978486 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.36        |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 128.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 198.37012987012986\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -121         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 333          |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062882183 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.08760683760684\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005212126 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 199.77742616033754\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005761193 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 200.47291666666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | -107       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 345        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00658004 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -3.32      |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.56       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.0397    |\n",
      "|    value_loss           | 3.8        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.15843621399176\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005759189 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 3.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 201.8658536585366\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -98.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 353          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061860634 |\n",
      "|    clip_fraction        | 0.0936       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0339      |\n",
      "|    value_loss           | 3.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 202.5491967871486\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -94.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 358          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058265114 |\n",
      "|    clip_fraction        | 0.0953       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 3.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 138.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.16865079365078\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -90.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 362          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066633145 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.25        |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.29         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 4.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 203.79313725490195\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -87.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073193167 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 204.43120155038758\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -83.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 369          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058182767 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 3.97         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.0565134099617\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -80.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005780667 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 4.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 150.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 205.68371212121212\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -77          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 376          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062590297 |\n",
      "|    clip_fraction        | 0.0977       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0325      |\n",
      "|    value_loss           | 4.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.28277153558054\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -74         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006729283 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 206.82685185185184\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -71.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 383          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061467076 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.29        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.07         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0324      |\n",
      "|    value_loss           | 3.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.38278388278388\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -69.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 387          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072978744 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 4            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 140.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 207.90307971014494\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -67.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005496127 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 3.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.4220430107527\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -65.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 394          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066921134 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 4.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 146.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 208.9618794326241\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -62.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059522074 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.92         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.4675438596491\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -60.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 401          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068520205 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.26        |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.05         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 4.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 144.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 209.95920138888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -58.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006385814 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 4.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.46563573883162\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -56.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 408          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050669783 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.45         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 4.66         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 142.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 210.93537414965985\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -54.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 412          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061590923 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0371      |\n",
      "|    value_loss           | 4.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 148.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.41750841750843\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -53.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 415          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072929924 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 4.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 152.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 211.91083333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -51.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007126977 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 4.14        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 61.18\n",
      "Overall Average Successful Assignments: 161.45784019702336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks400.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8b29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
