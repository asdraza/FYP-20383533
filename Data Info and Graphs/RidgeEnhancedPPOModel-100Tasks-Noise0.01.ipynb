{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06f0e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.45497986053091444\n",
      "RMSE: 0.5737672522389483\n",
      "R-squared: 0.997773370716979\n",
      "RAE: 0.04751820477894557\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=['Eligible'])\n",
    "    y = data['Eligible']\n",
    "    return X, y\n",
    "\n",
    "def train_ridge_model(X_train, y_train):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    ridge_model = Ridge()\n",
    "    ridge_model.fit(X_train_scaled, y_train)\n",
    "    return ridge_model, scaler\n",
    "\n",
    "# Load and train on VehicleTrainingDataset.csv\n",
    "X_train, y_train = load_and_preprocess_data('VehicleTrainingDataset_Noisy_0.01.csv')\n",
    "ridge_model, scaler = train_ridge_model(X_train, y_train)\n",
    "\n",
    "# Predict eligibility scores on 1000VehicleDataset.csv\n",
    "vehicles_df = pd.read_csv('1000VehicleDataset_Noisy_0.01.csv')\n",
    "X_test = vehicles_df.drop(columns=['Eligible'])\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "predicted_scores = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# Assuming you have access to actual scores, replace this line with the actual score loading logic if available\n",
    "y_actual = vehicles_df['Eligible']  # This would be prior to overwriting with predictions if you run this block again\n",
    "\n",
    "# Replace actual scores with predicted ones\n",
    "vehicles_df['Eligible'] = predicted_scores  \n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_actual, predicted_scores)\n",
    "rmse = np.sqrt(mean_squared_error(y_actual, predicted_scores))\n",
    "r_squared = r2_score(y_actual, predicted_scores)\n",
    "rae = np.sum(np.abs(y_actual - predicted_scores)) / np.sum(np.abs(y_actual - np.mean(y_actual)))\n",
    "\n",
    "# Output the results\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "print(f\"RAE: {rae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93709ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -98.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 2.6\n",
      "All assignments history: [2, 5, 7, 4, 6, 4, 5, 2, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -91.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 664      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 3.55\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006986077 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | -0.37       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 5.583333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 608          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062415423 |\n",
      "|    clip_fraction        | 0.0726       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | -0.192       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.96         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0292      |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.1625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006215591 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | -0.0818     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.48        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 9.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.79\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 579          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058744336 |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.46         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0292      |\n",
      "|    value_loss           | 8.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.266666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 578         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006856867 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.54        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.464285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007383789 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.0639      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 7.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.46875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 565          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077889534 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.98        |\n",
      "|    explained_variance   | 0.0962       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.11         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 6.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.105555555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077736224 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.97        |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.23         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 6.16         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.495\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 573          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074089253 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.96        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.93         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0371      |\n",
      "|    value_loss           | 6.03         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.736363636363638\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008214124 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.902       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 5.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.745833333333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -88.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 566        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00761437 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.94      |\n",
      "|    explained_variance   | 0.459      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.72       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 5.37       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.6\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -87.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 568          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 13312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071712215 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.92        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.58         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 4.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.29642857142857\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -87.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 567          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071051596 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.91        |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.13         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 4.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.04\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -86.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 568          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 15360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070215045 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.9         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2            |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 3.94         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.69375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -85.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006900934 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.956       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.261764705882353\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -84.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 568          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077754334 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.87        |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 3.44         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.78611111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -83.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005883266 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.84       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.257894736842104\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -82.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 571          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 19456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066584144 |\n",
      "|    clip_fraction        | 0.0952       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.81        |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.715\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -81.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 571          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068680253 |\n",
      "|    clip_fraction        | 0.0996       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.79        |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.173809523809524\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -80.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056336336 |\n",
      "|    clip_fraction        | 0.0694       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.75        |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0316      |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.652272727272727\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -79.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 571          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071109044 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.515        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    value_loss           | 2.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.195652173913043\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -77.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 571          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060445257 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.66        |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.70625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -75.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 570          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064970013 |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.63        |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.924        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.033       |\n",
      "|    value_loss           | 2.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.19\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -73.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007247796 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.57       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.793       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.638461538461538\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -71.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063409703 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.5         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.053703703703704\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -69.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 564          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070573855 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.43        |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.898        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0423      |\n",
      "|    value_loss           | 2.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.48392857142857\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -67.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 567          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074973265 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.35        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.776        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0431      |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.91551724137931\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -65.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 567          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071180053 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.465        |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 2.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.348333333333336\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -62.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065331794 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.17        |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.804        |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.77258064516129\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -60.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008009883 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.794       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.215625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -57          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077511873 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.95        |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.707        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0428      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.72121212121212\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -53.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008204807 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.81        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.21764705882353\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -50.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 565          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073040696 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.72571428571428\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -46.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007929562 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.18194444444445\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -42.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067070895 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.56         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.68783783783784\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -38.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008834129 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.7         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.171052631578945\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -34.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007648206 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.652       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.65128205128205\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -30.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008059122 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.93        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.1325\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -26.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006856639 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.714       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.6280487804878\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -22.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 557          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064953766 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.02        |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.845        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 2.44         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.1\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -18.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 555          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061048893 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.93        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.677        |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0359      |\n",
      "|    value_loss           | 2.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.562790697674416\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -15.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006240837 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.829       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.04090909090909\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -12.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006742506 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.811       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.51111111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -9.76       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005594828 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.694       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 2.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.96739130434783\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -6.42        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 556          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075469674 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.63        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.847        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.034       |\n",
      "|    value_loss           | 2.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.42872340425532\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -3.72        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 555          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056879325 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.56        |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.032       |\n",
      "|    value_loss           | 2.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.860416666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -1.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 554          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066156797 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.582        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 2.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.30510204081633\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 1.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 553         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004647156 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.4        |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.509       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 1.95        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.757\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 4.02         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 553          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048720352 |\n",
      "|    clip_fraction        | 0.0923       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.36        |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0268      |\n",
      "|    value_loss           | 2.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.17843137254902\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 5.74       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 552        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 52224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00607115 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.36      |\n",
      "|    explained_variance   | 0.877      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.386      |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    value_loss           | 1.7        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.5875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 7.54         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048619388 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.563        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 1.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.01698113207547\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 9.88         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047458564 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.28        |\n",
      "|    explained_variance   | 0.861        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.813        |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0291      |\n",
      "|    value_loss           | 1.89         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.39907407407407\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 11.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053352662 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.22        |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.482        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.78545454545455\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 12.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043464582 |\n",
      "|    clip_fraction        | 0.0734       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.562        |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 1.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.16875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 14.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039029315 |\n",
      "|    clip_fraction        | 0.0743       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.16        |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.437        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0247      |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.532456140350874\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 15.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004010897 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.54        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.88879310344828\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 16.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003863777 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.453       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.242372881355934\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 17.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037303066 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.11        |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.429        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.596666666666664\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038151862 |\n",
      "|    clip_fraction        | 0.0811       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.492        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.93114754098361\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042261276 |\n",
      "|    clip_fraction        | 0.0825       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.383        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0246      |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.25967741935484\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042000646 |\n",
      "|    clip_fraction        | 0.0742       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.398        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0238      |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.58095238095238\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037691398 |\n",
      "|    clip_fraction        | 0.082        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0254      |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.90546875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038534033 |\n",
      "|    clip_fraction        | 0.085        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.32         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0259      |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.216923076923074\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004051286 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.407       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.52045454545455\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 23.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039434694 |\n",
      "|    clip_fraction        | 0.0831       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.507        |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0261      |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.820149253731344\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044013346 |\n",
      "|    clip_fraction        | 0.093        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.34         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0253      |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.11691176470588\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 25.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004300407 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.39782608695652\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042280857 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.331        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0222      |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.68785714285714\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055785533 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.959154929577466\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046121636 |\n",
      "|    clip_fraction        | 0.0924       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0223      |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.225\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 28.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003553831 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.48424657534247\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050250613 |\n",
      "|    clip_fraction        | 0.0978       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.219        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0226      |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.73783783783784\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005200545 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.971333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040556807 |\n",
      "|    clip_fraction        | 0.063        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.358        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0203      |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.20065789473684\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061502927 |\n",
      "|    clip_fraction        | 0.0992       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.177        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0253      |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.416233766233766\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039082887 |\n",
      "|    clip_fraction        | 0.0762       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.232        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0228      |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.631410256410255\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004627095 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.395       |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.84303797468355\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042394935 |\n",
      "|    clip_fraction        | 0.0861       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.246        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.049375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004249066 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 1.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.251234567901236\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 29.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 547        |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 82944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00615857 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.95      |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.202      |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    value_loss           | 1.05       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.44634146341463\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055013793 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.373        |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0246      |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.63734939759036\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047259126 |\n",
      "|    clip_fraction        | 0.0955       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.269        |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0234      |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.832142857142856\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 546          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058985734 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0286      |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.012352941176474\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 546          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053069172 |\n",
      "|    clip_fraction        | 0.098        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0232      |\n",
      "|    value_loss           | 0.988        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.187209302325584\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004979475 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.287       |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.35919540229885\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422326 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.53693181818182\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053837416 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.406        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0278      |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.714606741573036\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051185694 |\n",
      "|    clip_fraction        | 0.0972       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.253        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 0.852        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.88\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004479411 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 0.958       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.04560439560439\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064626792 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.182        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0284      |\n",
      "|    value_loss           | 1            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.204891304347825\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054965606 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.36         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 0.962        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.35913978494624\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 540         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005261466 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.51276595744681\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059945052 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.027       |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.66157894736842\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051950114 |\n",
      "|    clip_fraction        | 0.0919       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.132        |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0236      |\n",
      "|    value_loss           | 0.932        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.811458333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 31.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 537         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006167438 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.387       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.95463917525773\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 535          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054938486 |\n",
      "|    clip_fraction        | 0.0958       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.178        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0218      |\n",
      "|    value_loss           | 0.999        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.093877551020405\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 31.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009457154 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.224747474747474\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 532          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051819193 |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.254        |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0268      |\n",
      "|    value_loss           | 0.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.3635\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 532          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050016916 |\n",
      "|    clip_fraction        | 0.0908       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.991        |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 0.963        |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 29.54\n",
      "Overall Average Successful Assignments: 38.87057758212155\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828cb5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 2.75\n",
      "All assignments history: [1, 2, 3, 8, 3, 2, 6, 2, 3, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -93      |\n",
      "| time/              |          |\n",
      "|    fps             | 551      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 2.775\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -92.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060715135 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | -0.315       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.41         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.516666666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -92.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060055866 |\n",
      "|    clip_fraction        | 0.0681       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | -0.156       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.82         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0302      |\n",
      "|    value_loss           | 11.6         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 10.575\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 502          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050122878 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | -0.0142      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.06         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0269      |\n",
      "|    value_loss           | 9.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.09\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 498          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062258076 |\n",
      "|    clip_fraction        | 0.0756       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.0313       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.87         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 8.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.958333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 480          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068553174 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.0593       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.11         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 8.36         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 16.042857142857144\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074592447 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.0725       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.62         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0349      |\n",
      "|    value_loss           | 7.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.04375\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -91.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 448        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00673841 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.98      |\n",
      "|    explained_variance   | 0.0919     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.88       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 6.86       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.105555555555554\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 443         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007175105 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 6.91        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.16\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009528417 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.39        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 6.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.263636363636362\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 434         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062233 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 6.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.358333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 429          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075895423 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.93        |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0361      |\n",
      "|    value_loss           | 6.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.26153846153846\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 426         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007227582 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.11        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 6.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.964285714285715\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 420         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007974421 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 6.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.926666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -86.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 415          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 15360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072162845 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.88        |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.31         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    value_loss           | 5.99         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.771875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -85.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007189675 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 5.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.591176470588234\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -84.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006568388 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 4.57        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.336111111111112\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -82.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 386         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005675991 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 4.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.028947368421054\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -81.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 380          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 19456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070332848 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.76        |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    value_loss           | 4.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.6575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -80.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005506315 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 3.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.307142857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -78.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006866195 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 3.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.902272727272727\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -76.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057868175 |\n",
      "|    clip_fraction        | 0.0999       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.61        |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0346      |\n",
      "|    value_loss           | 3.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.567391304347826\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -74.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006159675 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.976       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.172916666666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -71.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 363        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00577429 |\n",
      "|    clip_fraction        | 0.082      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.49      |\n",
      "|    explained_variance   | 0.771      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.25       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 3.54       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.738\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -69.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059543364 |\n",
      "|    clip_fraction        | 0.0909       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.42        |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0333      |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.30576923076923\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -67          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068676644 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.33        |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.857407407407408\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -64.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070160907 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.36964285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -62.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063253846 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.15        |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.90862068965517\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -59.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069102515 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.05        |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.48\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -55.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 356         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008263515 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.04838709677419\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -52.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 354         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007051886 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.95        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.6015625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -48.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 352         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006952162 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.15151515151515\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -45.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 351         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007646845 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.694       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.675\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -42.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 352         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006982392 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.832       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.245714285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -38.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 353         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007425946 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.727       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 2.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.795833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -34.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 353         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006160913 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.755       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.35675675675676\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 354         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007640361 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.845       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.86578947368421\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -26.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 354         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008428439 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.696       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 2.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.40512820512821\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -22         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 354         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006824988 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.791       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.93\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -18.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006584518 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 2.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.41829268292683\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -15.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005850302 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.932       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.88809523809524\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -12.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008686046 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.942       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.36046511627907\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -9.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074083563 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 2.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.80568181818182\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -6.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 356         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005672858 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.24666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -4.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005791417 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.696739130434786\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -1.84        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 355          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045798942 |\n",
      "|    clip_fraction        | 0.0833       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.65        |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0292      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.08936170212766\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -0.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060612597 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.63        |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.531        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0295      |\n",
      "|    value_loss           | 2.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.478125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 1.22         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050533838 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.61        |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0306      |\n",
      "|    value_loss           | 2.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.8734693877551\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 2.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 356         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006164534 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.936       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.252\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 3.76         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048656696 |\n",
      "|    clip_fraction        | 0.083        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.56        |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.728        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.027       |\n",
      "|    value_loss           | 2.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.64019607843137\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 5.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041010445 |\n",
      "|    clip_fraction        | 0.0731       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.54        |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0269      |\n",
      "|    value_loss           | 2.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.99230769230769\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 6.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049910443 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.49        |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.909        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    value_loss           | 2.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.35566037735849\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 8.14         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046856515 |\n",
      "|    clip_fraction        | 0.0877       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0292      |\n",
      "|    value_loss           | 2.46         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.68333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 8.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 356         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004820034 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.03272727272727\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043103728 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.38        |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    value_loss           | 2.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.3625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 10.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004776304 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.34       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.727       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.69210526315789\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 12.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044747163 |\n",
      "|    clip_fraction        | 0.0749       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.864        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.79         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.025       |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.014655172413796\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004668699 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.28       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.755       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 2.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.32627118644068\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004859102 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.777       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.62833333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 16           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046661217 |\n",
      "|    clip_fraction        | 0.0956       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.645        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.93032786885246\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 16.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003886122 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 2.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.22096774193548\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 18          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004318973 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.926       |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 2.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.48888888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 18.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004287903 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.766       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.74765625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 19.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004358791 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.765       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.00923076923077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 19.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004094069 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.684       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 2.03        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.26969696969697\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 20.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003874706 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.841       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 2.08        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.515671641791045\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047739567 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.734        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0283      |\n",
      "|    value_loss           | 2.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.74852941176471\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057510105 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.865        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.738        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.025       |\n",
      "|    value_loss           | 2            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.981159420289856\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 20.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003996306 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.62        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.21357142857143\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046660397 |\n",
      "|    clip_fraction        | 0.0821       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.671        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.429577464788736\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 20.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004874495 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.564       |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 1.84        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.645833333333336\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039900388 |\n",
      "|    clip_fraction        | 0.0901       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.746        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0264      |\n",
      "|    value_loss           | 2.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.847945205479455\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039591296 |\n",
      "|    clip_fraction        | 0.0782       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.16        |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.536        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0245      |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.054054054054056\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004437351 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.539       |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.257333333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004034359 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.595       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 2.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.45986842105263\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004190094 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.587       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.6551948051948\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 22          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004253105 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.633       |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 1.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.853846153846156\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 22.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004349052 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.707       |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 1.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.04746835443038\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004050221 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.399       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 1.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.230625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004058088 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.616       |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.407407407407405\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004458206 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 1.52        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.58170731707317\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 24.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004325694 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.568       |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 1.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.74819277108434\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053880336 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.67         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0281      |\n",
      "|    value_loss           | 1.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.91547619047619\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041299285 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.573        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0281      |\n",
      "|    value_loss           | 1.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.08\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044184444 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.631        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0292      |\n",
      "|    value_loss           | 1.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.25232558139535\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051162764 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.469        |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0258      |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.41724137931035\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 25.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004468184 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.57215909090909\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 249          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044475356 |\n",
      "|    clip_fraction        | 0.0819       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.565        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0224      |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.72696629213483\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039833896 |\n",
      "|    clip_fraction        | 0.0825       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.581        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.025       |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.88611111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046202336 |\n",
      "|    clip_fraction        | 0.0943       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.384        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0273      |\n",
      "|    value_loss           | 1.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.03791208791209\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004476306 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.358       |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.18913043478261\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 261          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052139163 |\n",
      "|    clip_fraction        | 0.0866       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.31         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0212      |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.331720430107524\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005484999 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.476063829787236\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 26.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 360        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00413299 |\n",
      "|    clip_fraction        | 0.0821     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.1       |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.381      |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    value_loss           | 1.42       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.61736842105263\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004371639 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.775       |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 1.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.75989583333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037851606 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.525        |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.90051546391753\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 275          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056928676 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.347        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0264      |\n",
      "|    value_loss           | 1.45         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.03775510204082\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 278          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042031407 |\n",
      "|    clip_fraction        | 0.086        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.193        |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.16818181818182\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006244898 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.3005\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 360        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00469967 |\n",
      "|    clip_fraction        | 0.0975     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.07      |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.444      |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    value_loss           | 1.22       |\n",
      "----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 30.0\n",
      "Overall Average Successful Assignments: 39.47713147261827\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da832c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -88.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 4.9\n",
      "All assignments history: [4, 6, 2, 0, 4, 6, 4, 5, 4, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -92.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 435      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -90.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 4.875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006746405 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | -0.301      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 3.4         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -68.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 6.666666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006915168 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | -0.265      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.975\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 390         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006434254 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | -0.217      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 9.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.06\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 386          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061042747 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | -0.083       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.22         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 8.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.941666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 379         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005619421 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | -0.00777    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.5         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 8.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.428571428571429\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 378          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074939462 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.0106       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.73         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 7.23         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.70625\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -89.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 377        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00759349 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.98      |\n",
      "|    explained_variance   | 0.0323     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.69       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 6.92       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.038888888888888\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 377         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008321481 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.0858      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 6.88        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.11\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077791093 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.96        |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.85         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 6.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.881818181818183\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -88.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074305157 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.95        |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.43         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 5.73         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.033333333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007963641 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 5.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.111538461538462\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008039823 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.82        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 4.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.04642857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006640957 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.27        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 4.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.89666666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -86.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 15360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076385383 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.9         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0408      |\n",
      "|    value_loss           | 4.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.6625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -86          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074733594 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.88        |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 4.01         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.441176470588236\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -85.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007570534 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 3.73        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.225\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -84.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007937529 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 3.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.957894736842107\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -83.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 371        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 52         |\n",
      "|    total_timesteps      | 19456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00714699 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.81      |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.01       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0374    |\n",
      "|    value_loss           | 3.21       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.68\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -82.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070856074 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.77        |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.297619047619047\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -81.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 21504      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00733976 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.73      |\n",
      "|    explained_variance   | 0.791      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.42       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    value_loss           | 3.53       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.861363636363638\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -79.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007677176 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.71       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.938       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.35\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 100       |\n",
      "|    ep_rew_mean          | -78.2     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 364       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 23552     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0075836 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -4.68     |\n",
      "|    explained_variance   | 0.813     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.36      |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -0.0406   |\n",
      "|    value_loss           | 2.87      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.810416666666665\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -76.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072725816 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.62        |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.288\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -75.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007112954 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.759615384615383\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -73.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067337034 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.49        |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0387      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.237037037037037\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -70.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071931905 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.42        |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0411      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.7375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -68.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066410596 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.35        |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.995        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.23448275862069\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -65.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006900962 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.686666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -63.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007200088 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.16774193548387\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -60.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007596345 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.6390625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -57.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074845566 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.97        |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.10454545454545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -54.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006863669 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.955       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.5735294117647\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -51.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007552649 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.877       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.04714285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -47.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072758077 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.641        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 2.34         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.525\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -44.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008267989 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.967       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.99189189189189\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -41.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071811974 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.812        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0411      |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.497368421052634\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -37.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007580609 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 2.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.98974358974359\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -34.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072821137 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.609        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 2.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.51\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -30.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069812434 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.18        |\n",
      "|    explained_variance   | 0.77         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    value_loss           | 2.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.00731707317073\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -26.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067127934 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.06        |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.709        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 2.33         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.53928571428571\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -22.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061817644 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | 0.789        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.848        |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0336      |\n",
      "|    value_loss           | 2.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.03023255813954\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -19.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005955489 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.91       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.468       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 2.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.50340909090909\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -15.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070616165 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.748        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 2.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.983333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -12.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064138677 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.498        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 2.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.46413043478261\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -9.42        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054259193 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.67        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0316      |\n",
      "|    value_loss           | 2.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.922340425531914\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -6.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048562735 |\n",
      "|    clip_fraction        | 0.0963       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.58        |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.841        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.031       |\n",
      "|    value_loss           | 2.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.38333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -3.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005008597 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.947       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.820408163265306\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -0.76      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 364        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 50176      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00502053 |\n",
      "|    clip_fraction        | 0.0675     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.52      |\n",
      "|    explained_variance   | 0.826      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.971      |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    value_loss           | 2.51       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.235\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 0.74        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005065658 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.525       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.66372549019608\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 2.82        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005184208 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.78        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 2.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.08076923076923\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 4.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056411633 |\n",
      "|    clip_fraction        | 0.0883       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.44        |\n",
      "|    explained_variance   | 0.863        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.583        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0253      |\n",
      "|    value_loss           | 1.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.47547169811321\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 5.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005576345 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.44       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 1.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.862037037037034\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 7.56         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049588894 |\n",
      "|    clip_fraction        | 0.0921       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.4         |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.651        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0295      |\n",
      "|    value_loss           | 2.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.231818181818184\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 8.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004026901 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.618       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 1.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.59375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 9.56        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004748377 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.659       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.96491228070175\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 10.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043570986 |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.384        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0286      |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.331896551724135\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 11.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004208299 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.679       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 1.99        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.666101694915255\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 12.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004932056 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.698       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.0\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004950663 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.832       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 1.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.34672131147541\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004189049 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.679       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 1.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.67338709677419\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 15.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003854037 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.746       |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 1.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.99603174603175\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 16.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004359085 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.475       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.31171875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045786165 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.024       |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.62307692307692\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 19.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005138376 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.593       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.92272727272727\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 184          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043616667 |\n",
      "|    clip_fraction        | 0.0787       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.601        |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0215      |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.21492537313433\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004910612 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 1.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.50588235294118\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 21.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041662343 |\n",
      "|    clip_fraction        | 0.0931       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 1.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.78695652173913\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042863037 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2           |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.374        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.05428571428571\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004149136 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.284       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.33521126760564\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 24.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004341122 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.60486111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042585465 |\n",
      "|    clip_fraction        | 0.087        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.87397260273973\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037199138 |\n",
      "|    clip_fraction        | 0.0761       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.417        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0266      |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.13310810810811\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046556983 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.486        |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.024       |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.382666666666665\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003760077 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.323       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.627631578947366\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004449581 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.406       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.877272727272725\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004538254 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.294       |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 1.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.11538461538461\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034559024 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.267        |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.02        |\n",
      "|    value_loss           | 1.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.35632911392405\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047404077 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.288        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.578125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 225          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040669134 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.395        |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0224      |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.800617283950615\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048075174 |\n",
      "|    clip_fraction        | 0.0859       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.689        |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.025       |\n",
      "|    value_loss           | 1.49         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.014634146341464\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043614395 |\n",
      "|    clip_fraction        | 0.092        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.363        |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0254      |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.230722891566266\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004943019 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.44940476190476\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004520118 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.338       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.66529411764706\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 30.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 361        |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 240        |\n",
      "|    total_timesteps      | 87040      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00475699 |\n",
      "|    clip_fraction        | 0.0875     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.83      |\n",
      "|    explained_variance   | 0.909      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.536      |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | -0.0253    |\n",
      "|    value_loss           | 1.38       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.88023255813953\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 31.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 359        |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 244        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00394625 |\n",
      "|    clip_fraction        | 0.0807     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.83      |\n",
      "|    explained_variance   | 0.922      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.283      |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    value_loss           | 1.2        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.092528735632186\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040713176 |\n",
      "|    clip_fraction        | 0.0668       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.116        |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0217      |\n",
      "|    value_loss           | 0.928        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.29318181818182\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 251          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043715923 |\n",
      "|    clip_fraction        | 0.0802       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.167        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0221      |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.491573033707866\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045341062 |\n",
      "|    clip_fraction        | 0.0959       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.028       |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.67888888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043445453 |\n",
      "|    clip_fraction        | 0.0717       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.31         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0208      |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.86813186813187\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 32.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004074825 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.05652173913043\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004083075 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.331       |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.237096774193546\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005235336 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.41436170212766\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004600021 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.376       |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.59684210526316\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 34.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004942044 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.76875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 34           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050447155 |\n",
      "|    clip_fraction        | 0.086        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.183        |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0258      |\n",
      "|    value_loss           | 0.977        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.93865979381443\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 34         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 359        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 99328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00471979 |\n",
      "|    clip_fraction        | 0.0911     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.85      |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.292      |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 1.12       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.10408163265306\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 34.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007152699 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.351       |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.265151515151516\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 34.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 359        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 281        |\n",
      "|    total_timesteps      | 101376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00581548 |\n",
      "|    clip_fraction        | 0.0943     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.21       |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    value_loss           | 1.02       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.4205\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 34.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 284          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047753756 |\n",
      "|    clip_fraction        | 0.0847       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.911        |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0265      |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 30.84\n",
      "Overall Average Successful Assignments: 38.28293850844623\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4bb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 3.1\n",
      "All assignments history: [5, 3, 3, 4, 3, 5, 3, 3, 7, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -91.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -66.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 6.925\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007508908 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.067       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -48.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.75\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006309334 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.0581      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 9.68        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 10.65\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 351         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005286822 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.0528      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.23        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 8.38        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 11.3\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 346          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059864284 |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.0804       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.24         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.029       |\n",
      "|    value_loss           | 8.42         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.933333333333334\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -90.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 329        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00680233 |\n",
      "|    clip_fraction        | 0.0998     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.99      |\n",
      "|    explained_variance   | 0.0877     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.86       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 7.02       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.17142857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007867548 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.0976      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.56        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 7.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.9375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007247041 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.06        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 6.58        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.22222222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008523203 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 6.01        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.345\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007810382 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 6.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.145454545454545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009557851 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.67        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 6.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.941666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008743072 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 6.27        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.834615384615386\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -88.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 341          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 13312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073022195 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.94        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.05         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 6.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.71785714285714\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -87.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067846603 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.93        |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.05         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 5.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.573333333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 342         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006348631 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.41        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 5.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.146875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -86.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062449956 |\n",
      "|    clip_fraction        | 0.0873       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.91        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.13         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 5.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.66470588235294\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -86         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 338         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007043789 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.43        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 4.86        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.169444444444444\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -85.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062584453 |\n",
      "|    clip_fraction        | 0.0943       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.88        |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.06         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    value_loss           | 4.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.642105263157895\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -85.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006028534 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.81        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 4.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.02\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -84.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 331          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068167173 |\n",
      "|    clip_fraction        | 0.0999       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.83        |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 4.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.419047619047618\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -83.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007042886 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 4.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.802272727272726\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -82.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 329        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00553184 |\n",
      "|    clip_fraction        | 0.067      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.77      |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.18       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 3.88       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.265217391304347\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -81.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 328         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006954172 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.65625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -80.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 328          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066259233 |\n",
      "|    clip_fraction        | 0.0995       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.69        |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 3.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.158\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -78.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 328         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006266637 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.630769230769232\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -76.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 328          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067687957 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.56        |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.127777777777776\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -74.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 328          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067195725 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.49        |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.616071428571427\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -72.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 327          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079752365 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.42        |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.124137931034483\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -69.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007605453 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.35       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.745       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.66\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -66.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 325        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00714808 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.27      |\n",
      "|    explained_variance   | 0.789      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.813      |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0429    |\n",
      "|    value_loss           | 2.85       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.18548387096774\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -63.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007160055 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.734375\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -60.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 321        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00743661 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.05      |\n",
      "|    explained_variance   | 0.739      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.2        |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0451    |\n",
      "|    value_loss           | 3.13       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.265151515151516\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -56.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008342628 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.75735294117647\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -53.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 318          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081238095 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.85        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.28285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -49.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007126059 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.73        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.80972222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -45.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007629432 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.926       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.372972972972974\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -41.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073504387 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.857        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.9\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -37.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065342095 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.79         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 2.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.426923076923075\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -33.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007893177 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.95125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -29.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007600403 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.678       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 2.42        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.47682926829268\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -26.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008117272 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.99404761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -22.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 309          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068442095 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.927        |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 2.63         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.52209302325581\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -18.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006890688 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.796       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 2.35        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.054545454545455\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -14.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 308          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064214556 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.951        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0412      |\n",
      "|    value_loss           | 2.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.57222222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -11.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005567775 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.08586956521739\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -7.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 308          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058925957 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0306      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.53829787234042\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -5.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051244553 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.67        |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.782        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 2.52         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.00625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -3.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005772992 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.46224489795918\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -0.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 306          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067328275 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.55        |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0322      |\n",
      "|    value_loss           | 2.64         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.927\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 2.12         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049159545 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.49        |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.881        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.031       |\n",
      "|    value_loss           | 2.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.36764705882353\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 4.28         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053062527 |\n",
      "|    clip_fraction        | 0.0918       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.81         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.626        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0293      |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.78653846153846\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 6.26         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045619695 |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.39        |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0261      |\n",
      "|    value_loss           | 2.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.19056603773585\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 7.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003715916 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.35       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.577777777777776\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 8.52         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 303          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055130385 |\n",
      "|    clip_fraction        | 0.0991       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.028       |\n",
      "|    value_loss           | 2.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.97636363636364\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 9.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005667643 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.71        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 2.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.34285714285714\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 302          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051628286 |\n",
      "|    clip_fraction        | 0.09         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.731        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0245      |\n",
      "|    value_loss           | 2.43         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.717543859649126\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 12           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057920264 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.901        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 2.46         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.07672413793104\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 13.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 300          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043830294 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.751        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0214      |\n",
      "|    value_loss           | 2.36         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.41271186440678\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 13.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 299          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040407637 |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0212      |\n",
      "|    value_loss           | 2.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.73583333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003950324 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.881       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 2.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.07295081967213\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003760388 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.523       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.39354838709677\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 15.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004331239 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.658       |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 2.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.71111111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 15.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 295          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040648193 |\n",
      "|    clip_fraction        | 0.0651       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.16        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.804        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0238      |\n",
      "|    value_loss           | 1.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.02578125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 16.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 294          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039534518 |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.755        |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0199      |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.31230769230769\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 17           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040664393 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.503        |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0218      |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.6\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 18          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003364246 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.666       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.884328358208954\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 291          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044542253 |\n",
      "|    clip_fraction        | 0.0861       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0238      |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.154411764705884\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 290          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030513888 |\n",
      "|    clip_fraction        | 0.065        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.418        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0211      |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.42028985507246\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 19.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003890552 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.477       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.68857142857143\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049455985 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.311        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0266      |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.959154929577466\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004215111 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.468       |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.21597222222222\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 21.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045850165 |\n",
      "|    clip_fraction        | 0.0853       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.37         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0245      |\n",
      "|    value_loss           | 1.49         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.46232876712329\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 261          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041399263 |\n",
      "|    clip_fraction        | 0.0767       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.272        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0221      |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.7\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 22.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003845436 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.47        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.937333333333335\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 100       |\n",
      "|    ep_rew_mean          | 22.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 283       |\n",
      "|    iterations           | 75        |\n",
      "|    time_elapsed         | 270       |\n",
      "|    total_timesteps      | 76800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0033263 |\n",
      "|    clip_fraction        | 0.0704    |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -2.04     |\n",
      "|    explained_variance   | 0.916     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 1.46      |\n",
      "|    n_updates            | 740       |\n",
      "|    policy_gradient_loss | -0.0246   |\n",
      "|    value_loss           | 1.57      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.16381578947368\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 275          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046772254 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.261        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0274      |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.40584415584416\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 23.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045914585 |\n",
      "|    clip_fraction        | 0.091        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.368        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0259      |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.63782051282051\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004402671 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.86329113924051\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 280          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 288          |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046940357 |\n",
      "|    clip_fraction        | 0.0864       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.432        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0221      |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.084375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036377918 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.309        |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0229      |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.29506172839506\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 24.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004836537 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.249       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 1           |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.51341463414634\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 25          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005040629 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.24        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.723493975903615\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 276          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 307          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050148126 |\n",
      "|    clip_fraction        | 0.0931       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.116        |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0236      |\n",
      "|    value_loss           | 0.907        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.93154761904762\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061843814 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.121        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.025       |\n",
      "|    value_loss           | 0.947        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.131764705882354\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 316          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054875994 |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.226        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    value_loss           | 0.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.32848837209303\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005126098 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.826       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.52298850574713\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 274          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 325          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061302516 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    value_loss           | 0.944        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.70454545454545\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 273          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048801037 |\n",
      "|    clip_fraction        | 0.0923       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.195        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0236      |\n",
      "|    value_loss           | 0.957        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.87921348314607\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061191805 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0271      |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.06666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004259509 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.24835164835165\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 343          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041196253 |\n",
      "|    clip_fraction        | 0.0985       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.139        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0273      |\n",
      "|    value_loss           | 0.843        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.4195652173913\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053822314 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.117        |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0272      |\n",
      "|    value_loss           | 0.926        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.59623655913978\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 28.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 353        |\n",
      "|    total_timesteps      | 95232      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00503048 |\n",
      "|    clip_fraction        | 0.0995     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.181      |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    value_loss           | 0.897      |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.768085106382976\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 358          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049205683 |\n",
      "|    clip_fraction        | 0.0972       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0218      |\n",
      "|    value_loss           | 0.984        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.93684210526316\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064537367 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.112        |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0288      |\n",
      "|    value_loss           | 0.731        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.0984375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 368          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061608907 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0928       |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0259      |\n",
      "|    value_loss           | 0.785        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.26752577319588\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004478713 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.894       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.429591836734694\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047206995 |\n",
      "|    clip_fraction        | 0.0988       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.12         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 0.833        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.594949494949496\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 383          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047629536 |\n",
      "|    clip_fraction        | 0.0901       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.972        |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 0.852        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.7575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005302674 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0673      |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.757       |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 26.14\n",
      "Overall Average Successful Assignments: 37.01067644774575\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3699e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -82.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 6.15\n",
      "All assignments history: [2, 5, 4, 5, 6, 2, 2, 1, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -93.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 237      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -62.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 8.775\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -92.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061978074 |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | -0.136       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.55         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0315      |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -46.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 11.133333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -92.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067604384 |\n",
      "|    clip_fraction        | 0.0734       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | -0.087       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0324      |\n",
      "|    value_loss           | 10.9         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.0875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 202          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062252935 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | 0.0412       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0315      |\n",
      "|    value_loss           | 8.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.38\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006459019 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.0803      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 7.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.841666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 196         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006670541 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.82        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 7.3         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.457142857142856\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 198          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059363125 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.13         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.43         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 7.56         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.09375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007332513 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.53        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 6.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.72222222222222\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 202          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072345855 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.98        |\n",
      "|    explained_variance   | 0.198        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.66         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    value_loss           | 6.38         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.235\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075360667 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.97        |\n",
      "|    explained_variance   | 0.27         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 6.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.87727272727273\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008809055 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 5.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.641666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -88.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075504966 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.95        |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.2          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 5.67         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.361538461538462\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007070588 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 5.28        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.039285714285715\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -87.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070426194 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.92        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 4.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.713333333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -86.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006290668 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 4.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.303125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -86.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006468647 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.96        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 3.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.83235294117647\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -85.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059073414 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.87        |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 3.95         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.17222222222222\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -84.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064984714 |\n",
      "|    clip_fraction        | 0.0996       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.84        |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 4.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.71578947368421\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -83.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006809517 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.82       |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.315\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -82.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006330494 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.85238095238095\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -80.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064727487 |\n",
      "|    clip_fraction        | 0.0883       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.77        |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.033       |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.338636363636365\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -80.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007264932 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.74       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.88695652173913\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -78.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067774057 |\n",
      "|    clip_fraction        | 0.0967       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.035       |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.370833333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -77.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058492734 |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.833        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.836\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -75.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007352112 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.865       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.59        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.315384615384616\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -73.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007253642 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.79074074074074\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -72.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006587809 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.51       |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.275\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -69.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007426084 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.949       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.767241379310345\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -67.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006707337 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.35       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.283333333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -64.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007854046 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.27       |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.791       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.79193548387097\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -62.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 211        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 31744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00656158 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.17      |\n",
      "|    explained_variance   | 0.839      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.907      |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 2.74       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.278125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -58.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068913177 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.06        |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.997        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.745454545454546\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -56.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008370519 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.661       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.247058823529414\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -52.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008323364 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.75142857142857\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -48.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006963067 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.877       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.25416666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -45         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008982044 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.763513513513516\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -40.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075151306 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.51        |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.873        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.25\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -37.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007998162 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.751282051282054\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -33.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009229299 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.235\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006175146 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 3.17        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.708536585365856\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -26.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008147755 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.194047619047616\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -23.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073488783 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.04        |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.694186046511625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -19.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063952506 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.97        |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.57         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.16136363636364\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -16.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068093007 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.94        |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0324      |\n",
      "|    value_loss           | 2.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.61888888888889\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -13.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006850639 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.06086956521739\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -10.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064716274 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.933        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 2.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.492553191489364\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -8.84        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062050014 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.9          |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 2.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.94479166666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -6.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006223587 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.38367346938775\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -3.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 238          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047657685 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.62        |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.897        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0244      |\n",
      "|    value_loss           | 2.66         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.843\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -1.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058612013 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.58        |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.798        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0286      |\n",
      "|    value_loss           | 2.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.266666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 0.82        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005661669 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.816       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 2.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.675961538461536\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 2.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006588615 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.951       |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.077358490566034\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 3.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005688785 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.927       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.48148148148148\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 5.16         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 262          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060644457 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.5         |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.886        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0297      |\n",
      "|    value_loss           | 2.45         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.88090909090909\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 6.64        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004666237 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.47       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.799       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 2.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.27410714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 8.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005061197 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.989       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.65438596491228\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 9.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 276          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067196367 |\n",
      "|    clip_fraction        | 0.0959       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.908        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0257      |\n",
      "|    value_loss           | 2.12         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.00948275862069\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 10.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049323766 |\n",
      "|    clip_fraction        | 0.0949       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.4         |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.72         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.028       |\n",
      "|    value_loss           | 2.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.372033898305084\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 11.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 286          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051003154 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.34        |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.907        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0311      |\n",
      "|    value_loss           | 2.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.745\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 12.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005254491 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.924       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 2.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.087704918032784\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 13.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 295          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050812983 |\n",
      "|    clip_fraction        | 0.0849       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.817        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0226      |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.41935483870968\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 14.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050832615 |\n",
      "|    clip_fraction        | 0.0959       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.647        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0278      |\n",
      "|    value_loss           | 2.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.7484126984127\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 15.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 305          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050769476 |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.28        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.667        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 2.21         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.07109375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 16          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005024428 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.468       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.393846153846155\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 17.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041856198 |\n",
      "|    clip_fraction        | 0.0784       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.746        |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    value_loss           | 2            |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.696969696969695\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 17.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 319          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058189696 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.633        |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.994029850746266\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 18.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005917215 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.561       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.283088235294116\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052123815 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.22        |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.585        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0259      |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.57028985507247\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039137024 |\n",
      "|    clip_fraction        | 0.0931       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.894        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0271      |\n",
      "|    value_loss           | 1.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.847857142857144\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 19.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004153421 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.63        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.11971830985915\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 343          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049168267 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.751        |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 1.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.38472222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005079532 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.758       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.65068493150685\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 21.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 352          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046410803 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.91148648648649\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 356          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046209125 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.11        |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.366        |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0233      |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.157333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 360          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049098707 |\n",
      "|    clip_fraction        | 0.0915       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.15        |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.496        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0246      |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.41381578947368\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004039284 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.464       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.654545454545456\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 23.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 368          |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048843767 |\n",
      "|    clip_fraction        | 0.0927       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.409        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.89358974358974\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 372          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051347218 |\n",
      "|    clip_fraction        | 0.0972       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0262      |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.1246835443038\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 376          |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054375343 |\n",
      "|    clip_fraction        | 0.0971       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.542        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.355625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 380          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044092303 |\n",
      "|    clip_fraction        | 0.0791       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.56728395061728\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 385          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048379917 |\n",
      "|    clip_fraction        | 0.0945       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.365        |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.78414634146341\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004738368 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.409       |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.99578313253012\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 393          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041653714 |\n",
      "|    clip_fraction        | 0.0842       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.329        |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0248      |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.21071428571429\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048022317 |\n",
      "|    clip_fraction        | 0.0952       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.986        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0265      |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.417647058823526\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005285077 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.61802325581395\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004513231 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.331       |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.81436781609195\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005526395 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.503       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.00340909090909\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 414          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044555087 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.211        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.18258426966292\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005972887 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.986       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.37277777777778\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 28         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 218        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 422        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00519994 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.02      |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.425      |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.0284    |\n",
      "|    value_loss           | 1.36       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.55494505494506\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 28.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 218        |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 426        |\n",
      "|    total_timesteps      | 93184      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00568712 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.01      |\n",
      "|    explained_variance   | 0.933      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.196      |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    value_loss           | 0.98       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.73695652173913\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 218          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 430          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048532155 |\n",
      "|    clip_fraction        | 0.0893       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2           |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.287        |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0244      |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.909677419354836\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 218          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 434          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066762194 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.105        |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    value_loss           | 0.882        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.07553191489362\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 438          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052893544 |\n",
      "|    clip_fraction        | 0.0941       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.106        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0251      |\n",
      "|    value_loss           | 0.931        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.23368421052631\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 442          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077834786 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.26         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0311      |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.3921875\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 28.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 447        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00706725 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.02      |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.309      |\n",
      "|    n_updates            | 950        |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 1.1        |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.56082474226804\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005726799 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.71632653061224\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005021119 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.21        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 0.971       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.87676767676768\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 459          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052495394 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.205        |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    value_loss           | 0.947        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.036\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 464          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068038777 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.183        |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.027       |\n",
      "|    value_loss           | 0.857        |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 27.4\n",
      "Overall Average Successful Assignments: 37.46009461722642\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f8b14a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 2.15\n",
      "All assignments history: [4, 3, 6, 4, 6, 2, 5, 6, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -91.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 5.4\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006848591 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | -0.0769     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.94        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 11.533333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067370934 |\n",
      "|    clip_fraction        | 0.0683       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | -0.0336      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0307      |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.9375\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 100       |\n",
      "|    ep_rew_mean          | -90.2     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 254       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0070311 |\n",
      "|    clip_fraction        | 0.102     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -5.01     |\n",
      "|    explained_variance   | 0.0753    |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 2.1       |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -0.0334   |\n",
      "|    value_loss           | 7.79      |\n",
      "---------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.19\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005656586 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 8.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.891666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069775707 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 3.29         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0342      |\n",
      "|    value_loss           | 7.67         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.45\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007848075 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 6.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.54375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008105694 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 6.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.216666666666665\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -88.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077266693 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.96        |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.86         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 5.78         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.315\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009091396 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.41        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 4.97        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.331818181818182\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007967401 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 5.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.033333333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007875393 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.91       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 5.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.803846153846155\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -87.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 13312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00768989 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.9       |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.69       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 4.62       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.553571428571427\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -85.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079044625 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.88        |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.95         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 4.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.116666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -84.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006248299 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 4.59        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.7125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -83.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066324663 |\n",
      "|    clip_fraction        | 0.0926       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.85        |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.07         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.155882352941177\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -83.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069284923 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.82        |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 3.72         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.605555555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -82.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071374867 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.8         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.055263157894736\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -81.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 19456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072175413 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.76        |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0402      |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.475\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -79.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071042716 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.72        |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.866666666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -78.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073230565 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.833        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.338636363636365\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -76.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063702855 |\n",
      "|    clip_fraction        | 0.0858       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.63        |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.685        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 2.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.776086956521738\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -75.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006295934 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.57       |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.2125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -73.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006234008 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.911       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.678\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -71.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064119585 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.43        |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 2.7          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.16538461538462\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -69.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075247018 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.38        |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.717        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 2.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.63333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -66.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067559397 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0413      |\n",
      "|    value_loss           | 3.08         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.1125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -63.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061929515 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.601724137931036\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -61         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006824174 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.096666666666664\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -57.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005391988 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.56612903225806\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -54.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064710137 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.788        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 2.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.053125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -50.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006608054 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.546       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.53939393939394\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -47.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006179249 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.00147058823529\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -44          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065081646 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.59        |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.48571428571429\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -40.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077429367 |\n",
      "|    clip_fraction        | 0.186        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0461      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.96805555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -36.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009476854 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.91        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.43378378378378\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -32.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007313515 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.91315789473684\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -29          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073723476 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.21        |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.943        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    value_loss           | 2.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.38846153846154\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -25.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077502634 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.11        |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.84\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -22.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007398855 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.06       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.29390243902439\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -18.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068617947 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.97        |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.75119047619047\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -15.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007199224 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.2093023255814\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -12.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052963723 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.654545454545456\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -9.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 184          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063401805 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.97         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.11666666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -6.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 244        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 188        |\n",
      "|    total_timesteps      | 46080      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00614512 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.72      |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.02       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 2.69       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.56195652173913\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -4.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006302339 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.835       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.994680851063826\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -1.72        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056755817 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.59        |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.746        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.43020833333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 0.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006263787 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.556       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 2.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.837755102040816\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 2.56        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004808867 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.249\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 4.74         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049142563 |\n",
      "|    clip_fraction        | 0.0931       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0281      |\n",
      "|    value_loss           | 2.7          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.63725490196079\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 6.38         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043447632 |\n",
      "|    clip_fraction        | 0.0885       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.5         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.979        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.00865384615385\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 8.16         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062202727 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 2.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.37924528301887\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 9.64         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044144774 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0275      |\n",
      "|    value_loss           | 2.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.733333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 11.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043306425 |\n",
      "|    clip_fraction        | 0.0909       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0288      |\n",
      "|    value_loss           | 2.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.08\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 12.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046398933 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.38        |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.82         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0286      |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.43482142857143\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 13.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053248387 |\n",
      "|    clip_fraction        | 0.0959       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.35        |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.542        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.027       |\n",
      "|    value_loss           | 2.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.78771929824561\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 14.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006004819 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.717       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.1\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 14.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 243          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047612465 |\n",
      "|    clip_fraction        | 0.0995       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.874        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0274      |\n",
      "|    value_loss           | 2            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.4271186440678\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 15.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 247          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044876332 |\n",
      "|    clip_fraction        | 0.0951       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.776        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 2.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.73916666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 16          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004009314 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.753       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.057377049180324\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 17           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040295725 |\n",
      "|    clip_fraction        | 0.0844       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.22        |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.659        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 2.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.37822580645161\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 260          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048284205 |\n",
      "|    clip_fraction        | 0.0912       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.543        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0259      |\n",
      "|    value_loss           | 2.03         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.689682539682536\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040894747 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.16        |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0227      |\n",
      "|    value_loss           | 1.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.99453125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 20          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005655798 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.537       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.29769230769231\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004152461 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.774       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 2.03        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.59469696969697\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 278          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038122053 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.716        |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0212      |\n",
      "|    value_loss           | 1.91         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.87014925373134\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 282          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041696145 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.592        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0223      |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.144852941176474\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 23.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 287          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041851066 |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.11        |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.527        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0215      |\n",
      "|    value_loss           | 1.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.39710144927536\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 291          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045395633 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.502        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 1.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.64857142857143\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041845404 |\n",
      "|    clip_fraction        | 0.0787       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.67         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0235      |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.901408450704224\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 298          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050500035 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.623        |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.15902777777778\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 303          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045785373 |\n",
      "|    clip_fraction        | 0.0938       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 1.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.4027397260274\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004109325 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.61        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.63716216216216\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043813046 |\n",
      "|    clip_fraction        | 0.0787       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.497        |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0223      |\n",
      "|    value_loss           | 1.65         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.864\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 314          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047553834 |\n",
      "|    clip_fraction        | 0.0874       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0234      |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.09736842105263\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044945227 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.48         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.024       |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.33311688311688\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 322          |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056669377 |\n",
      "|    clip_fraction        | 0.0883       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.232        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0242      |\n",
      "|    value_loss           | 1.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.54423076923077\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039402815 |\n",
      "|    clip_fraction        | 0.071        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.547        |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0213      |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.756962025316454\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048665395 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2           |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.482        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0268      |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.965625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 333          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046024057 |\n",
      "|    clip_fraction        | 0.0926       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.351        |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.17469135802469\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 29.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 337        |\n",
      "|    total_timesteps      | 82944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00442095 |\n",
      "|    clip_fraction        | 0.0836     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.98      |\n",
      "|    explained_variance   | 0.902      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.361      |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    value_loss           | 1.47       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.36585365853659\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005050987 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.407       |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.55722891566265\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005080279 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.478       |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.74166666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004879077 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.375       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.940588235294115\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 30.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 351        |\n",
      "|    total_timesteps      | 87040      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00384147 |\n",
      "|    clip_fraction        | 0.0845     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.94      |\n",
      "|    explained_variance   | 0.903      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.494      |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 1.48       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.132558139534886\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 354          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044987947 |\n",
      "|    clip_fraction        | 0.09         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0213      |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.3183908045977\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004930621 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 1           |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.503977272727276\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050189206 |\n",
      "|    clip_fraction        | 0.0826       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0229      |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.66573033707865\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060438323 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.322        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0236      |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.836666666666666\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 368          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049069067 |\n",
      "|    clip_fraction        | 0.0917       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.568        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.004945054945054\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 371          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048566256 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.169        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0226      |\n",
      "|    value_loss           | 1.16         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.17554347826087\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 32.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 374        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00643768 |\n",
      "|    clip_fraction        | 0.0949     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.96      |\n",
      "|    explained_variance   | 0.926      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.449      |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.328494623655914\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 377          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050190073 |\n",
      "|    clip_fraction        | 0.096        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.17         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0218      |\n",
      "|    value_loss           | 0.962        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.49095744680851\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 32.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005446355 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.477       |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.64684210526316\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 383          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060820617 |\n",
      "|    clip_fraction        | 0.0849       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0205      |\n",
      "|    value_loss           | 0.972        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.7984375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 32.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004387524 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.208       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 0.937       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.94948453608247\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 389          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051718904 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.251        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 55.09591836734694\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 32.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 255        |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 392        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00718562 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.934      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1          |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.0276    |\n",
      "|    value_loss           | 0.916      |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 55.24090909090909\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 395          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054504955 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.199        |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0248      |\n",
      "|    value_loss           | 0.976        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 55.384\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 398          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062506655 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.191        |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0234      |\n",
      "|    value_loss           | 0.925        |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 32.52\n",
      "Overall Average Successful Assignments: 40.52656071896684\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b84e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -86.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 5.9\n",
      "All assignments history: [5, 3, 8, 3, 5, 6, 5, 4, 4, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -90.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 436      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.225\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063776365 |\n",
      "|    clip_fraction        | 0.0612       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.92         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0336      |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.8\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005965767 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.00417     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -56.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.275\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006944466 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | -0.00676    |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 8.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 10.77\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066164993 |\n",
      "|    clip_fraction        | 0.0908       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.04         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.23         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0324      |\n",
      "|    value_loss           | 7.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.158333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067093447 |\n",
      "|    clip_fraction        | 0.0861       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.0608       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.75         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 7.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.15\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007408115 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.0889      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 7.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.8375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006817203 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.34        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 6.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.205555555555556\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007524943 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.44        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 6.04        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.245\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008859288 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.06        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 5.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.20909090909091\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007702157 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 5.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.979166666666668\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007636937 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 5.2         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.723076923076924\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007556668 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.40357142857143\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006845682 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 4.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.94\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -87.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 374          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 15360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072642528 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.91        |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.46875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -86.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007132558 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.98235294117647\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -85.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066043716 |\n",
      "|    clip_fraction        | 0.0997       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.88        |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0368      |\n",
      "|    value_loss           | 3.48         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.57777777777778\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -84.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076025235 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.85        |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0406      |\n",
      "|    value_loss           | 3.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.11315789473684\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -83.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 19456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066854507 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.84        |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.855        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.6\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -83         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006120253 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.82       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.609       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.13095238095238\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -82          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071255737 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.78        |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.924        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0413      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.729545454545455\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -80.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007675166 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.75       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.35217391304348\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -78.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 374          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068168677 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.995833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -77.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007120948 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.54        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.584\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -75.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062225508 |\n",
      "|    clip_fraction        | 0.098        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.63        |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.130769230769232\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -73.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079469485 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.58        |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0424      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.711111111111112\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -71.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007265092 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 2.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.2125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -70          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073756506 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.45        |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.895        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0458      |\n",
      "|    value_loss           | 2.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.713793103448275\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -68         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007791434 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.39       |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.683       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.243333333333332\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -65.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073058866 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.3         |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.83         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 2.44         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.833870967741934\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -62.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 370        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 31744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00814608 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.22      |\n",
      "|    explained_variance   | 0.84       |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.98       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0432    |\n",
      "|    value_loss           | 2.69       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.3875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -59.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076579303 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.12        |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.042       |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.922727272727272\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -56.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073756333 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.02        |\n",
      "|    explained_variance   | 0.867        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.383        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0403      |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.46470588235294\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -53         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007842616 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.824       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.01571428571429\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -49.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007827796 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.781       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.548611111111114\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -45.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006985288 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 2.54        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.07972972972973\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -42.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009265274 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.649       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 2.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.63947368421053\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -37.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076725306 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.914        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0417      |\n",
      "|    value_loss           | 2.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.18846153846154\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -33.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078025525 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.37        |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.826        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0411      |\n",
      "|    value_loss           | 2.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.7\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -30.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072050784 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.27        |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.817        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.234146341463415\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -26.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008008346 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 2.38        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.76190476190476\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -23         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005858787 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.701       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.27558139534884\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -19.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006485886 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.913       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 2.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.77272727272727\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -16.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005553506 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.886       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.25\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -13.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005965419 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.915       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.71630434782609\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -10.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005947804 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.180851063829785\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -7.78        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053630657 |\n",
      "|    clip_fraction        | 0.098        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.9          |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 2.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.623958333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -5.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005181713 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.929       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 2.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.06938775510204\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -3.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005951138 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.833       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 2.42        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.507\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -1.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054885256 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.61        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.621        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0301      |\n",
      "|    value_loss           | 2.42         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.938235294117646\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 0.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054237503 |\n",
      "|    clip_fraction        | 0.0997       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.54        |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.722        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.031       |\n",
      "|    value_loss           | 2.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.363461538461536\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 2.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004910569 |\n",
      "|    clip_fraction        | 0.0889      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.743       |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.79433962264151\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 4.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005751062 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.772       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.196296296296296\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 6.64         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038472852 |\n",
      "|    clip_fraction        | 0.086        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.37        |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.748        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.589090909090906\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 8.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004802455 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.514       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.975\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 10.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004134639 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.996       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 1.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.357894736842105\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 12          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004297089 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.795       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.724137931034484\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004473529 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.092372881355935\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 15.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051342538 |\n",
      "|    clip_fraction        | 0.0971       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.15        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.446        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0259      |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.43833333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 16.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045862263 |\n",
      "|    clip_fraction        | 0.0752       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.451        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0219      |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.78852459016394\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 17.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036265804 |\n",
      "|    clip_fraction        | 0.0792       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.542        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0248      |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.126612903225805\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041411216 |\n",
      "|    clip_fraction        | 0.0878       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.467        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.448412698412696\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053710425 |\n",
      "|    clip_fraction        | 0.0965       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.49         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0267      |\n",
      "|    value_loss           | 1.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.77734375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 20.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004040567 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.606       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.09923076923077\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003558548 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.672       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 1.53        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.43333333333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 22.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004237742 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.502       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.75223880597015\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004938867 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.466       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.061764705882354\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044534625 |\n",
      "|    clip_fraction        | 0.0974       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.403        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0253      |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.36449275362319\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 24.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004168749 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.233       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.65571428571429\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 25.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003920527 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.524       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.95140845070423\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 26.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 371        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 72704      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00494606 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.923      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.446      |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.0277    |\n",
      "|    value_loss           | 1.28       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.231944444444444\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049215527 |\n",
      "|    clip_fraction        | 0.0939       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.283        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0222      |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.51027397260274\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047945245 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.923        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.335        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0278      |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.78243243243243\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 28.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 372        |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00470504 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.228      |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    value_loss           | 1.07       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.053333333333335\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051458892 |\n",
      "|    clip_fraction        | 0.0859       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.315        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0232      |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.30855263157895\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006212179 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.874       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.55909090909091\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 29.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 371        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 212        |\n",
      "|    total_timesteps      | 78848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00499669 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.9       |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.763      |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    value_loss           | 0.855      |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.80320512820513\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004687121 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.506       |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.04367088607595\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004016136 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0836      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.28\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005624408 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.196       |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.874       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.51604938271605\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005443643 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.778       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.983       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.73719512195122\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 31.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 371        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 226        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00522885 |\n",
      "|    clip_fraction        | 0.0979     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.86      |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.786      |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.884      |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.966265060240964\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 31.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005348315 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.273       |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.17261904761905\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059283418 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.081        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 0.712        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.388823529411766\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053838035 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.174        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0292      |\n",
      "|    value_loss           | 0.974        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.598837209302324\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046205865 |\n",
      "|    clip_fraction        | 0.0851       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.192        |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0229      |\n",
      "|    value_loss           | 0.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.802298850574715\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049554305 |\n",
      "|    clip_fraction        | 0.0932       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.225        |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 0.802        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.001704545454544\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049426337 |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0557       |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 0.767        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.20168539325843\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055055884 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.123        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 0.73         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.388888888888886\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050236816 |\n",
      "|    clip_fraction        | 0.0951       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0241      |\n",
      "|    value_loss           | 0.747        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.574175824175825\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 251          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063930135 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.181        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 0.849        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.75163043478261\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054081026 |\n",
      "|    clip_fraction        | 0.095        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.149        |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 0.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.93279569892473\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072388547 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.14         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0306      |\n",
      "|    value_loss           | 0.876        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.11010638297872\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 259          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058387136 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0281      |\n",
      "|    value_loss           | 0.712        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.27894736842105\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005479938 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.718       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.4515625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005553221 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.717       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.619072164948456\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005932784 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.696       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.78928571428571\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 34.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006544858 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.612       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.95454545454545\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 34.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062790224 |\n",
      "|    clip_fraction        | 0.0984       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.035        |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.025       |\n",
      "|    value_loss           | 0.626        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.1185\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 34.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004917318 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.041       |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.649       |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 29.36\n",
      "Overall Average Successful Assignments: 37.643957329337866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce9fcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -92.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 4.05\n",
      "All assignments history: [5, 5, 5, 5, 5, 1, 4, 3, 6, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -91.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 424      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.575\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006361192 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | -0.127      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.26        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 11.55\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -91.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005614593 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | -0.132      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.8125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005950092 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | -0.0393     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 8.72        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.28\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006307724 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.00911     |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.35        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 8.13        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.158333333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007154472 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.0488      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 7.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.742857142857144\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007587294 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.0885      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.48        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 6.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.71875\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007901238 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.18        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 6.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.6\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -89.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 364        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00813476 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.96      |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.47       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0398    |\n",
      "|    value_loss           | 6.44       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.47\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007988105 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.55        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 6.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.34090909090909\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008228641 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.71        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 5.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.2375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007870033 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 5.11        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.06153846153846\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -86.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 13312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073304046 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.91        |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    value_loss           | 4.63         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 22.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.857142857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -86.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008097566 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    value_loss           | 4.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.69\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -85.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007260562 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.88       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 4.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.140625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -84.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007418297 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    value_loss           | 3.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.591176470588234\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -83.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008062774 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.84       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.16111111111111\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -82.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007189689 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.935       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.66842105263158\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -81.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007396123 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.77       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.981       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.1525\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -80.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006267219 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.74       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.847       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.607142857142858\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -79         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006844621 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.824       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.070454545454545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -77.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006740259 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.58478260869565\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -75.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068493653 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.61        |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    value_loss           | 2.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.022916666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -73.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056844037 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.55        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0353      |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.452\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -72         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006346595 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.47       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.89423076923077\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -70.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064216405 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.41        |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.85         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 2.69         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.32777777777778\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -67.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007328294 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.35       |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.7625\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -65.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 366        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00818737 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.28      |\n",
      "|    explained_variance   | 0.854      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.688      |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.044     |\n",
      "|    value_loss           | 2.63       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.182758620689654\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -63.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068442794 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0398      |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.61666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -60.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007648659 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.857       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.04677419354839\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -57.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070092073 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.01        |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.872        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0439      |\n",
      "|    value_loss           | 2.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.528125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -54.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008307842 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.837       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.97878787878788\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -51.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008206676 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.695       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.436764705882354\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -48.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075704493 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.973        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0474      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.918571428571425\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -45.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008589916 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.691       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.420833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -41.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007195499 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.675       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 2.43        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.887837837837836\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -37.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070934556 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.38        |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.674        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 2.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.35921052631579\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -33.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007325733 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.875       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0466     |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.8\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -30.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007248957 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.698       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 2.03        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.28375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -26.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071560005 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.06        |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.787        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    value_loss           | 2.33         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.75731707317073\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -23.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007074185 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.426       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 1.95        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.195238095238096\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -20.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061571817 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.739        |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0334      |\n",
      "|    value_loss           | 2.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.64883720930233\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -16.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060237637 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.661        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    value_loss           | 2.07         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.10454545454545\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -13.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006253464 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.544       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.55777777777778\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -10.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068315268 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.67        |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.601        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0348      |\n",
      "|    value_loss           | 1.75         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.0\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -7.46        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067224614 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.61        |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0352      |\n",
      "|    value_loss           | 1.87         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.39468085106383\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -5.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005821068 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.467       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.79270833333333\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -2.84       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005706706 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.668       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.18469387755102\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -0.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060128504 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.627        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.561\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 1.68         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055228192 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.408        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.92745098039216\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 3.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005498429 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.906       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.29615384615385\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 5.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004900459 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.41       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.416       |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.64056603773585\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 6.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 54272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005066656 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.297       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.976851851851855\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 7.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059601027 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.38        |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.449        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0299      |\n",
      "|    value_loss           | 1.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.31\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 8.58         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 56320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045338958 |\n",
      "|    clip_fraction        | 0.0885       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.34        |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.516        |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0281      |\n",
      "|    value_loss           | 1.88         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.62321428571428\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 9.16         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049273735 |\n",
      "|    clip_fraction        | 0.0979       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.333        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.0269      |\n",
      "|    value_loss           | 1.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.9359649122807\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044406806 |\n",
      "|    clip_fraction        | 0.0917       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.28        |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.587        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0278      |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.25258620689655\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 11.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004170131 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.377       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.52881355932203\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 11.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004313083 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.821666666666665\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 12.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041903863 |\n",
      "|    clip_fraction        | 0.0785       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.625        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0264      |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.09672131147541\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 13           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050576474 |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.374        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0274      |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.37983870967742\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 13.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047640586 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.284        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0299      |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.646031746031746\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004351704 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.359       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.903125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 14.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048825825 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.15        |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.301        |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0278      |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.15615384615385\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 15.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043567093 |\n",
      "|    clip_fraction        | 0.0857       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.212        |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0257      |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.403030303030306\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 15.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003861435 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.265       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 1.12        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.647014925373135\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 16.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043522874 |\n",
      "|    clip_fraction        | 0.0834       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.26         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0261      |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.88088235294118\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 16.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035177348 |\n",
      "|    clip_fraction        | 0.0735       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.212        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.11739130434783\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 17.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050210655 |\n",
      "|    clip_fraction        | 0.0984       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.938        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0273      |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.337857142857146\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 17.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004677855 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.55070422535211\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 18.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004972205 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.7625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 17.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046445364 |\n",
      "|    clip_fraction        | 0.0934       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.318        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0277      |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.97671232876712\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048115565 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.185        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0293      |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.18783783783784\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045748586 |\n",
      "|    clip_fraction        | 0.0998       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.962        |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0297      |\n",
      "|    value_loss           | 1            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.396\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040237014 |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.39         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0283      |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.60921052631579\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053568413 |\n",
      "|    clip_fraction        | 0.0957       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.224        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0297      |\n",
      "|    value_loss           | 0.971        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.80909090909091\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 19.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004853992 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.922       |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.00769230769231\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058050705 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.185        |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 0.968        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.19746835443038\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 19.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004268565 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.704       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.85        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.39\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 20.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005383918 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.31        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.977       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.57098765432099\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 20.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005620884 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.912       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.75792682926829\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 21.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055428557 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.202        |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0316      |\n",
      "|    value_loss           | 0.981        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.93313253012048\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005345421 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0981      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.772       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.114285714285714\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005015262 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.28529411764706\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 21.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058000255 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0258      |\n",
      "|    value_loss           | 0.797        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.44825581395349\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004971157 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0945      |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.896       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.614367816091956\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046937335 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.966        |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0318      |\n",
      "|    value_loss           | 0.966        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.785227272727276\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 247          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052243792 |\n",
      "|    clip_fraction        | 0.0995       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.738        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0265      |\n",
      "|    value_loss           | 0.983        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.94438202247191\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005021452 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.643       |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.846       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.10611111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 23.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049646497 |\n",
      "|    clip_fraction        | 0.0958       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.18         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0273      |\n",
      "|    value_loss           | 0.875        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.25769230769231\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 23.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041314433 |\n",
      "|    clip_fraction        | 0.0987       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.923        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.259        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.41304347826087\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003869851 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.805       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.56666666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 23.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 262          |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046883468 |\n",
      "|    clip_fraction        | 0.0845       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.12         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0286      |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.71968085106383\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 265          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053607496 |\n",
      "|    clip_fraction        | 0.0996       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2           |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.232        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0286      |\n",
      "|    value_loss           | 0.872        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.862631578947365\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 267          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038929756 |\n",
      "|    clip_fraction        | 0.0812       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0616       |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0263      |\n",
      "|    value_loss           | 0.673        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.0078125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 24.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005333052 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.273       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.924       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.16237113402062\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054830136 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0694       |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0284      |\n",
      "|    value_loss           | 0.73         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.30408163265306\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 24.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006441596 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0948      |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.663       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.4520202020202\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 24.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006982652 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.805       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.598\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 282          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052022403 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2           |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.223        |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    value_loss           | 0.823        |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 26.0\n",
      "Overall Average Successful Assignments: 38.709095513204076\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a2c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -100.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 2.3\n",
      "All assignments history: [6, 7, 2, 4, 0, 7, 4, 5, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -90.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 383      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -60.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 7.225\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071851453 |\n",
      "|    clip_fraction        | 0.0924       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | -0.0624      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.92         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0357      |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -58.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.0\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062076207 |\n",
      "|    clip_fraction        | 0.065        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | 0.0444       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0294      |\n",
      "|    value_loss           | 12           |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 11.3\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006818076 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.075       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 9.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.4\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 378          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067588454 |\n",
      "|    clip_fraction        | 0.0932       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.0966       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.42         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0327      |\n",
      "|    value_loss           | 8.41         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 13.958333333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065410053 |\n",
      "|    clip_fraction        | 0.0868       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.108        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.78         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0312      |\n",
      "|    value_loss           | 7.67         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.971428571428572\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077984324 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.98        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.98         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 7.17         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -20.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.9875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068888227 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.97        |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.32         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    value_loss           | 6.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.055555555555557\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -89.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 375        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00830375 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.96      |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.87       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0397    |\n",
      "|    value_loss           | 6.51       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 8.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.465\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008031938 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.89        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 5.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.986363636363638\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009171994 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.79        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 5.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.425\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008929022 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 4.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.638461538461538\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -86.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007829763 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 4.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.585714285714285\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -86         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007866022 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 4.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.46\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -85.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007831507 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.88       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 3.95        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.29375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -84.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008127458 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 3.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.03529411764706\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -83.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008121444 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.996       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    value_loss           | 3.72        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.7\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -82.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006960498 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.695       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.263157894736842\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -81         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007156821 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.949       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.8425\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -80.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006542398 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.75       |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.376190476190477\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -79.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059094746 |\n",
      "|    clip_fraction        | 0.09         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 28.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.868181818181817\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -78         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006833384 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.38478260869565\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -76.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068102726 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.62        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.93         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    value_loss           | 2.7          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.8625\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -74.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006232838 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.354\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -72.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007182311 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.773       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.840384615384615\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -70.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006799252 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.42       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.994       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.31851851851852\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -68.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 371        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 74         |\n",
      "|    total_timesteps      | 27648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00704978 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.36      |\n",
      "|    explained_variance   | 0.836      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.12       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.041     |\n",
      "|    value_loss           | 3.06       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.823214285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -65.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071107014 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.29        |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0396      |\n",
      "|    value_loss           | 2.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.313793103448276\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -63          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063367663 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.21        |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.87         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.833333333333336\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -59.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008052717 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.37258064516129\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -56.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008422869 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.8796875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -52.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077077993 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0436      |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.38636363636363\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -49.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008661212 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.861       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.90882352941176\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -45.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008883871 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.773       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.41571428571429\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -41.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008726877 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.828       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.925\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -38         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009244127 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.846       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.43108108108108\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -34.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007880921 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.841       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.94736842105263\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -30.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008105315 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.45384615384615\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -26.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068157134 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.16        |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.912        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.96625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -22.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068373038 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.43292682926829\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -19.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006301922 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.917857142857144\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -15.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006229544 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.931       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 2.47        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.38139534883721\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -12.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005812641 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.845454545454544\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -9.48       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006669597 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 2.37        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.29\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -6.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007480261 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.593       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.733695652173914\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -3.82       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006476565 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.677       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.17659574468085\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -1.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048459014 |\n",
      "|    clip_fraction        | 0.0876       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.885        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 2.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.615625\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 1.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055818358 |\n",
      "|    clip_fraction        | 0.0984       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.791        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0338      |\n",
      "|    value_loss           | 2.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.03367346938776\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 3.58         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049755676 |\n",
      "|    clip_fraction        | 0.0956       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.733        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0266      |\n",
      "|    value_loss           | 2.19         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.444\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 5.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052911304 |\n",
      "|    clip_fraction        | 0.0972       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.49        |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.687        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0302      |\n",
      "|    value_loss           | 2.25         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.81666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 6.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 52224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004428755 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.904       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 2.29        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.2\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 8.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058227433 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.44        |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.774        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0311      |\n",
      "|    value_loss           | 2.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.56981132075472\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 9.72         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053584683 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.4         |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.668        |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0323      |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.949074074074076\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 11.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060269777 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.35        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.303636363636365\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 12.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004226789 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.409       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.65446428571428\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 13.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00415012 |\n",
      "|    clip_fraction        | 0.0892     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -2.27      |\n",
      "|    explained_variance   | 0.886      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.549      |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.028     |\n",
      "|    value_loss           | 1.73       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.00877192982456\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006367812 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.562       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.35086206896552\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 15.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004409626 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.494       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.68813559322034\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 16.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045821127 |\n",
      "|    clip_fraction        | 0.0899       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0262      |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.030833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 17.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004113815 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.359836065573774\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 18.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004131546 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.529       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.66451612903226\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038287542 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.553        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0261      |\n",
      "|    value_loss           | 1.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.98888888888889\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047591263 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.567        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0309      |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.2875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044906037 |\n",
      "|    clip_fraction        | 0.0725       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.454        |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0245      |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.59230769230769\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 21.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004276189 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.88333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055714166 |\n",
      "|    clip_fraction        | 0.0928       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0242      |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.17462686567164\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 68608       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004538225 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.54        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.46029411764706\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046973145 |\n",
      "|    clip_fraction        | 0.091        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0273      |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.73550724637681\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044158543 |\n",
      "|    clip_fraction        | 0.0798       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.216        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0231      |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.011428571428574\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041831513 |\n",
      "|    clip_fraction        | 0.0945       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.529        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0272      |\n",
      "|    value_loss           | 1.37         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.27323943661972\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042746156 |\n",
      "|    clip_fraction        | 0.0777       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0235      |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.52847222222222\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004262565 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.29        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.775342465753425\n",
      "All assignments history: []\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 100       |\n",
      "|    ep_rew_mean          | 27.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 369       |\n",
      "|    iterations           | 73        |\n",
      "|    time_elapsed         | 202       |\n",
      "|    total_timesteps      | 74752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0052428 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -1.98     |\n",
      "|    explained_variance   | 0.928     |\n",
      "|    learning_rate        | 0.00018   |\n",
      "|    loss                 | 0.293     |\n",
      "|    n_updates            | 720       |\n",
      "|    policy_gradient_loss | -0.0266   |\n",
      "|    value_loss           | 1.16      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.020270270270274\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005118493 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.251333333333335\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004876651 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.49144736842105\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053403135 |\n",
      "|    clip_fraction        | 0.0985       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0268      |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.72207792207792\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 29.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 78848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00418073 |\n",
      "|    clip_fraction        | 0.0834     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.9       |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.0895     |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    value_loss           | 0.842      |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.94294871794872\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041239243 |\n",
      "|    clip_fraction        | 0.0874       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.17         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.163291139240506\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005640909 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.88        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.385\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 30           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056005977 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.225        |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.6\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004780104 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.788       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.80853658536585\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 30.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004824507 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.169       |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.871       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.00903614457831\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050080484 |\n",
      "|    clip_fraction        | 0.0955       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0791       |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0269      |\n",
      "|    value_loss           | 0.78         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.211309523809526\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 31.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 233          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051933965 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0735       |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0273      |\n",
      "|    value_loss           | 0.878        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.41\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055626645 |\n",
      "|    clip_fraction        | 0.094        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.124        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 0.831        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.598255813953486\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 238          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053165387 |\n",
      "|    clip_fraction        | 0.0957       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.025        |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0258      |\n",
      "|    value_loss           | 0.699        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.78333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 32.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061863377 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0674       |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0268      |\n",
      "|    value_loss           | 0.81         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.96022727272727\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 32.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006130267 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0863      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.875       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.14494382022472\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 247          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069389204 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0277      |\n",
      "|    value_loss           | 0.847        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.32666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005843224 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.807       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.504945054945054\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054315794 |\n",
      "|    clip_fraction        | 0.0904       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0698       |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 0.811        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.678260869565214\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00530817 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -1.83      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 0.0848     |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0283    |\n",
      "|    value_loss           | 0.757      |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 53.84193548387097\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004188309 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.948       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.657       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.01010638297873\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 260          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061461404 |\n",
      "|    clip_fraction        | 0.0802       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.163        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0246      |\n",
      "|    value_loss           | 0.806        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.16894736842105\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005580036 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0864      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 0.666       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.32395833333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063548977 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | -0.00419     |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.028       |\n",
      "|    value_loss           | 0.632        |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.47268041237113\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 33.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047012204 |\n",
      "|    clip_fraction        | 0.0847       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.0749       |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0248      |\n",
      "|    value_loss           | 0.82         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.61887755102041\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005522723 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.847       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.76464646464647\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 33.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006065531 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.715       |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 54.9145\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 34.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 277          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054105804 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | -0.0166      |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0291      |\n",
      "|    value_loss           | 0.663        |\n",
      "------------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 30.24\n",
      "Overall Average Successful Assignments: 39.28860981182147\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ec4fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -96.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 3.2\n",
      "All assignments history: [4, 1, 5, 4, 6, 9, 4, 2, 5, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -91.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 471      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_average_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_average_success` for environment variables or `env.get_wrapper_attr('get_average_success')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\asdra\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.successful_history to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.successful_history` for environment variables or `env.get_wrapper_attr('successful_history')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -74.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 5.875\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -91.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 413        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00621165 |\n",
      "|    clip_fraction        | 0.0601     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.02      |\n",
      "|    explained_variance   | -0.0863    |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 2.29       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0332    |\n",
      "|    value_loss           | 15.4       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -54.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 8.566666666666666\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -91.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 393        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00595993 |\n",
      "|    clip_fraction        | 0.061      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -5.02      |\n",
      "|    explained_variance   | -0.141     |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.63       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 10.7       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -64.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 9.2\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -91.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 386          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056123743 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | -0.0142      |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0309      |\n",
      "|    value_loss           | 8.73         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 12.42\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -90.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006039178 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.0585      |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.13        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 8.64        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 14.25\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 378          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056959693 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.0782       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.26         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0317      |\n",
      "|    value_loss           | 7.62         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 15.635714285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -90          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 377          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065428764 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.0885       |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 2.49         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    value_loss           | 7            |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -14.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 16.7125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 374          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066500218 |\n",
      "|    clip_fraction        | 0.0983       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.123        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.83         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0348      |\n",
      "|    value_loss           | 6.42         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 17.511111111111113\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -89.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071089994 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.98        |\n",
      "|    explained_variance   | 0.182        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.82         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 6.23         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: -10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.275\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008205964 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.39        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 6.16        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 18.73181818181818\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007670894 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.4         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 6.32        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: -6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 19.370833333333334\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -89.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008223405 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.99        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 6.02        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.05\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007567998 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 2.55        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 5.26        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 0.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 20.635714285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -88.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007441073 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 5.14        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 2.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.276666666666667\n",
      "All assignments history: []\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -87.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 369        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00797962 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -4.91      |\n",
      "|    explained_variance   | 0.616      |\n",
      "|    learning_rate        | 0.00018    |\n",
      "|    loss                 | 1.58       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0424    |\n",
      "|    value_loss           | 4.98       |\n",
      "----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 21.83125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -87.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007125711 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.91       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 4.53        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 10.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.45294117647059\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -86.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007304092 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.807       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 4.07        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 4.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 22.919444444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -85.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006190623 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.879       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 3.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 6.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.36578947368421\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -84.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 19456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066561634 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.84        |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 23.8475\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -83.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066435486 |\n",
      "|    clip_fraction        | 0.0925       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.82        |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 18.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.40714285714286\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -82.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062838607 |\n",
      "|    clip_fraction        | 0.0938       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.79        |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.787        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 12.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 24.913636363636364\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -80.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050687976 |\n",
      "|    clip_fraction        | 0.0704       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.75        |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0321      |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 16.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.36304347826087\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -79.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063251285 |\n",
      "|    clip_fraction        | 0.0932       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0349      |\n",
      "|    value_loss           | 3.32         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 24.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 25.920833333333334\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -77.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054117707 |\n",
      "|    clip_fraction        | 0.0721       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0334      |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 26.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 26.464\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -76.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057473285 |\n",
      "|    clip_fraction        | 0.0801       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.63        |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0346      |\n",
      "|    value_loss           | 3.51         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.040384615384614\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -74.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063279225 |\n",
      "|    clip_fraction        | 0.0988       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.58        |\n",
      "|    explained_variance   | 0.833        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.83         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 27.61111111111111\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -72.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074793957 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.53        |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.972        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 2.9          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.1375\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -70.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071256403 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.46        |\n",
      "|    explained_variance   | 0.833        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.967        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0416      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 28.67241379310345\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -68.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072231544 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.38        |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.634        |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0409      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 30.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.211666666666666\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -65.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007436815 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 29.746774193548386\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -62.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059678527 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.037       |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.2875\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -60.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066914707 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4.09        |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.829        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 30.825757575757574\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -56.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066442946 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -4           |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 32.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.354411764705883\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -53.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007065517 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 31.87142857142857\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -50.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068353927 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.77        |\n",
      "|    explained_variance   | 0.812        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0407      |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.40694444444444\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -46.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006613932 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.969       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 32.932432432432435\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -43.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006449894 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 33.46842105263158\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -39.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068697543 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.908        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0398      |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.03333333333333\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -34.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070261657 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -3.35        |\n",
      "|    explained_variance   | 0.81         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0369      |\n",
      "|    value_loss           | 2.58         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 34.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 34.56375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -31.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006301685 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.7         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.07073170731707\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -27.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007614812 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 2.47        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 35.59404761904762\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -23.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006487024 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.080232558139535\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -20.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 44032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006086439 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.576       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 2.24        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 36.56136363636364\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -17.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063819634 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.95        |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.799        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0402      |\n",
      "|    value_loss           | 2.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.035555555555554\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -14.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061638323 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.89         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    value_loss           | 2.26         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 37.530434782608694\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -11.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006883955 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.736       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 2.34        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.02872340425532\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -8.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005833883 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.49166666666667\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -5.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061105588 |\n",
      "|    clip_fraction        | 0.0985       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.66        |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.787        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0293      |\n",
      "|    value_loss           | 2.39         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 38.96632653061224\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -3.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005626253 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.407\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -1.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005017938 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 39.826470588235296\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 0.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054272898 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.77         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0301      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 36.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.2375\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 2.56        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005230128 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 40.64811320754717\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 4.56         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049590385 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.44        |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0306      |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.07314814814815\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 6.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051780455 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.39        |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    value_loss           | 2.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.46181818181818\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 8.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004831631 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.39       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 2.51        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 38.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 41.85089285714286\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 9.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005338719 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.41       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 2.36        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.228070175438596\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 10.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007405013 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.37       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.60689655172414\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 11.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004724918 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.34       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.953       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 42.978813559322035\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 12.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049688052 |\n",
      "|    clip_fraction        | 0.0965       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.958        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0272      |\n",
      "|    value_loss           | 2.54         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.354166666666664\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 14           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043281466 |\n",
      "|    clip_fraction        | 0.0795       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0252      |\n",
      "|    value_loss           | 2.18         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 43.705737704918036\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 15.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 62464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045813886 |\n",
      "|    clip_fraction        | 0.0844       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.935        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0221      |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.04435483870968\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 16.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004109718 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 2.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.36666666666667\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 16.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004343294 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.778       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 2.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.6703125\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 16.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048795496 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.23        |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0304      |\n",
      "|    value_loss           | 2.24         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 44.98384615384615\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 17.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004460008 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.766       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.3\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 18.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045389794 |\n",
      "|    clip_fraction        | 0.076        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0233      |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.61119402985074\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 19.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 186          |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049352096 |\n",
      "|    clip_fraction        | 0.0927       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.15        |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.86         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0282      |\n",
      "|    value_loss           | 1.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 45.90661764705882\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 20           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042585935 |\n",
      "|    clip_fraction        | 0.0741       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.765        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.023       |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.20579710144928\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 20.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004267641 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.669       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.49\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 21           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053784614 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.772        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0261      |\n",
      "|    value_loss           | 1.86         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 46.77323943661972\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 21.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049785683 |\n",
      "|    clip_fraction        | 0.0898       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.698        |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0259      |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.044444444444444\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 22.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039374502 |\n",
      "|    clip_fraction        | 0.0704       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.577        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0224      |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.31643835616438\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 23.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006404692 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.806       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.5722972972973\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 24.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050403783 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.537        |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0235      |\n",
      "|    value_loss           | 1.6          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 47.816\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 24.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005741935 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.586       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 1.71        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.05789473684211\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 25          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005171311 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.48        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.29675324675325\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049306685 |\n",
      "|    clip_fraction        | 0.0854       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.533        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.025       |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.53782051282051\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 25.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048207743 |\n",
      "|    clip_fraction        | 0.081        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.607        |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0235      |\n",
      "|    value_loss           | 1.68         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 48.78291139240506\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 25.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 80896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004683037 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.0175\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055927206 |\n",
      "|    clip_fraction        | 0.0862       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.4          |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0219      |\n",
      "|    value_loss           | 1.47         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.23271604938272\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 225          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055413414 |\n",
      "|    clip_fraction        | 0.0976       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.644        |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0261      |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 40.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.447560975609754\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054631755 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0283      |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.66867469879518\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 26.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004525951 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.415       |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 49.87380952380953\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049804845 |\n",
      "|    clip_fraction        | 0.0919       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.07235294117647\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057074847 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.475        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.028       |\n",
      "|    value_loss           | 1.57         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.270348837209305\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 26.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 367          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041037663 |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.448        |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 1.64         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.478735632183906\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041665286 |\n",
      "|    clip_fraction        | 0.0737       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.471        |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0226      |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.673863636363635\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 27.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004735642 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.401       |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 50.86067415730337\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044761756 |\n",
      "|    clip_fraction        | 0.084        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.572        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0241      |\n",
      "|    value_loss           | 1.45         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.05222222222222\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 366          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 251          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050321273 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.408        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0262      |\n",
      "|    value_loss           | 1.52         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.23186813186813\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 27.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055349143 |\n",
      "|    clip_fraction        | 0.0909       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.573        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.40869565217391\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 28          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005192807 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.4         |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.589247311827954\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 28.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 95232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005284548 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.703       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.768085106382976\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 28.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 263          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055793617 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 0.265        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0266      |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 51.932631578947365\n",
      "All assignments history: []\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 29           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055762343 |\n",
      "|    clip_fraction        | 0.0975       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.0953125\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005647619 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.452       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.26237113402062\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 28.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006293055 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.354       |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Rollout Summary --------\n",
      "Total mean reward: 44.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.425\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 28.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005855756 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.586363636363636\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005805978 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.266       |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "-------- Rollout Summary --------\n",
      "Total mean reward: 42.0\n",
      "Standard deviation of reward: 0.0\n",
      "Average successful assignments: 52.742\n",
      "All assignments history: []\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 29.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004636739 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | 0.443       |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-------- Training Summary --------\n",
      "Overall Average Mean Reward: 26.28\n",
      "Overall Average Successful Assignments: 36.66564767400641\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Load datasets\n",
    "tasks_df = pd.read_csv('RandomTasks100.csv')\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "tasks_df.rename(columns={\n",
    "    'Required_RAM': 'RAM',\n",
    "    'Required_Storage': 'storage',\n",
    "    'Minimum_Trust_Factor': 'Trustfactor',\n",
    "    'Max_Distance': 'Distance',\n",
    "    'Min_Transmission_Rate': 'TransmissionRate',\n",
    "    'Min_Eligibility': 'MinEligibility'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the Gym environment for task allocation\n",
    "class TaskAllocationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, vehicles, tasks):\n",
    "        super(TaskAllocationEnv, self).__init__()\n",
    "        self.vehicles = vehicles\n",
    "        self.tasks = tasks\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.successful_history = []  # Added to track successful assignments\n",
    "        self.seed()\n",
    "\n",
    "        num_features = tasks.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "        self.eligible_vehicle_indices = []\n",
    "        self.update_action_space()\n",
    "\n",
    "    def seed(self, seed=42):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]        \n",
    "        \n",
    "    def update_action_space(self):\n",
    "        task_eligibility = self.tasks.iloc[self.current_task]['MinEligibility']\n",
    "        eligible_vehicles = self.vehicles[self.vehicles['Eligible'] >= task_eligibility]\n",
    "        self.eligible_vehicle_indices = eligible_vehicles.index.tolist()\n",
    "        if len(self.eligible_vehicle_indices) == 0:\n",
    "            self.action_space = spaces.Discrete(1)  # Prevents invalid action space of size 0\n",
    "        else:\n",
    "            self.action_space = spaces.Discrete(len(self.eligible_vehicle_indices))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_task = 0\n",
    "        self.successful_assignments = 0\n",
    "        self.update_action_space()\n",
    "        #print(\"Resetting environment. Starting new episode.\")\n",
    "        return self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        task = self.tasks.iloc[self.current_task]\n",
    "        vehicle = self.vehicles.iloc[action]\n",
    "        reward = 0\n",
    "\n",
    "        # Check if the vehicle meets all the task requirements\n",
    "        meets_requirements = (\n",
    "            vehicle['RAM'] >= task['RAM'] and\n",
    "            vehicle['storage'] >= task['storage'] and\n",
    "            vehicle['Trustfactor'] >= task['Trustfactor'] and\n",
    "            vehicle['Distance'] <= task['Distance'] and\n",
    "            vehicle['TransmissionRate'] >= task['TransmissionRate']\n",
    "        )\n",
    "        reward = 1 if meets_requirements else -1\n",
    "\n",
    "        self.successful_assignments += reward > 0\n",
    "        self.current_task += 1\n",
    "        done = self.current_task >= len(self.tasks)\n",
    "\n",
    "        if not done:\n",
    "            self.update_action_space()\n",
    "            next_state = self.tasks.iloc[self.current_task].values.astype(np.float32)\n",
    "        else:\n",
    "            next_state = np.zeros(self.observation_space.shape[0])\n",
    "            self.successful_history.append(self.successful_assignments)\n",
    "            #print(f\"Episode completed. Successful assignments: {self.successful_assignments}.\")\n",
    "            self.successful_assignments = 0  # Reset for next episode\n",
    "\n",
    "        \n",
    "        \n",
    "        #three lines below can be uncommented for more detailed output\n",
    "        #print(f\"Task Details: {task.to_dict()}\")\n",
    "        #print(f\"Vehicle Details: {vehicle.to_dict()}\")\n",
    "        #print(f\"Step: Task {self.current_task}, Action {action}, Reward {reward}\")\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def get_average_success(self):\n",
    "        return np.mean(self.successful_history) if self.successful_history else 0\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Custom callback for logging\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.total_rewards = 0\n",
    "        self.total_assignments = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        mean_reward, std_reward = evaluate_policy(self.model, self.model.get_env(), n_eval_episodes=10)\n",
    "        average_assignments = self.env.get_attr('get_average_success')[0]()\n",
    "        self.total_rewards += mean_reward\n",
    "        self.total_assignments += average_assignments\n",
    "        self.num_episodes += 1\n",
    "\n",
    "        print(\"-------- Rollout Summary --------\")\n",
    "        print(f\"Total mean reward: {mean_reward}\")\n",
    "        print(f\"Standard deviation of reward: {std_reward}\")\n",
    "        print(f\"Average successful assignments: {average_assignments}\")\n",
    "        print(\"All assignments history:\", self.env.envs[0].successful_history)\n",
    "        self.env.envs[0].successful_history = []  # Reset history after each iteration\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        average_total_reward = self.total_rewards / self.num_episodes\n",
    "        average_total_assignments = self.total_assignments / self.num_episodes\n",
    "        print(\"-------- Training Summary --------\")\n",
    "        print(f\"Overall Average Mean Reward: {average_total_reward}\")\n",
    "        print(f\"Overall Average Successful Assignments: {average_total_assignments}\")\n",
    "\n",
    "\n",
    "# Prepare the environment\n",
    "env = make_vec_env(lambda: TaskAllocationEnv(vehicles_df, tasks_df), n_envs=1)\n",
    "\n",
    "# Initialize and train the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "            n_steps=1024, batch_size=128, n_epochs=10, learning_rate=0.00018,\n",
    "            gamma=0.96, gae_lambda=0.87, clip_range=0.15, ent_coef=0.07)\n",
    "\n",
    "callback = CustomCallback(env)  # Use custom callback for detailed tracking and logging\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=1024*100, callback=callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_task_allocation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5af8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
